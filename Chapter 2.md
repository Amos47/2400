# Chapter 2
### In which we dig in a little deeper

## Context
We begin this chapter by stating unequivocally that computers have historically done a lousy job with *context*. They have been unable to understand, process and make sense of the nuanced detail of our lives and our interactions with each other and with our environment. Why? Because they have struggled with *knowledge*. They have struggled to *learn* in the way that humans learn. They have not been able to generalise either from the specific to the general or from the general to the specific. They have been unable to observe a piece of art and decide if they *like* it or not or even, until very recently, to quantify its characteristics. They struggle with deciding if a painting were a Picasso, a Monet or a Da Vinci.

Those kind of tasks -- appreciating beauty, creating music, writing poetry -- have been left to humans because computers lacked the ability to create and appreciate *context*. They can’t see the *bigger picture*. All this is changing. Read on.

**Figure DC. The definition of context from Visual Thesaurus**

![visualthesaurus.com Definition of context](https://raw.githubusercontent.com/robertriordan/2400/master/Images/vt_context.PNG)

The Visual Thesaurus definition for context reads, in part:

1. Language that helps to determine its interpretation
2. The set of facts or circumstances that surround a situation or event

Of the two definitions, the second is most important for us. I have written elsewhere that data are *facts*. Just pieces of unencumbered specifics, providing measurement of some phenomenon. *Circumstance*, on the other hand, is a collection of facts which together frame the *situation* or *condition*. It’s the *fact bath* in which we continuously find ourselves. It’s all the stuff that happens *around* an event at a place and time that give us the ability to weave a rich fabric of meaning around the event and allows us reduce the error around what’s happening in a particular setting. Here's what the online Oxford Reference has to say about context:

"Most broadly, any frame of reference or framework within which something is perceived, produced, consumed, communicated, interpreted, or otherwise experienced, or which is seen as relevant to the description or analysis of any phenomenon."

[Interested?](http://bit.ly/1ITF5oD)

The salient parts of that definition refer to the *frame of reference* within which *something is perceived, consumed... or otherwise experienced...* Why so important? Because context is everything. As humans, we live in a contextual soup of signs, signals, impressions, facts and suspicions. Computers can’t quite figure us out. Yet.

So what is context?

Think for the moment of the process of getting ready for an adventure outside the home. Going to school maybe, or work, or just for a walk. Think about the decisions that need to be made, focusing on what to wear. If you and I are even somewhat alike, then you have a range of things to put on your back -- but what to wear today? First level of decision, likely made with no conscious thought whatsoever, is to consider the season. Thus the season provides the largest or highest level (most abstract) *context* in which is made the decision of what to wear outside. Season sets the broad parameters. Fact: It’s cold in winter and hot in summer and spring and fall are a crap shoot.

Next in line is likely the general state of the weather, within the broader context of season. If it's winter, is it sunny and cold or is a blizzard raging? Finally, just hearing that it's cold outside is insufficient context. As we know, being good Canadians, there's Winnipeg or Ottawa cold and then there's Vancouver or Niagara cold. Not the same thing at all. *Ergo* "cold" is a qualitative and relative measure, relative to the context of where one currently finds oneself. It doesn't much help us to decide on apparel. Summer cold is a different beast entirely from winter cold. Consider further the tug-of-war between the Alberta Clipper and the Chinooks. Even being in Canada in the winter can cause wide swings in temperature.

Let's just drive this home by considering temperature in a little more detail. In determining what to wear, we might be wise to consult a weather service. Navigate to a website or click a *Follow me* app such as www.theweathernetwork.com (and isn't the function of 'follow me weather' to provide the **context** of where one is currently located?) on your device or switch on the TV and select the weather channel (where a local context will already be provided because the weather channel *knows* to where the signal is being sent and thus provides the proper geo-context for you). Normally the current temperature is the most salient factor, thus we might find a large **20** prominently displayed on the screen. Not to put too fine a point on it, and you've likely already caught on, but *20 degrees* indicates entirely different weather in Buffalo as opposed to just across the lake in Toronto - even on a day where the objective weather is nearly exactly the same in both cities. That's owing to, obviously, the scale of temperature being measured in *Fahrenheit* in Buffalo and *Celsius* in Toronto. Twenty F is below freezing in Buffalo whereas 20 C is t-shirt weather in Toronto. So the context of location, regardless of what the weather actually is, is important. Context drives interpretation. Context makes information out of data and allows us to make decisions.

And now, just to really make this a challenge, consider the final bowl of contextual stew in which we find ourselves. *Fashion. Whim. Trends. Expectations. Style.* How do I feel today? Is it before or after Labour Day? Should my pants and jacket be from the same design house? Do I dare wear a department store label? What did I wear last time I was with the people I'm likely to see today? What will they expect me to wear, given that I just got a promotion at work? Will *he* be there? What kid of person do I need to be today?

Often, when someone reminds me of a particularly silly or ill-conceived decision I have made in the past, I glibly justify by stating "Oh, that was during my pastel phase." Meaningless banter meant to deflect criticism in a lighthearted way but... what if it were true? What if I did have a *pastel phase*, whatever that might mean. Indeed, how could we ever expect a machine to decode and enforce the rules around such a thing whether in the present (I'm only wearing chalk tones these days." or when examining the past "Oh, well, I must be excused for that behaviour. I was under the influence at the time.")

Fashion is a tall order for people, let alone machines. And people often get fashion wrong. Take a stroll through a Tim Horton's. Worse still, fashion is *opinion* driven by the huge influence machine we call *marketing*. We can't win.

### Situatedness
An interesting corollary of context is the notion of *situatedness*. Oxford Reference defines it partly as:

“The dependence of meaning (and/or identity) on the specifics of particular sociohistorical, geographical, and cultural contexts, social and power relations, and philosophical and ideological frameworks, within which the multiple perspectives of social actors are *dynamically constructed, negotiated, and contested.*” [emphasis added]

 [[Interested?](http://bit.ly/1svpjLY)]

Ever answered to someone “You had to be there.” in reply to the question “What’s so funny?” If so, then you appreciate *context*. The interpretation of a message or communication is dependent on the situation in which it occurs and to which it refers. Imagine how many ways a simple word like *Yes* or *No* could be interpreted when you consider situational variables such as voice inflection, facial expression, volume and the length of utterance of the speaker, emphasis on a particular word or even syllable, to name but a few. There’s an hilarious comedy skit by a Jewish comic in which he successively puts the emphasis on each word in the interrogative phrase “He said I should bring a gift?” and in so doing changes the interpretation of the phrase each time. Try it yourself: Emphasise the **bolded** word in each sentence below by making the word a question in and of itself and note how the meaning attached to the phrase changes each time:

**He?** said I should bring a gift?

He **said?** I should bring a gift?

He said **I?** should bring a gift?

He said I **should?** bring a gift?

And so forth.

There are literally dozens of possible interpretations or meanings for a simple word, depending on the context in which the word was uttered. Misreading the context of a situation can be a very serious matter. People are in jail for it. Lives are ruined by it. If someone has ever quoted you *out of context* then you know what we’re talking about here. So subtle and so powerful is context that we must dynamically manage all our behaviours in order to be appropriate *in context*.

Oxford suggests that context is dynamically constructed, negotiated and contested. I would add that people navigate and interpret context all the time. We are social actors who are continuously jostling for a position of advantage among our peers and contemporaries. Such is the human condition.

#### Exformation
Appropriate in this context is the discussion of the concept of *Exformation*. Here I extensively quote [the exformation entry in wikipedia.com](https://en.wikipedia.org/wiki/Exformation "Exformation") (all emphasis added by me]:

"Exformation (originally spelled *eksformation* in Danish) is a term coined by Danish science writer Tor Nørretranders in his book *The User Illusion* published in English 1998. It is meant to mean *explicitly discarded information*. However, the term also has other meanings related to information, for instance *useful and relevant information* ...

"Effective communication depends on a shared body of knowledge between the persons communicating. In using words, sounds, and gestures, the speaker has deliberately thrown away a huge body of information, though it remains implied. This shared **context** is called *exformation*.

"Exformation is everything we do not actually say but have in our heads when, or before, we say anything at all - whereas information is the measurable, demonstrable utterance we actually come out with. [see Chapter 1 of this textbook.]

If someone is talking about computers, what is said will have more meaning if the person listening has some prior idea what a computer is, what it is good for, and in what *contexts* one might encounter one. From the information content of a message alone, there is no way of measuring how much exformation it contains.

"In 1862 the author Victor Hugo wrote to his publisher asking how his most recent book, *Les Misérables*, was getting on. Hugo just wrote "?" in his message, to which his publisher replied "!", to indicate it was selling well. This exchange of messages would have no meaning to a third party because the shared context is unique to those taking part in it. The amount of information (a single character) was extremely small, and yet because of exformation a meaning is clearly conveyed."

**Figure JJLL. Exformation as context**

![Exformation as context](https://raw.githubusercontent.com/robertriordan/2400/master/Images/exformation.png)

Examine Figure JJLL and imagine time-transporting Canada's first PM, Sir John A. Macdonald to the present day and eventually, handing him with an Android device (I don't know about you, but I indulge in such fantasies regularly...). Note the massive *exformation* in this interaction - the things that *we* just implicitly understand about such modern devices that Sir John A. could not possibly even fathom. This is context at its most obvious.

We might think of exformation as *common sense* in a way. Common sense is *context* that is commonly held by individuals in a particular social setting. When someone says "That's just common sense!" it is understood that a person should have internalised the context in which some action was taken and have been guided by that experience. "It's just common sense that you can't make toast in the tub." It's a shared understanding and a product of having been immersed in the computing culture since forever. But what of Sir John A?

Our question in this section is “Will machines ever be able to make sense of context and exformation?" We’ll get there in our discussion. Hang on.

Meanwhile, take a look at context in practice. Below in Figure GH we see the distribution of scores on the 2013 high school exit examination in Poland. Is human decision making at play here ("We just can't let poor Wojciech fail... he's so close!") or have humans written an computer algorithm that contextualises grades such that "Given that scores have a confidence interval around them of say +/-3%, any score that is in the range of 27- should be awarded a grade of 30." We don't know, but this is interesting *context*, no? Also note the small amount of what's referred to in statistical circles as *heaping* at the highest level (100%). I guess if you get close enough, what's the difference? If you log into bit.ly (see below) and examine the data, you will see that there were no scores of 92, 95 or 98, but that the frequency of test scores at 100% was twice that at 99%. You might also note that no one scored a 29. There was also a bit of a heap at 31 -- so likely a 31 means you scored a legit 30 and are given a 31 so as to differentiate from those who were gifted a 30 - that's a message in itself. A 30 means you didn't earn it... And there's a bit of heaping at 32 up to about 36 or so as the *bumping up* continues to ripple through the distribution. An otherwise almost textbook *normal distribution* becomes the victim of context.

**Figure GH. Context at its finest.**

<div>
    <a href="https://plot.ly/~Dreamshot/461/" target="_blank" title="Distribution of the Results of the Matura in 2013 (Poland&#39;s High School Exit Exam)&lt;br&gt;&lt;br&gt;The minimum score to pass is 30%" style="display: block; text-align: left;"><img src="https://plot.ly/~Dreamshot/461.png" alt="Distribution of the Results of the Matura in 2013 (Poland&#39;s High School Exit Exam)&lt;br&gt;&lt;br&gt;The minimum score to pass is 30%" style="max-width: 100%;width: 700px;"  width="700" onerror="this.onerror=null;this.src='https://plot.ly/404.png';" /></a>
    <script data-plotly="Dreamshot:461"  src="https://plot.ly/embed.js" async></script>
</div>

*Source: https://plot.ly. Create an account and play around. Fun stuff.*

### Meaning
How do we derive meaning from data or communication? Through interpreting data and facts in context. Context provides meaning for meaningless data. But what does *meaning* mean? Oxford to the rescue.

"Whatever it is that makes what would otherwise be mere sounds [...] into instruments of communication and understanding. The philosophical problem is to demystify this power, and to relate it to what we know of ourselves and the world."

[Interested?](http://bit.ly/1GoQwmb)

What we *know* of ourselves and the world is clearly *knowledge*.  But from where comes knowledge?
[Oxford](http://www.oxforddictionaries.com/us/definition/american_english/knowledge "Oxford on knowledge") offers the following (edited for applicability in this context -- see? Context everywhere). Knowledge is:

1. **Facts, information**, and skills acquired by a person through **experience** or education; the theoretical or practical understanding of a subject
2. Awareness or familiarity gained by experience of a fact or **situation**

The important concepts were **bolded** in the definitions above by me. Let’s look at each in turn:

1.    Facts – facts are data; simple measurements lacking context
2.    Information – we deal with information below, and how it is derived from data and then becomes transformed into potential action through context
3.    Experience – comes from observation of the results of actions, which flow from decisions fuelled by actions as a result of information produced from data in a context
4.    Situation – clearly a synonym for context

This suggests a simple and general model of knowledge acquisition that applies to all creatures, great and small, that are faced with making decisions. But where does this all fit in terms of business?

### Context in business decisions
**Figure LJLJ. A simple context - from measurement to knowledge**

![Simple context](https://raw.githubusercontent.com/robertriordan/2400/master/Images/simple_context.png)

Examine Figure LJLJ from left to right. Imagine this as the first ever measurement of a phenomenon in a state of complete *nescience* (absence of knowledge); the very first ever occurrence of this data; perhaps the first day of a new business where everything is all brand new. View it as a system in the way we understand systems from the introductory chapter where *d* (data) is the input and *K* (knowledge) is the output. The only existing elements are measurements, which make the data tangible (length, for example, is a concept or a variable; 6 cm is tangible data and a fact representing the length of something being measured).

There might well be a question or a challenge creating a strategy vacuum and drawing data into that question context. It’s also possible that exploratory research is driving the data initiative, as in “Let’s look at our data and see what it has to tell us.” with no particular agenda in mind.

Regardless of what nudged the process into action (remember that systems need a trigger in order to start), the ensuing process is the same. It begins as newly-measured data approach from outside the system and become understood in a *context* where the data become *information*. This creation of new information allows a decision to be made, and decisions lead either to *action* or *inaction*. Action/inaction leads to results, the measurement of which yield new data (measured observations) in the context of that situation, which leads ultimately to knowledge (experienced gained by observing the effects of the action/inaction in this particular context).

This is a general theory of how data are transformed into knowledge.

There are thus two contexts in each chain from data to knowledge. There’s the initial context with the decision and action/inaction attendant upon it, then there’s the context resulting from the action/inaction. This is how we gain knowledge. We act or stand still. We experiment. We make decisions and we see what happens. But there is a much richer model to come, wherein we benefit from our accumulated knowledge and our observations of context. That’s the only real reason for any of this. To get better at what we do based on experience. Hang on.

It’s important to note that information only occurs within a context, and each context is, by definition, unique. There can be similar contexts, contexts that share traits with other, but each context is itself unique. The universe ticks ahead and an infinite array of things change with each tick. Thus it’s important to bring as much data as possible to bear on a particular context, as it will never occur again. Everything changes in the ticking of the clock. We will return to this.

Let’s re-examine our clothing decision in light of this theory.

Imagine a new friend has just landed from Mars. Or Alberta. Our visitor needs to find food and has no preconceived notions (previous contexts) upon which to base a choice of clothing. Our Martian friend has an objective measurement of temperature (temperature being a universal concept and all living organisms are sensitive to temperature and have an *operating range* outside of which they cannot function), is aware of their location (earth) and of the star date, and finally that they have a certain tolerance for temperature (this is accumulated knowledge). What to wear?

In our knowledge-acquisition model, there is *always* context. The context in this case is that there is precious little data upon which to base the information required to choose what to wear. So in this context, our Martian friend simply chooses to wear nothing (no action) while going for a stroll to the mall. Turns out today is February 10th and we’re in Ottawa. Tad chilly. The result of this decision to take no dressing action is that our friend experiences intense cold against an unprotected body and the outside temperature is outside the sustainable operating range of a healthy Martian. Their body measures the temperature and the effects of that temperature and this data, in the new context, becomes information. This information in this context, in association with the information provided by the initial context is stored, becomes knowledge. Now our friend has a bit of a bead on what to wear. They have gained some *knowledge*.

The nugget of knowledge for our little green friend is that at this temperature on this date in this location taking no action to protect oneself from the elements is potentially damaging. Bingo. Knowledge and a new context upon which to base further action. Walk through this scenario again with this knowledge but with the same Martian in the same situation on July 10. What would the process look like?

To answer this question, we must move to the more elaborated model of knowledge acquisition (or decision making if you prefer). See Figure LAJ.

**Figure LAJ: The flow of data into contextual information to decision, action and knowledge**

![Context](https://raw.githubusercontent.com/robertriordan/2400/master/Images/context.png)

In Figure LAJ we see illustrated how the process of measurement (m), whether conscious or not, provides a value for a new piece of data (d), which in combination with existing, measured data (whether newly-measured or previously measured) flows into a new context (circle) where new information (green) is produced when combined with knowledge available through feedback from previous contexts (green arrow). This new 'mashup' provides the necessary ingredients for a new decision. The decision begets some results, whether through action or inaction, which, in turn, creates new information in this new context. This new information in turn feeds knowledge from observing the outcome of the action. This new knowledge (K), in combination with prior knowledge, in its accumulated glory, washes back over any new context. The creation of knowledge is thus a dynamic, fluid and constant activity for living organisms and inanimate entities such as organisations alike.

### Schemata and knowledge acquisition
This model of knowledge acquisition is not inconsistent with, and may be seen as an extension of, the work done in the fields of Psychology and Cognitive Science in the area of *schemata*. Pioneering work by Bartlett, extended by Jean Piaget, (see the Interested? links below) postulates that people learn about and make sense of their work by building, modifying, extending and discarding mental models of how things work. A quick (and brutally naïve) explanation and example follows.

The first premise necessary to accept if one subscribes to the schema notion of knowledge acquisition is that of *tabula rasa*, loosely translated and understood to mean *blank slate*, as in a blank chalk board in a classroom. As far back as Aristotle, the notion that humans are born with a blank slate mind has been popular. [Interested?]( http://en.wikipedia.org/wiki/Tabula_rasa) This *blank slate* is written on, erased, altered and generally enhanced as humans grow and learn and acquire knowledge. So at the first encounter of a child with a dog, for example, the rudimentary schema of *dog* is created that inscribes the characteristics of the dog (a particular size creature with four legs, fur, a tail and a long snout of a nose, etc.) to the dog schema. A parent labels the creature *dog* and the kid is off to the races, able to recognise all manner of four-legged creatures forever more. But trouble looms…

Next, our fearless young dog expert encounters a cow. Slightly bigger, but hey, it’s got four legs, fur, a snout and a tail. Must be a dog. So our schema builder spots a cow and happily points to it and announces to a parent “Dog!” Nope, the parent corrects, that’s a cow. New schema in order here. At the same time, it’s possible that a *super schema* is also developed, this one encompassing the characteristics we know as *animal* and containing the attributes “four legs, fur, tail, long snout” of which *dog* and *cow* are specific examples. *Dog* might now have an encoded attribute for *size* that would differentiate the dog from the cow based on size. But *calf* and *pony* and *puppy* and *kitten* present problems, necessitating further refinements of the existing schemata. We won’t even get into the difference between a house cat (and the colour variation) and the myriad of *jungle casts*. Learning can be frustrating.

A [McKinsey report on Machine Learning](http://www.mckinsey.com/insights/high_tech_telecoms_internet/an_executives_guide_to_machine_learning "Machine Learning") had the following to say about how machines are *taught* to recognise simple things like cows and cats:

"In 2007 Fei-Fei Li, the head of Stanford’s [University] Artificial Intelligence Lab, gave up trying to program computers to recognize objects and began labeling the millions of raw images that a child might encounter by age three and feeding them to computers. By being shown thousands and thousands of labeled data sets with instances of, say, a cat, the machine could shape its own rules for deciding whether a particular set of digital pixels was, in fact, a cat. Last November, Li’s team unveiled a program that identifies the visual elements of any picture with a high degree of accuracy. IBM’s Watson machine relied on a similar self-generated scoring system among hundreds of potential answers to crush the world’s best Jeopardy! players in 2011."

We return to *Jeopardy!* and Watson later in this chapter.

It is through continual exposure to new data and continual feedback based on decisions made emanating from that exposure that specific and actionable knowledge is created and stored. You can see that the notion of context fits nicely here (well maybe you can’t see yet, but I can and I hope you will come to an understanding of these principles as we progress). It is also very interesting to note the similarities between the schemas of cognitive psychology and the software development technique known as *Object-Oriented Programming* (or OOP). I’ll try to remember to revisit that connection in the chapter on Systems Development… :)

Knowledge acquisition (also referred to as the process of *Knowledge Engineering*) is also the biggest obstacle to creating *Artificial Intelligence* (or AI). If we have time to fit that in somewhere, it will likely be in the final chapter on *Future Trends*. While we’re here, I also strongly recommend a course (or even picking up a book on the topic) in Cognitive Psychology for anyone interested in ICT, Marketing, Finance or Management. It’s so cool you might just fall in love.

[Interested in schemas?](http://en.wikipedia.org/wiki/Schema_(psychology))
[Interested in knowledge acquisition?]( http://www.wisegeek.com/what-is-knowledge-acquisition.htm)

Knowledge acquisition can be seen as a system, with the four main entities identified by coloured background ovals in Figure LAJ. On the left is *Input*, flowing into *Process*, which produces *Output* which is fed back into the system as *Input* to the continuous process of knowledge production and acquisition. ANd don't overlook the important tenet that much of the data that enters a decision process as input, and equally previous knowledge that is fed back to the decision-making process, functions as *context*. It is the soup made from the situation and the previous experience that allows us to decide how to move forward. All the ingredients of the soup together allow us to decide if we like the taste.

## Important takeaways
*
A context is a new, unique and non-reoccurring circumstance created out of the intersection of existing and new data and existing knowledge gained from previous contexts. It can only occur once. No two contexts are alike.

*
Since contexts (and thus decisions emanating from the information created in them) are unique, it is critical to provide the optimal (note I didn’t write *maximal* as too much data can be as confounding as too little data) amount of data and knowledge as input to the context. There is no substitute for accurately-measured data and accumulated knowledge.

*
Decision quality is a function of reducing error around the decision outcome. Accumulated knowledge from previous contexts and of the outcomes of decisions attendant upon them will reduce error. Better decisions are the result. If you have *seen stuff like this before* and have *observed the outcome* you are clearly in a better position to make a more accurate prediction of the future, and thus better decisions about how to get there.

*
Knowledge is accumulated by observing results of action/inaction in context.

*
Wisdom is knowing how and when to use it…

### Data architecture

How do we go about ensuring that optimal contexts are built, within which we generate the most valuable information? The answer is *data architecture* and perhaps in the broader field of *information architecture*. Our online Business Dictionary defines *data architecture* as:

"Models, policies, rules, or standards that govern which data is collected, and how it is stored, arranged, and put to use in a database system, and/or in an organization."

[If you are interested, make sure to follow each link for the related definitions!](http://www.businessdictionary.com/definition/data-architecture.html)

What does all this mean for us? It means that we need to carefully think about *which* data to collect, *how* we will collect it, how we will *store* it and how we will *retrieve* it in order that it will contribute to our decision-making context. We will return to this general topic when we discuss databases and related technology in a subsequent chapter.

For now, imagine a survey with only one question: "So what do you think?" Administering this survey to a sample of your cohort would lead to all kinds of rich data, wild imaginings and likely some quite pointed suggestions about what we can do with our *survey*. The data we get in response might well be interesting, but not at all targeted to anything. People would be looking for a context. "What do I think about WHAT?" In fact, I went to the trouble of creating such a survey on a public survey service site but thought better of it... I can imagine the results. It is this principle which guides us in architecting our data collection, storage and retrieval plans for an organisation. We must specify what questions we will need to answer:

- about our organisation when it comes time to account for our activities
- to determine how we are performing
- to understand our place in the market
- to determine how to move forward
- in reply to our employees, customers, stakeholders, regulators, partners and even competitors

In this regard, organisations must carefully consider their data strategy. But we must also be aware that simply saving everything in every possible format *just in case* is not a wise strategy either. The burden would be onerous, the data would be monstrous, the information generated from it redundant and perhaps even contradictory. The cost would soon far outweigh the benefits. Rather, an intelligent strategy to specify what data will be required in what volume at what frequency and in which format(s) is the best way forward.

[McKinsey](http://www.mckinsey.com/insights/high_tech_telecoms_internet/an_executives_guide_to_machine_learning "Machine Learning") had this to say on the subject of whom should be responsible for *marshalling data* in the organisation:

"Access to troves of useful and reliable data is required for effective machine learning, such as [IBM *Jeopardy!*-winning supercomputing cluster] Watson’s ability, in tests, to predict oncological [cancer] outcomes better than physicians or Facebook’s recent success teaching computers to identify specific human faces nearly as accurately as humans do. A true data strategy starts with identifying gaps in the data, determining the time and money required to fill those gaps, and breaking down silos [see our discussion of the ERP organisation [(take me there)](#erp_org). Too often, departments hoard information and politicize access to it—one reason some companies have created the new role of chief data officer [CDO as opposed to Chief Information Officer (CIO)] to pull together what’s required. Other elements include putting responsibility for generating data in the hands of frontline managers."

### Information Theory
This all leads to thinking about how to think about information, and for this, we need to dig a bit deeper. Here we go.

Our business dictionary defines Information Theory as: "Basic data communication theory that applies to the technical processes of encoding a signal for transmission, and provides a statistical description of the message produced by the code. It defines information as choice or entropy and treats the 'meaning' of a message (in the human sense) as irrelevant. Proposed together by the US mathematicians Claude Shannon (1916-2001) and Warren Weaver (1894-1978) in 1949, it focuses on how to transmit data most efficiently and economically, and to detect errors in its transmission and reception."

[[Interested?](http://www.businessdictionary.com/definition/information-theory.html)]

To really understand Shannon and Weaver (and a guy named Weiner), we need to look a little more deeply into the theory of information.

<a name="entropy"></a>
### Entropy and organisation and *potential* information
From another relatively old (1998) but still [excellent piece](http://www.sveiby.com/articles/Information.html), we find an introduction to the concept of *entropy*.

“In the physical sciences the entropy associated with a situation is a measure of the degree of randomness. The second law of thermodynamics states that entropy always increases in the universe. High entropy equals high level of chaos.”

Thus for decision making, entropy is the enemy. Entropy is *junk on the signal or static on the line.* It's your cell signal *breaking up*. It thwarts our efforts to make sense of a data transmission  and to translate data into information. While entropy and chaos and superfluous data provide richness in terms of the **volume** of signal being sent, they are useless in the context of seeking pointed, surgical, targeted information to answer a specific question and to guide action.

But this (rather dense – too much so to make it an [Interested?] link) article also raises some crucial points. Specifically that “The word information is derived from Latin *informare* which means "give form to". […] Most people tend to think of information as disjointed little bundles of 'facts'. In the Oxford definition of the word it is connected both to knowledge and communication. […] The way the word information is used can refer to both 'facts' in themselves and the transmission of the facts.”

The author continues. “The double notions of information as both facts and communication are also inherent in one of the foundations of information theory: cybernetics introduced by Norbert Wiener (1948). The cybernetic theory was derived from the new findings in the 1930s and 1940s regarding the role of bioelectric signals in biological systems, including the human being. The full title was: 'Cybernetics or Control and Communication in the Animal and the Machine'. Cybernetics was thus attached to biology from the beginning.

"Wiener introduces the concepts, amount of information, entropy, feedback and background noise as essential characteristics of how the human brain functions. [...] "The notion of the amount of information attaches itself very naturally to a classical notion in statistical mechanics: that of entropy. Just as the amount of information in a system is a measure of its degree of organisation, so the entropy of a system is a measure of its degree of disorganisation. [...]

Thus *entropy* = *disorganisation* = *information*. How odd. How can *dis*organisation yield more *information*? Disorganisation leaves a lot of room for interpretation. It allows for various different conclusions about the actual message or meaning of the data. The process of organising information reduces *dis*organisation in that superfluous elements (not related to a particular context, for example) are removed, yielding more targeted and focused data.

We can also easily imagine how this notion jives with our contention that systems only add value if they either reduce input or augment output. The more parsimonious we are in architecting our data for specific purposes, the less input will be required in any specific context. Thus thinking about data is important, and planning its collection, storage and retrieval is pivotal to efficiency. Think of this as a geologist would inasmuch as more pure ore makes it easier to produce steel - there is less to discard. Or the more pure and clean a cell transmission is, the better understanding of the conversation in context.

"What is information and how is it measured? Wiener defines it as a probability: One of the simplest, most unitary forms of information is the recording of choice between two equally probable simple alternatives, one or the other is bound to happen - a choice, for example, between heads and tails in the tossing of a coin. We shall call a single choice of this sort a decision. If we then ask for the amount of information in the perfectly precise measurement of a quantity known to lie between A and B [...] then the number of choices made and the consequent amount of information is infinite. [...] The quantity that we here define as amount of information is the **negative** of the quantity usually defined as entropy in similar situations." (article author’s bold)

The author continues: "Information is from its conception attached to issues of decisions, communication and control, by Wiener. System theorists build further on this concept and see information as something that is used by a mechanism or organism, a system which is seen as a 'black box', for steering the system towards a predefined goal. The goal is compared with the actual performance and signals are sent back to the sender if the performance deviates from the norm. This concept of negative feedback has proven to be a powerful tool in most control mechanisms, relays etc."

I will now muddy the already turbid water by introducing an opposing viewpoint, that of Claude Shannon, an eminent information scientist working at AT&T (the US telephone people) in the 1950s. The author writes:

"The other scientist connected with information theory is Claude Shannon. He was a contemporary of Wiener and as an AT&T mathematician he was primarily interested in the limitations of a channel in transferring signals and the cost of information transfer via a telephone line. He developed a mathematical theory for such communication in *The Mathematical Theory of Communication*, (Shannon & Weaver 1959). Shannon defines information as a purely quantitative measure of communicative exchanges."

So Shannon wasn't interested in *what* was communicated as much as he was in the *volume* or *occurrence* of communication. It's not *what* for him, but *that*. The author continues:

"[...] based on Shannon it does not matter whether we are communicating a fact, a judgment or just nonsense. Everything we transmit over a telephone line is 'information'. The message 'I feel fine' is information, but 'ff eeI efni' is an equal amount of information."

Note that the message (we cannot say the 'intended message' as we do not know the intention of the sender when sending it) 'I feel fine' is *almost* an anagram of the gibberish 'ff eeI efni' (one too many 'f' and no 'l'), but there may be other possible combinations of letters and spaces that would yield other equally viable messages *in this context*. For Shannon there is information richness in this disorganisation. The potential for many messages means there is more raw information in the message. As we will see, for business, this isn't a good thing.

In Shannon's defence, the author goes on to write that "Shannon is said to have been unhappy with the word 'information' in his theory. He was advised to use the word 'entropy' instead, but entropy was a concept too difficult to communicate so he remained with the word. Since his theory concerns only transmission of signals, Langefors (1968) suggested that a better term for Shannon’s information theory would therefore perhaps be 'signal transmission theory'."

But we have a problem here. How can one theorist describe information as *organisation* and another describe it as *disorganisation*? The article continues with:

“Weaver, explaining Shannon’s theory in the same book: Information is a measure of one’s freedom of choice in selecting a message. The greater this freedom of choice, the greater the information, the greater is the uncertainty that the message actually selected is some particular one. Greater freedom of choice, greater uncertainty, greater information go hand in hand.”

Here comes the contradiction...

“There is thus one large - and confusing - difference between Shannon and Wiener. Whereas Wiener sees information as negative entropy, i.e. a 'structured piece of the world', Shannon's information is the same as (positive) entropy. This makes Shannon's ‘information’ the opposite of Wiener's ‘information’."

For Shannon, the content of a message (which he calls *information* but which I call *potential* information or simply *data*) is a function of volume. The bigger the message, the greater the information content. Shannon was a telephone company engineer, interested only in *that* a message was sent and not *what* message was sent. Shannon did not care *what* people were talking about on the phone but only *that* they were talking. The volume of data transmitted was more important than the actual content.

And this makes sense if you think about it, from the point of view of a telephone conversation. Imagine you are in a phone call. In the background, you have music playing loudly enough for the other party to hear. While the music is not part of the conversation, *per se*, it becomes an element of the message being sent from you to the other party. It’s background and contributes to the richness of the signal.

But that music does *not* contribute to the clarity of the conversation. Music is competition for understanding the spoken word.

Thus for Shannon, the more *entropy* (disorder – as in background music), the more disorganisation (lack of focus) and therefore the more *potential* interpretations could be made as a result of the message. If the background music was too loud, for example, the *intended message* might become garbled or unintelligible. This is not helpful for us in business, where we rely on *targeted* almost *surgical* messaging in order to make decisions that result in positive outcomes. This is especially true in information systems, where *interpretation* is not a particularly strong suit of software. Systems are rules based for the most part. They don't interpret well. Yet.

Weiner, on the other hand, saw information as *negative entropy*, or positive organisation with structure, interpretability, less equivocation and noise and more certainty. This is the kind of message that business communication requires. Straightforward and to the point. No guessing about the information content of a data stream. *Less input for a given output.*

Entropy is the friend of *information volume* but the enemy of good *decision making*. In business, we need to keep the junk off the signal. Entropy is to be avoided. Structure is valued. Clean communication is the goal. Understanding is critical.

Thus Weiner is our man. We care both *that* messaging is occurring and *what* is being messaged. But Shannon was an inspiring academic. You’ll see reference to him in the section on ASCII.

[Interested?]( http://www.kerryr.net/pioneers/shannon.htm)

### The five faces of information
Below is an infographic of sorts, showing the five faces of information. The faces and their characteristics are from a (highly recommended) 2012 book by Joel Katz entitled *Designing Information: Human factor and common sense in design* (2012, John Wiley & Sons).

**Figure FFI. the five faces of information**

![Nature of information](https://raw.githubusercontent.com/robertriordan/2400/master/Images/nature_of_info.png)

I have arranged Katz’s five types into three groups, then ranked them in terms of their importance to us as students of business, but moreover, added a column delineating the approach taken by ICT to the challenge of how to deal with each group. Let’s begin at the bottom, and explain each in turn.

As we walk our way up the scale, consider the context to be that our organisation is examining the results of an online poll asking visitors to a third-party website to rate the various products in our industry (let’s say it’s the toothpaste segment of the dental hygiene industry just to put a face on it). The results have been summarised by the polling firm and released at a press conference sponsored by one of our biggest competitors. This could be damaging to us. The opinions of visitor’s to the website have been measured with the online survey and the raw data have been contextualised by the polling firm and, worst of all, our competitor has provided their own spin.

Though the data have been transformed into information in the context of our competitor’s survey and the analysis by the polling firm, for us, it’s still raw data. In order to make a decision whether to act on the release of the data, we need to put it in our own unique context. The data are inbound per Figure LJLJ.

We need to contextualise the input data in order to create information sufficient to decide on an action. Here we go, starting from the bottom of the taxonomy.

#### Non-information
Non-information is described by Katz as being possibly true (thus perhaps untrue), probably unimportant (perhaps we can ignore it) and/or possibly confusing (not well enough explained or contextualised to allow understanding). The ICT approach is likely to monitor and filter. If the information is deemed to be of no impact, the ICT response could be to filter it out and remove it from consideration by our company. If deemed potentially relevant, we might conclude that the survey information passes the non-information test, thus we retain it and move up the ladder. Our organisation might have a simple system in place to monitor electronic news services and social media flows looking for keywords (our organisation’s name for example, and perhaps negative and positive words in the context). Such monitoring might allow the system to decide whether to move the status of the news item up the scale to alert. News items that fail to meet a minimum criteria would likely be filtered out and not subject to further scrutiny.

#### Un-information
Next up is un-information as we move into the orange zone of importance. This is a curious category indeed, but information here is more important (potentially more impactful) than is non-information. It’s slightly up the *fudge scale* in terms of perceived truth, going from only ‘possibly true’ to ‘probably not untrue’ -- talk about a fine distinction! It remains probably unimportant, but has moved up the scale from confusing to possibly interesting. We have then, in this situation, some input data that is at least potentially interesting to us. The ICT response might be to alert the firm to the existence and location of the information, and wait for a knowledge worker to decide whether the information warrants escalation or disposal.

Assuming the knowledge worker decided on escalation, a further determination is necessary in order to decide on a response. We need to go up another rung on the ladder into the critical red zone. This is where context and information become critical.

#### Disinformation
The first category in the red zone is ‘disinformation’, which Katz characterised as *deliberately not true* and very likely used tactically to intentionally mislead those consuming it. This information might well have been fabricated by our competitor to cast us in a bad light. This activity might even be illegal (libelous), and could be quite damaging to our reputation. In this context, we will want to take some action to protect ourselves. An ICT response could be to provide data to counter the disinformation and disseminate it to our stakeholders in order to protect ourselves from damage.

Indeed, news organisations are continuously on the lookout for potentially damaging posts in the *Comments* section following many news stories (in fact, many online news publications have abandoned comments altogether owing to the near impossibility of monitoring and moderating them). The *Toronto Star*, for example, wrote the following in an editorial piece appearing on their online site on July 23, 2015, regarding such comment sections:

"Our moderation team spends the bulk of its time working on limiting the worst of the worst: racism, threats and personal attacks. This is done with help from readers who flag comments they deem out of line with our community guidelines and *software that scans for keywords we have identified as sensitive, and moves those comments to a ‘disabled’ queue until an editor can read them.*" [*emphasis* added]

#### Misinformation
If analysis determines that the information released by our competitor is not deliberately untrue, it might well be ‘misinformation’, described as definitely not true and important to avoid, in the sense that if the information were considered to be true (where it is, in fact, *untrue*) any actions taken under the erroneous belief that it *is* true would be inappropriate in the least and damaging at worst. This information is toxic and needs to be corrected before inappropriate action is taken by some party believing it to be true. Some party such as our customers! The ICT response could be to provide true information to counter the false assertions, which could be provided to our customers through various actions (email, Twitter, Facebook, etc.) made possible by stored electronic customer service records with contact information.

#### Information
If the information is deemed to be not untrue (*ergo*, it’s true) then we move to the last level in the scale: information. If we make it up to this level, we know that the information released at the press conference is deemed to contain a true representation of our customers’ opinions of our products and, if released by our competitor, the results must be saying either something bad about us or something good about them. Whichever, the information is true and action must be taken to deal with the fallout. Several ICT strategies are possible, including targeted information campaigns designed to bolster our reputation and/or discredit the competition.

##Contextualisation and the role of ICT
We can now provide a little more depth in terms of contextualisation and the role of ICT in the process. Examine Figure LLJJ below. It’s the same figure as LJLJ above, but with the ICT contributions overlaid on each element.

**Figure LLJJ. Context with ICT contribution**

![ICT context](https://raw.githubusercontent.com/robertriordan/2400/master/Images/ict_context.png)

### System input
As our discussion moves from left to right in Figure LLJJ, each area is marked with a numbered black box for easier reference.

We begin on the input end of the context system, and we begin pre-data, with measurement. **This is Area 1.** ICT provides several critical functions in terms of data measurement, beginning at the very basic level of *sensing*. ICT systems are deployed in a myriad of situations as sensors, simply sitting quietly and waiting for something to happen. Sensing a phenomenon is often akin to measuring it – a photon of light passing through a pane of glass, for example, causes a count of photons to tick up by one. An RFID (Radio Frequency Identification) system on a gas pump continuously broadcasts its presence, waiting for a customer’s matching key fob transmitter to spring to life in response to the signal. Then all kinds of commerce can happen. Sensors are everywhere from parking lots to soft drink dispensers and from washrooms to smart phones. And more and more sensors are being deployed all the time. We will return to this topic a number of times as we move forward.

[Interested in measurement?]( http://en.wikipedia.org/wiki/Measurement)

ICT can of course measure things independent of sensing. A scale on the highway measures truck weight in the same way a bathroom scale measures our own weight, minus the incessant upward bias that shows our weight as impossibly and erroneously heavy… oops. Did I say that out loud? A radar gun measures speed. An elevator measures weight and will refuse to close its doors if overloaded. An accelerometer measures the speed of your finger swipe on a tablet computer in order to calibrate the throwing of a lance at an invading barbarian to protect your virtual village from attack. All are measurement devices. In performing this function, ICT systems must be engineered to respect the most critical tenet of measurement: *accuracy* and its constituents, *trueness* and *precision*, and including *reproducibility*. Once measured, the same data must yield the same results using the same technique. This is sometimes referred to as *reliability*. We discussed these things in Chapter 1 [(take me there)](#measurement).

**On to Area 2**. Note also that the infographic implies that a lot of data just *fly right by* the system. This is true in two ways. First, data that has no known bearing on the current context has no value in this system. Data about vehicle fuel efficiency, no matter how accurate and reliable, simply cannot add to the context of a decision about the marketing of disposable diapers, for example (though both involve tailpipe emissions). It’s simply not in the domain. So this data flies right by.

Next, however, is a more important aspect. There is simply so much data being generated every micro-second (5 Exabytes every two days according to Google chairman Eric Schmidt though this is contentious... [Interested?](http://techcrunch.com/2010/08/04/schmidt-data/)) that it’s impossible to capture it all in either it’s incredible volume or to process it in a timely manner before it becomes stale, so vast is the big data cloud. But what’s important is to capture an optimal amount in order to create the richest context and thus the most informed information, leading to the most accurate decisions about a course of action.

**Figure BGJ. Data generation**

![How much data is out there?](https://raw.githubusercontent.com/robertriordan/2400/master/Images/schmidt.png)

This leads to the next contribution of ICT to the area of decision making and knowledge acquisition, that of dealing with the data itself. ICT systems can act as data filters, enforcing rules about relevancy, domain, accuracy, freshness and reliability. Data can be fed through systems and sorted, filtered, combined and then stored for later use. When required, systems can assemble and package data into usable formats (a spreadsheet format for example) and can then send them on their way to other systems for analysis (via network file sharing or even email). This is referred to as *marshalling*. At a low level, operating systems support marshalling through file management. Allowing us to store data under a single name in a place in either short- or long-term memory. In a very real way, data marshalling is like railway marshalling, where huge networks of track are used to *assemble* trains. Much like at the rail yard, ICT can store, slice and dice and then assemble and transport data. A one-stop shop for management.

**Photo TTA. A railway marshalling yard in Germany**

![How much data is out there?](https://raw.githubusercontent.com/robertriordan/2400/master/Images/trainyard.jpg)

*Photo credit: http://d1.stern.de/bilder/stern_5/fotografie/2014/KW44/bahn_von_oben/bahn-von-oben-06_maxsize_2048_1536.jpg*


This can be understood in terms of the input/output dichotomy in a variety of ways. Can ICT reduce the amount of input required to produce a given output? Yes, in many situations. Even simple filtering and sorting, arranging and, in true Weiner fashion, reducing the uncertainty around input data, can contribute to more streamlined and efficient processes and thus satisfy the *less input* tenet of our contribution rule.

Moving to the area at the boundary between input and processing, we enter one of the most crucial and hot areas in ICT: *context and information creation*. We’ve spent some considerable time talking about context and information in context, so all we need here is to elaborate on how ICT contributes to and supports the activities in this area. **This is Area 3.**

ICT helps to contextualise a decision through providing measured data to contribute to the richness of the solution space. ICT can accomplish this in a number of ways, and not just the traditional method of storing and marshaling legacy data (such as spreadsheet data of last year’s sales, for example), but by providing real-time, synchronous data *representing the current situation*. Things such as identity authentication (allowing you to be in a certain place at a certain time based on either what you have – such as a password or a fingerprint – or what know, such as a password). Your location in time and space can be known and broadcast.

And if it can be done for you, it can be done for others. Thus random gatherings of persons in a particular place and time can be sensed and utilised in assembling a context. Even simple things such as GPS and cell tower triangulation can locate you and others. This can facilitate all sorts of crowd-related things such as pop-up retail, policing and research into facility location. It’s also how things such as geo-fencing are accomplished. Geo-fencing has been in the spotlight lately with the use (and abuse) of a little app named *Yik-Yak*.

[Interested?]( http://whatis.techtarget.com/definition/geofencing)

In this way, ICT can produce better or more output from the same input as the rich contextualisation of the decision space around *what's happening here?* leads to a more informed (better quality) decision from the same amount of input data.

ICT can not only use and broadcast your location, it can also sense activity – *what* you’re doing. If your location puts you on the a highway, ICT can make a reasonable guess about what you’re doing, and the error around deciding what it might be can be reduced by examining (measuring) your velocity, for example. Insurance firms are increasingly using voluntary sensors to monitor your driving habits and providing insurance at a lower premium for "good" drivers.

[Interested?](http://www.ecommercetimes.com/story/75600.html)

Systems can sense and determine lots of activity in which you might be engaged. It can therefore authorise you, based on location, time and activity, to perform certain tasks, such as allow you access to a secure facility or to take possession of rental materials or even rental vehicles. Unattended attendants. How cool. And way fewer resources are required to get those rental materials to you. More output for the same input. *Bingo*.

Finally (but by no means exhaustively), ICT can contextualise your activities based on your or others’ previous pattern of activity at a time and place. A system might also make some reasonable guesses (though systems don’t guess things, rather they use rules at best and probability at least) about what you are likely to do *next* and anticipate and allow you to discover available services in your vicinity that are appropriate and appealing to you. Walking through the park? Ever rented a canoe to go paddling in the pond? How about a little text message on your phone from Joe’s Canoe Rental? This stuff, called *m-commerce* facilitated by *location services*, is popping up all over. And we’ve just scratched the surface. Mobile payment options now allow commerce between two parties with just cellphones, *disintermediating* financial institutions altogether.

[Interested?](https://en.wikipedia.org/wiki/Mobile_commerce)

Note that a considerable part of this data that is brought to bear on a context has no direct relationship to the problem or challenge itself, *per se.* The decision space around a firm’s advertising spend this year would contain plenty of direct information, such as the firm’s liquidity position, sales figures, cost to advertise in various markets, customer demographics, competitor’s spend, etc. But there are plenty of other, more *contextual* variables that come into play. Things such as the firm’s mission and vision, ethics, brand value, consumer tastes and trends, strategy, resource capabilities and others. All of these things play into the decision but some are less, shall we say, tangible? These things provide context and they are the things at which ICT hasn’t been as good, historically.

But we are on the verge of a change. Context is *the single biggest thing happening in ICT today*. The proliferation of sensors, so tiny and innocuous, is facilitating measurement at such a fine scale and with such sensitivity that soon we’ll have what one author referred to as *liquid information* (see below). Context is so compelling, let’s take a few more minutes with it.

<a name="digital"></a>
###Digital vs. Analog
The distinction between the concepts of *analog* and *digital* is important here. The difference between them is akin to the difference between an integer (whole) number and a real number (with decimal precision of varying degrees). Analog is the *real numbers* of nature. Analog is the subtle curve and continuous and apparently seamless change we witness all around us; so subtle that sometimes it’s impossible to tell where one thing ends and another begins.

Consider colour. In Figure ECC below, we see colour represented in two different ways, as discrete swatches representing the ROYGBIV colours of the rainbow and then, below that, as a continuum of those visible colours.

**Figure ECC. Illustrating the difference between analog and digital**

![Analog and digital](https://raw.githubusercontent.com/robertriordan/2400/master/Images/analog_digital.png)

We can (most of us – some people suffer with some form of colour blindness [Interested?]( http://www.colourblindawareness.org/colour-blindness/types-of-colour-blindness/)) easily discern the difference between red and orange, or orange and yellow from among the boxes in the top row of the figure. And we could equally easily point to a green region or a blue region in the continuous strip of colour beneath. The challenge becomes specifying the point at which yellow becomes green, or exactly where indigo becomes violet. Try and pinpoint the exact location where yellow disappears and becomes green as we move left to right. The continuous nature of the colour strip makes it difficult to nail anything down, in fact.

The colours in the upper box are represented using a specific method of reproducing colour called the RGB method, standing for Red, Green, Blue, two of the three primary colours. All colours, using this method, are produced as a function of mixing more or less of each of these three on a scale from 0 to 255. So the RGB for the colour red is 255, 0, 0. The maximum red (255) and no green or blue. Green is 0, 255, 0 and blue, 0, 0, 255. Of course there are plenty of shades and hues between these values, and indigo and violet off the right end of the spectrum are entities unto themselves.

It doesn’t matter to us how this or other colour representation methods (such as CMYK, Pantone, etc.) actually work. What matters is that the continuous colour scale represented by the visible spectrum of the rainbow can be *sampled* and *digitised* such that we can work with it in a discrete way. The RGB scale itself produces tints and shades between which the naked eye could not discern. I challenge you to distinguish an RGB of 255, 0, 0 from 254, 0, 0. It would take an expensive display device to even produce and display an image capable of allowing us to discern that difference – but our eyes must be able to work at that level of precision. The message being, at some point or at some resolution, a digital representation becomes just as good as an analog one. It’s just as good because *we can’t tell the difference*. I’m not saying *better* or more *natural* but rather *just as good* for certain purposes. Take a look at Figure JP below.

**Figure JP. Subtle differences in RGB**

![Can you tell the difference?](https://raw.githubusercontent.com/robertriordan/2400/master/Images/rgb.png)

The four reds are, for certain, red. The normally-sighted would have no trouble identifying each and all as being of the colour red from among the other colours of the visible spectrum. But the differences within the range of red are more difficult to detect. The leftmost (labeled 255) is the same red as in Figure ECC. I have altered the amount of red first from the max to 254, then to 245 and then to 225. The difference between 255 and 254 is so slight that it is nearly impossible to detect at the resolution of that figure on any of my devices or monitors with my eyes (such as they are). *Perhaps a slightly darker tint?* We begin to see a subtle but discernible difference at 245 (a clearly darker tint) while the difference at 225 is quite noticeable. For some purposes, a specific red of a specific hue might be required. For the vast majority of others, any of these reds will do. We would all stop at a traffic light if it showed any of these reds. And that’s the point.

Imagine now, sensing the difference between an RGB value of 255, 0, 0 and 254.5460274, 0, 0. Only in the most exacting and demanding of scientific or engineering contexts would such a difference be important (you see the use of *context* here as a *situation* in which certain things, such as precision, are critical). In 99.999999999999999% of cases where the two were compared, it would make no difference. We can *model* the analog nature of nature and get a *good enough* representation on a digital scale. Hang on.

This concept is akin to *granularity*, and we will be introduced to it shortly.

I’m hoping that by this point you are starting to see the light. The point being that computers represent everything as a series and a combination of binary digits (bits) and the more bits that can be dedicated to modelling something, the more information can be carried and the finer and finer can be the distinction between discrete elements. So fine, with such massive computing power as we now have, that eventually the binary representation of things becomes so rich, so fluid, that we can no longer tell the difference between the *real thing* and the binary/digital representation of it such that, well, it doesn’t matter at all. Witness Apple’s *retina display* which Apple claims to be so close to analog that our retinae are incapable of discerning anything finer. We can’t tell the difference.

And what self-respecting chapter on this topic would be complete without a reference to the Keanu Reeves / Lawrence Fishburne epic movie series *The Matrix*, first released in 1999, written and directed by The Wachowski Brothers?

[Wikipedia Interested?]( http://en.wikipedia.org/wiki/The*Matrix) and/or [IMDB Interested?](http://www.imdb.com/title/tt0133093/?ref*=nv*sr*1)

And just to throw a wrench into the works, the notion of human *spirit* and a *soul* play large in this debate. If everything analog can ultimately be represented by a series of bits to the point where we can’t tell the difference, then are people simply huge binary machines, as are computers, made up of such minute and many binary objects that we simply can’t *yet* detect and measure them? Is the analog nature of nature just digital at such a fine level of precision that we simply haven’t seen it yet?  Take a biochemistry course. Take philosophy courses. Everyone should. You aren’t complete without them. The truth is out there ;)

**Time for an [XKCD](http://xkcd.com/1519/ "XKCD Venus").**

![](http://imgs.xkcd.com/comics/venus.png)

<a name="liquid"></a>
### Liquidity...

Let’s bring this home. A very old but again ever-so-interesting site (www.liquidinformation.org) has [this](http://www.liquidinformation.org/ana_digi_liqui.html) much to offer on the apparently spurious distinction between digital and analog as it pertains to ICT.

First some definitions:

*Analog*: A mechanism in which data is represented by continuously variable physical quantities.

*Digital*: Of or relating to the fingers or toes. Using calculation by numerical methods or by discrete units.

*Liquid*: Flowing freely like water. Having the properties of a liquid: being neither solid nor gaseous. Smooth and unconstrained in movement.

The article offers that “We have been brought up to believe that there is a total distinction, a wall of separation between digital and analog: The world is smooth and continuous; analog whereas computers are operating on discrete, black & white separate units; they are digital. And the twain shall never meet.

The author writes: “Well you know, it just ain't so. Imagine a couple of small grains of sand. Digital, separate, discrete. Now add a couple more. And a couple more. Millions more. Billions. And you have a beach. An analog, a smooth continuous environment. [sic]

“Everyday home and office computers, with capacities to manipulate literally billions of bits literally billions of times a second […] have gone the way of the grains of sand and are definitively not just digital anymore. And they have the potential to become more than analog. They have the potential to become, and make us, liquid.”

So the question for us is: At what point does digital become analog? At what point (threshold) does it matter to us? At what point can we detect? What resolution is important for us? This is akin to decimal place precision. How many decimals is it necessary to report in a table of financial ratios, for example, before the additional digit becomes meaningless? Think about this. Especially the Accountants and Finance people among you. How may decimal places, how much precision, is necessary? When is it *good enough*?


#### Just-noticeable differences and your brain on music
This introduces the notion of *Just-noticeable Difference* or JND. And of course a just-noticeable difference is context dependent (isn’t everything?). The message, again, is that at some point in the digitisation of analog phenomena, the distinction disappears and we can’t tell the difference. JND has applications in many areas, not the least of which is marketing, where intensive research has been done into how much a product can shrink, for example, before potential buyers notice a change in package size.

[Interested in Marketing?](http://www.scoop.it/t/psychology-of-consumer-behaviour/?tag=Just+Noticeable+Difference)

[Interested in Weber's Law of JND?](http://apps.usd.edu/coglab/WebersLaw.html)

[Interested in the Weber-Fechner Law of JND?](http://en.wikipedia.org/wiki/Just-noticeable_difference)

I’m reading a few books as I am writing this text. One that is particularly interesting to me is entitled *This is Your Brain on Music: The Science of a Human Obsession* by McGill neuroscientist and musician Daniel Levitin (2006, Penguin). He writes: “Less well known are the extraordinary advances we have been able to make in modeling how our neurons work, thanks to the continuing revolution in computer technology. We are coming to understand computational systems in our head like never before.” He continues that “Even consciousness itself is no longer shrouded in a mystical fog, but rather is something that emerges from observable physical systems.”

But what’s more interesting for us is the parallel he draws between sound and sight. Consider a motion picture. In case you didn’t know, a movie is made up of a series of still photos interspersed with black screens. When shown at the right speed, however, our visual system can’t tell that it’s a series of stills. Here’s what Levitin writes: “The lowest note on a standard piano vibrates with a frequency of 27.5 Hz. Interestingly, this is about the same rate of motion that constitutes an important threshold in visual perception. [...] ‘Motion pictures’ are a sequence of still images alternating with pieces of black film presented at a rate (one forty-eighth of a second) that exceeds the temporal receiving property of the human visual system. We perceive smooth, continuous motion when in fact there is no such thing actually being shown to us.”  So motion pictures are *just as good* as the real thing for us. Next time you're out on the road, take a look at the wheels of vehicles as they pass on the street. Note that for many, it appears as if you can see the disk brakes behind the wheels as if there were almost no rims at all. Our eyes can't keep up with the spinning speed and our brain can't paint the picture for us, rather just showing us that there's nothing there. But we know different.

Finally, just for fun...

**Figure WWE. The *wagon wheel effect***

![ICT context](https://raw.githubusercontent.com/robertriordan/2400/master/Images/WagonWheelEffect.gif)

The Wagon wheel effect is often seen in old Western movies where the wheels of a horse-drawn carriage sometimes appear to either be frozen or to be rotating counter to the direction in which the wagon is moving. This animated GIF illustrates the phenomenon. The speed of the "camera", moving towards the right, constantly increases at the same rate with the objects sliding to the left. Halfway through the 24-second loop, the objects appear to suddenly shift and head backwards.

*Credit: "WagonWheelEffect" by Ulillillia at the English language Wikipedia. Licensed under CC BY-SA 3.0 via Wikimedia Commons - https://commons.wikimedia.org/wiki/File:WagonWheelEffect.gif#/media/File:WagonWheelEffect.gif*

[Interested?](https://en.wikipedia.org/wiki/Wagon-wheel_effect)

We might also want to consider the concept of *resolution*. The resolution of a sensor is the smallest change it can detect in the quantity that it is measuring. Sensor resolution is being continuously improving.

[Interested?](http://en.wikipedia.org/wiki/Sensor)

Why matters all of this? It matters because as systems and sensors proliferate and their ability to communication improves, their ability to measure with more and more precision in more and more places at lower and lower resolutions at increasing rates of speed provides a richer and richer stream of input data to flow into and to generate our contexts. And that’s how decisions get made. As ICT is increasingly able to provide more and more context, machines are more and more able to work at a resolution level that is not only *good enough* for most situations, but maybe better than we humans can do... And with such great context, better and better information is generated and more and more decisions can be made for us by machines far below our level of consciousness. We'll be the spinning wheels. So fast, we can't see it happen.

Returning to our ICT Context discussion, we need to talk about Information and what ICT can do for and with the creation of information out of data in context.  So back we go to Figure LLJJ.

We continue our explanation of this figure at the point where we left off. We now consider the role played by ICT in the creation of information in the context (the confluence of contemporaneous activity = all the other $hit going on at the same time) in which we find the facts = measured data. **This is Area 4**. Given all that is going on at the same time, we need to focus on the available data, decide whether it is applicable, usable, reliable, up-to-date, etc., then create information out of the data (remember that information is actionable whereas data is not) and decide whether to act or not and if so, how to act. All this is about decision making. Recall also that we need the optimal amount of data in the context in order to create the optimal information and inform our subsequent decisions. This is a lot to swallow all at once, but people do it all the time, and organisations are expected to do it in a timely, rational, inclusive, profitable, equitable, respectful, mindful and repeatable way. It’s no mean feat.

ICT can help with this process by effecting data analysis, by synthesising (blending and amalgamating existing data and previous information pertinent to the task at hand) and by creating information (linking context to data). Information, once created, can be managed, stored, transported and reported upon by various ICT systems. It is functionally impossible for organisations to do even one of these tasks efficiently, given the volume of information while respecting the time constraints within which decisions must be made, without the substantial assistance of machines and systems. It’s simply impossible to keep up.

### Where the magic happens
Beyond analysis and synthesis of existing data and information in context, ICT also *creates* information in context. **This is perhaps the most critical role of ICT in the entire process of knowledge acquisition.** *This is where the magic happens*. This is the confluence of fact and circumstance and measurement and existing knowledge coming together to produce an understanding, at some level, of the decision space. An understanding of the problem or challenge and of the circumstance surrounding it such that a decision can be formulated out of the new information created in the new unique context that is this moment in space and time. This is the way forward.

I know this sounds eerily sci-fi or even spiritual. Not so. It’s something that we humans do continuously without even being aware of it. Machines do it also, but not as well as we. Yet. We are at the frontier of machines being able to recognise the boundaries of context. Able to ascertain what’s in and what’s out of scope. Creating information that bears on the problem and the solution space. Making sense of data in that context. This is to where ICT is going. We need to go along for the ride. *We need to keep up with technology or it will overtake our ability to realise value from its work.*

All the tools are available and in the public domain. The infrastructure already exists for a rapid and radical alteration of the computing landscape. In a recent issue of *The Economist* I read the following paragraph in an article entitled *Who's afraid of America?* on the subject of weapons technology: "The large lead that America enjoyed then [1980s] has dwindled. Although the Pentagon has greatly refined and improved the technologies [... they] have also proliferated and become far cheaper. Colossal computational power, rapid data processing, sophisticated sensors and bandwidth [...] are now widely available."  (The Economist, Volume 415, Number 8942, June 13th-19th 2015.) It's all out there and being leveraged for value creation.

When the information is created within the context, ICT can then assist in the more mundane activities of filtering for relevancy (as we have seen in our discussion of the functions of ICT in the management of information, misinformation, etc.), marshalling, managing, transporting, and reporting on it to various functions within the organisation (or just to us, as users, if it’s a local bit of information such as how many Tweets you issued in the past 24 hours – this is information and 67 TPD (tweets per day) is a report of that information to you).

Let's bring back Figure LLJJ for a refresher.

**Figure LLJJ. Context with ICT contribution**

![ICT context](https://raw.githubusercontent.com/robertriordan/2400/master/Images/ict_context.png)

Moving on, we next tackle the role of technology in making decisions (not acting on decisions just yet) but in *making* decisions. **This is Area 5**. How about a few simple examples of machines making decisions for us?

Consider the heating and cooling systems we enjoy in our homes, vehicles, places of work and public spaces. They constantly monitor the ambient temperature and turn on and off to match some parameters we set (such as desired temperature). Next consider red-light traffic cameras - an entirely automated process from flash to cash. Then think of active all-wheel drive in a vehicle, constantly monitoring the wheel rotations on all four corners of the vehicle and adjusting the amount of torque sent to the wheel to compensate for slippage. Then think of cruise control and self-parking cars and adaptive volume levels in sound systems and the list goes on. All decisions made for us with no input other than, at times, setting some default values. Such decisions are made constantly and far beneath our consciousness or our ability to do the same. Imagine we drivers having to take over for an adaptive all-wheel drive system and manually making a thousand adjustments per second. Impossible.

Thinking just about self-parking cars will help to cement the notion of *context* when you realise that this activity is all about context and almost nothing else. The context includes determining if the space is large enough to accommodate the parking vehicle, and then about exactly where in space the obstacles are (cars in front and/or behind) as well as location of the curb (if present), road conditions, ambient light, speed of approach, arc of attack and a myriad of other variables that describe the solution space for parking. Data is turned into information and then action. Context, in parking, is everything.

ICT can both make decisions and *act on them*. **This is Area 6.** ICT can also record and store the conditions leading to the decision, what decision was made, and the context of the decision – such as the current thermometer reading and time/date when a decision to heat your home was made. In addition, ICT can report all this information to anyone or any system that requires it for whatever purpose. Moreover, is can *combine* such information with sensor data indicating who and how many people are in the room, the season, the external temperature, the lighting conditions, the relative humidity, the time of day and a myriad of other usage data that just flies by in our homes every second we are there. This is the genesis for the *Net* system, bought by Google in early 2014 for $3.2B USD.

[Interested?](https://nest.com/ca/)

ICT can also execute decisions (take action) as a consequence of human intervention (we can decide to send an email, for example, and the machine will do our bidding). When executing, it can record and store the context of the execution action as well as monitoring and policing its own actions and provide an audit of its activities - such as adherence to policies, for example. Everything about your email is recorded in multiple places.

Moving to the right in Figure LLJJ, we encounter the work of ICT in sensing and storing the results of the actions executed by human and beast. **This is Area 7.** In this realm, ICT can both sense the results of actions and store those results for further analysis. At any juncture, as with any other activity undertaken by ICT, systems can report on their activities. To whom they report is a critical aspect of privacy. We will deal with this elsewhere in this manuscript.

Moving again to the right in Figure LLJJ, we again encounter the impact of ICT on the Data and Information entities. **This is Area 8 and 9.** Here the actions and impacts are the same as in our previous discussion of data and information so we won’t belabour them again here.

We come finally to the Knowledge component of Figure LLJJ. **This is Area 10.** Here we find the culmination of the process of acquiring knowledge from measurement of data and represents the ultimate human activity – the creation of order and reason out of action. ICT assists in many of the components of this activity, beginning with analysis of the stream of information emanating from the process. ICT can analyse existing knowledge as well as synthesise new and existing knowledge into unique nuggets of new information. Then it can manage, store and report on such knowledge.

Maybe give some examples here?

We next tackle the feedback piece and talk about the synthesis of new with existing knowledge and how it washes back over new and unique contexts to become input to the next set of decisions.

## The big picture of the organisation ##

We now come to the bigger picture of where data, information, decision, action and knowledge fit in the context of the organisation. The result is the rather busy and complex-looking Figure JL (here titled simply *The big picture* to save some space but with the working title of "The measurement to  knowledge continuum with associated indices, system types and spans, and organisational correlates"). This figure encapsulates the thinking of many who have gone before in the study of ICT and brings an order to the various insights about *how things fit* in the modern organisation. Bear in mind that the analysis and conclusions conveyed by this Figure are based on the author's experience and accumulated *tacit knowledge* of the field. There is no empirical evidence of which I am aware that would give an exact number of how many machine decisions versus human decisions are made. With that *caveat* in mind, let's take a look at it piece by piece.

**Figure JL. The big picture**

![The big picture of the organisation](https://raw.githubusercontent.com/robertriordan/2400/master/Images/big_picture.png)

### Type of work and who’s doing it
Let’s begin at the left of this Figure, and consider the “Type of work and done by” column. We start at the bottom, left corner of the figure, with the colour-coded Machine / Human distinction. The things above it are all activities performed in all organisations on a regular basis (Measurement, data collection/storage, etc.). Most of these activities we have seen before from examining Figure LLJJ in depth. The leftmost column seeks to inform regarding the relative contribution of human versus machine in the execution of the task activities stacked up on this dimension. The more yellow the activity box, the more humans are the nexus of activity in this particular domain. Conversely, the more black, the more machines are the ones doing the work in this domain.

We begin at the bottom, considering the activity of *Measurement*. The predominance of black in the yellow/black saturation indicates that most measurement is effected by machines. There is simply so much measurement to be done that it’s impossible for humans to do it. Sensors shoulder the majority of the load in this activity. There are just so many sensors measuring so much data that it’s impossible to even quantify the volume of data measurement going on. The volume is truly mind-boggling with, as we know, the data equivalent of 200,000 years of DVD-quality movies being generated every two days.

Next up is the activity of *Data collection and storage*. Again, the vast majority of the activity in this area is effected by machines. Almost no human activity here at all. There are countless millions of corporate, government and private databases and data warehouses holding immeasurable archives of data backed up in multiple locations. Imagine how many redundant copies of *Dropbox* data there must be in order to provide seamless availability and rock-solid failover of those often mission-critical data. If Dropbox lost data even once, their reputation would take a massive hit.

We next find *Context*, where we see the dominance of machines being reversed, with human activity taking the lead. This won’t last long however, as machines are coming to the fore in terms of providing context through the mass deployment of sensors and artificial intelligence. More later.

With context created, however, we find machines being responsible for the majority of *Information creation*. This assumes that the contexts created by humans are being turned over to machines to create the information necessary to make decisions. There is simply just so fucking much information out there that it’s impossible for humans to keep up. In order to make decisions that return value to the decision makers, it is imperative that all available and pertinent data be applied to the context around the creation of information. And that's what ICT is doing.

The notion of *bounded rationality* is pertinent here. Wikipedia offers the following:

"Bounded rationality is the idea that in decision-making, rationality of individuals is limited by the information they have, the cognitive limitations of their minds, and the finite amount of time they have to make a decision. The concept of bounded rationality [...] account[s] for the fact that perfectly rational decisions are often not feasible in practice because of the finite computational resources available for making them."

[Interested?](http://en.wikipedia.org/wiki/Bounded_rationality)

The notion of bounded rationality is rooted in the fact that humans can process only so much information in a particular time frame thus, we, as humans, actually simplify the decisions we must make because we just don't have the horsepower, time or resources to make a fully-informed decision. {See, for example, *Bounded Rationality: The Adaptive Toolbox*, Gigerenzer, Gerd and Reinhard Selten (eds.), The MIT Press,July 26, 2002.) The same is increasingly *not* true of machines. Machines can construct elaborate contexts, filter and process massive amounts of data in near real-time and come to incredibly informed decisions for extremely complex problems. Humans need no longer be constrained by limited information, resources, computational power or time in tackling many heretofore impossibly complex problems. The machines can do so much for us. Witness *The Human Genome Project* [Interested?](http://www.genome.gov/12011238) or the *Large Hadron Collider* [Interested?](http://home.web.cern.ch/about/updates/2015/03/lhc-experiments-join-forces-zoom-higgs-boson) or, in the ultimate expression of context, how about IBM's Deep Blue computer beating the world chess champion [Interested?](http://www-03.ibm.com/ibm/history/ibm100/us/en/icons/deepblue/) or IBM's Watson defeating the reigning Jeopardy champs on national TV [Interested?](http://www.techrepublic.com/article/ibm-watson-the-inside-story-of-how-the-jeopardy-winning-supercomputer-was-born-and-what-it-wants-to-do-next/).

When it comes to *Decision*, the activity is currently being done mostly by machines. But this dimension is unique. It's not a measurement of *volume* of decisions made. If that were the case, machines would win hands down. This dimension rather reflects the *importance* of the decisions made. Humans still make many of the critical and consequential decisions. We are the last resort. We always insist on *speaking to a human* when we need a critical decision made or to hear our arguments or listen to our entreaties. It's an open question whether this human/machine balance will persist. Especially with new *sharing economy* services such as Uber and Lyft ride-sharing (and others). Increasingly, a software layer is being injected between those creating the services and doing the marketing and finance (the secondary value chain activities) and the workers who are providing increasingly commodified work. So dispatch decisions for Uber cabs are done entirely by machine. All decisions are made with a maximising algorithm. While the drivers are overwhelmingly in favour of working for a machine (instead of *the man*), the bliss might be short-lived. When it comes time to cut costs, or when really cheap alternatives to human drivers come along (driverless cars, for example, which aren't far away at all) the *algorithm* might not be your friend. [Interested?](http://www.cbc.ca/radio/popup/audio/player.html?autoPlay=true&clipIds=2658630111).

Increasingly, however, machines are taking the *Action*. Machines carry out a myriad of instructions on our behalf from those we cannot do because we are simply not strong enough (think trucks and airplanes) to those we are not biologically equipped to do (think landing on Venus and sending back data for 10 years). Machines do much of our dirty, repetitive, mind-numbing and back-breaking work. And for that, we thank them.

When we get to *Knowledge*, however, it is humans who again take control of the process. But for how long? NEED MORE HERE. AI and Neural Networks, etc...

### Cost, complexity, variety and granularity
Moving to the next column to the right, we see an infographic indicating relative cost and complexity of the work at the various levels. In general, as we move up the measurement to knowledge ladder, the cost of working at each successive level increases at roughly the same rate as increases the complexity of the operations performed and the variety of data sources with which one must deal. The higher you go, the more expertise and computing power is required with a commensurate increase in cost. Nothing is free.

Moving to the next column to the right in Figure JL, we find the title Granularity. Granularity refers to the amount of data embedded or encapsulated in the information being presented at each level. At the bottom of the spectrum, we find all the Transaction data that each organisation must collect. The granular (small, tiny) detail represented on a bill of sale, for example, might include the exact product number, product model, version or revision, the exact quantity and the price charged for each. The date and time of the transaction and the ship to and bill to addresses and the salesperson responsible might also be included at this level of detail. This is a very fine level of data, much like the grains of sand on the beach to which we were alluding. This is the type of data that is measured in the bowels of the organisation. The data that the firm must collect in order to be able to account for itself.

This is the level of data where measurement occurs, where raw data are collected and stored and marshalled to provide insight and context to the higher levels of the organisation. You can't give the CEO a total sales figure for last year without a summation of the totals on all the individual sales invoices from last year. So as we move from bottom to top in an organisation, we move from very granular (grains of sand) up through small stones, through boulders to the mountains required by senior management.

There is a relationship between the Type of work done and the granularity of data required. But we mustn’t lose sight of the fact that often, once taking a look at the mountain, senior managers and executives will want to take a walk on the beach and feel the sand between their toes. Thus data must roll up to big-picture numbers, but must also persist and be available for *drill-down* exercises so that sense (read *context*) can be made of the big pictures. Data are rolled up and down with great regularity and must be available when required at the level of detail appropriate for the task at hand. And the task at hand involves problem solving at each level.

### Decisions, decisions, decisions (in the spirit of Jan Brady's *Marsha, Marsha, Marsha!*)

Problems, and the decisions that accompany them, come in three flavours: *structured, unstructured* and a hybrid, middle ground called *semi-structured*, with elements of both structured and unstructured decisions.

*Structured Decisions* are algorithmic (A x B / C) in nature where all quantities are measured and known. This leads to a verifiable result --  there is a correct answer and we can assess our answer against that standard. An example of a structured decision is the calculation of the sales tax on a purchase. There is little or no *context* involved here. Just the facts ma'am.

An *Unstructured Decision*, on the other hand, has no standard against which to measure the decision. Decisions such as whether to open a new store or launch a new product or hire a new CIO. The quality of such decisions can only be accurately assessed after the fact. Time will tell if the new store does well. This is not to say that the decision is made blind. Context provides important parameters to guide the creation of information that will lead to the decision. The important point is that there is no correct answer going forward. We can reduce error by creating a rich context and valuable information, but we can never eliminate potential error it the way we can by testing algorithms for the calculation of sales tax, for example.

The final decision type is the hybrid, *Semi-structured Decision*. Such decisions have elements of both previous types, such as would be found in an investment decision. The rate of return on an investment can be calculated in a structured fashion once the investment amount and the rate are known, but the actual rate itself is not and cannot be known in advance. Thus the decision to invest in this versus that opportunity is made without a standard against which to measure, other than the history of investments *like this one*. Again, we can reduce the error around the decision by creating a rich context (examining detailed history and doing our homework about the marketplace and anticipated trends), and the actual monetary value algorithm can easily be verified. It’s just the actual rate of return that cannot be known with precision in advance.

Note the correspondence between type of work and type of decision. Knowledge work is inherently unstructured, involving the synthesis of various sources and the exercise of judgment involving *tacit* knowledge. Tacit knowledge is differentiated from *explicit* knowledge in that the former is knowledge that comes from experience and wisdom, whereas the latter is codified, rules-based and written down. A CEO often operates on *gut instinct*. This is tacit knowledge. A transaction processing system has no gut feelings. In fact, it has no gut at all. They follow ridged rules.

#### Organisational levels - Taking the hill
In considering organisational levels, we need to talk about how stuff gets done; about what strategy is and how a strategic direction gets set and translated into actionable directives in an organisation.

The online Business Dictionary defines [Strategy](http://www.businessdictionary.com/definition/strategy.html) as:

"1.A method or plan chosen to bring about a desired future, such as achievement of a goal or solution to a problem.

2.The art and science of planning and marshalling resources for their most efficient and effective use. The term is derived from the Greek word for generalship or leading an army. See also tactics."  And we shall, *viz*.

[Tactics](http://www.businessdictionary.com/definition/tactics.html) are defined as:

"Means by which a strategy is carried out; planned and *ad hoc* activities meant to deal with the demands of the moment, and to move from one milestone to other in pursuit of the overall goal(s). In an organization, strategy is decided by the board of directors, and tactics by the department heads for implementation by the junior officers and employees."

A simple analogy is found in war.

At the highest level, strategy gets made in the smoky war rooms. General Highbottom declares: “In order to win this grand battle, we must take control of that hill!” Next comes the tactical level, which makes possible the strategic. Colonel Mittlestaff receives the strategic direction from Highbottom and declares that in order to take that hill, “We’ll need 100 soldiers and 10 tanks and 5 mortars and 3 APCs. Split the infantry soldiers into two groups. Send 50 to the back of the hill with the mortars. Bring 5 tanks in from each flank. Send 50 infantry up the hill in the APCs once the tanks and mortars have disbursed the enemy and weakened their resistance.”

Mittlestaff then pushes the tactical plan down the line to Captain Gitterdunn, who works at the operational level, at the interface with the enemy. Gitterdunn receives the tactical directives, is given access to the human and physical resources and proceeds to organise and execute the plan, with the help of subordinates such as Sergeant Spitzumfire, according to the tactical directives. The soldiers, such as Private Gruntz, are equipped, taken into battle and expected to succeed.

Gitterdunn reports at regular intervals on how the battle is progressing. In turn, Mittlestaff (who might be coordinating several different battles), informs Highbottom, who has the highest view in our scenario. Much of the *gut work* is done by Mittlestaff. Middle management has forever been under-appreciated. As we will see, this group faces a particularly dim employment future.

Take a look at Figure PP below and note especially the directional arrows for Strategy and Information:

**Figure PP. Strategy, tactics and operations – the case of taking a hill**

![Strategy](https://raw.githubusercontent.com/robertriordan/2400/master/Images/strategy.png)

You can see that information flows both ways in this scenario. From the top, the messages sent down are “Do this!” The messages pushed up from the field are “Here’s how it’s going.” Each player and level has a different view on the situation and each requires different information in order to fulfil their role. It’s the same in any organisation. Different roles require different information, and different information dictates different systems.

Et *voila*. From strategy to operation. The similarity to the situation at your own workplace is striking...

At what level of the organisation are we talking when we’re talking about knowledge and low-granularity data and unstructured decisions versus the TPS type of data and decision? Let’s start at the bottom of Figure JL in the *Decision type* column.

Measurement and data collection/storage are TPS responsibilities, and TPS deal with highly granular data; the TPS is on the beach. Such data are suited to structured decisions. There are no nuances or shades of meaning or complicated contexts to navigate. It’s black and white. This is the *shop floor* area. The showroom, the warehouse, the factory. The staff here are concerned with the very nuts and bolts of the organisation and require systems that are unambiguous, straightforward and next to fool-proof. They must be fast and efficient and they must work as advertised. This is the *operational level* of the organisation. But make no mistake; the data must be accurate and fresh since they provide the foundation for all that is to come as we move up the line. The overall health of the organisation – how well it is performing according to the tactical direction from the middle – is measured here and is pushed up the chain of command in the form of increasingly rolled-up data. Thus the upward arrow under the word *Operational.*

At the other end of the spectrum we find the exact opposite in terms of data, type of work and type of decision. Up there at the senior management and executive levels, unstructured decisions and nuanced contexts are the daily diet. This is where strategic decisions are made and those strategic goals are pushed down the management chain, as illustrated by the down arrow under the word *Strategic*. Strategic direction is pushed to the middle management level where it is translated into tactical directives for enforcement at the operational level. Thus middle management is the *sandwich meat* so to speak, accepting directives from the slice of bread above and translating and pushing to the slice below, from where it receives and transmits the status of the tactical directives up to the top slice. No baloney.

### Business intelligence
Business Intelligence is created through the use of both internal and external data in order to gain insight into the (you guessed it) *context* of the organisation. BI provides metrics on the complete range of activities of importance to the organisation through organising, analysing and synthesising the organisations *information assets* and making them available through a variety of means, but increasing through web-based applications and *dashboards*. Note the almost one-to-one correspondence between the activities of BI and those in the Type of work column. BI's *Acquisition phase* (collecting and marshalling data) lines up nicely with the Measurement and Collection/storage functions of the organisation. *Organisation* meshes nicely with collection/storage, shading into Context creation. And so on up the hierarchy. This reinforces the notion that Data engineering is an important function - making certain that the right data are available at the right time in the right place for the right function.

**Figure PPM. A wealth management dashboard (information-driven app) example dashboard**

Note the various metrics displayed in an easily-understandable format. The displays are continuously updated. Take a look at the video.

<iframe width="560" height="315" src="https://www.youtube.com/embed/1_lIXq4uW8M" frameborder="0" allowfullscreen></iframe>

[Interested?](http://www.informationbuilders.com/business-intelligence)

### System type and span
This is where we need to start talking about the various ICT systems that support the work at each level.

#### Transaction Processing Systems (TPS)
Enter TPS, or *Transaction Processing Systems*. As the name suggests, TPS are masters of the often massive number of tiny transactions and events that underpin almost every organisation (even your own personal organisation). Each sale a firm makes or service an agency provides is a transaction. Each hiring and firing and retirement of a staff person is an event. Accounts receivable and payable when received or paid are transactions. As are pay cheques and loan payments and stock purchases and corporate tax payments. Everything that goes into or out of the firm is a transaction, as are all the small events and trades that occur within an organisation. Gazillions of activities. And they must all be recorded in a way that allows them to be saved, rolled up, rolled down and retrieved in all their granular detail for many years to come. This is how the organisation accounts for itself.

TPS are primarily involved in the measurement, collection and storage functions of the organisation. TPS systems do validation (ensuring data are correctly formatted and respect the rules of the process for which they are gathering data), sorting, filtering, listing and basic calculations. They handle marshalling and storage. And through reporting functions, they will tell you everything they did and everything they have in storage.  Examples of TPS include: stock control systems to maintain inventory, order processing systems to replenish stock, payment systems (other than payroll – for accounts receivable and payable, for example), payroll systems, and reservation systems.

#### Management Information Systems (MIS)
Transactions form much of the grist for the analysis types that follow up the ladder. *Management Information Systems* or MIS, are systems used by lower to middle management types who must make decisions in the context of operational realities. MIS include systems such as human resource management, sales management, supply chain management and budgeting. Sometimes used as a blanket term for a wide range of organisational systems, MIS are in fact a particular set of tools used by a particular set of managers. We will come back to this.

Context is important for these types of decisions, and MIS can provide context as they contain the rolled-up transactions from the various TPS systems in the organisation and can cross boundaries and pull data from all functional areas. The scope of MIS is internal. They don’t deal with data that is external to the organisation. They support predominantly structured decisions but can shade into semi-structured decisions with help from either humans or DSS (considered next).

MIS help firms to manage the myriad processes that must be managed on a day-to-day basis. They aren’t about strategy but are rather about operations. Boots on the ground. They deal in structured data (known and predictable format) that is of low to medium granularity, cost and complexity.  They sort, prioritise and merge data from different internal sources and then summarise it, providing rich context. They will also tell you anything you want to know about what they have done. They have excellent reporting facilities but can’t tell you about the future. They deal strictly in the past up to the present and are not at all strategic.

Another way to think of MIS is to approach it in terms of supporting particular business activities in the *value chain* along two dimensions, namely *primary* and *secondary* activities. The value chain is a connected series of activities, each of which adds value or supports the addition of value to the firm’s goods or services. *Primary activities* create the most direct business value for the organisation and its customers. Primary activities in order along the value chain are *inbound logistics*, *operations*, *outbound logistics*, *marketing and sales* and finally *service* (both product and customer).

*Secondary activities* are conducted in support of or expansion of the business value that is created by the primary activities. These include *firm infrastructure* (which is often also called administration, including Accounting, Finance, Communication and Legal), *ICT*, *quality assurance* and *product development* (R&D), as well as *human resource management* (HRM) and *procurement* (sourcing and purchasing).

A final way to conceive of the various systems that are required to run and organisation is the take the *supply chain* perspective. Every business has a supply chain, which is a *system of organisations, people, technology, activities, information, and resources involved in moving a product or service from suppliers, through the firm, to the customer.* Supply chain activities transform natural resources, raw materials, and components into a finished product, delivered to the end customer. In sophisticated supply chain systems, used products may re-enter the supply chain at any point where residual value is recyclable. For example, reclaimed steel, paper and plastic are often reused in several industries.

There are multiple systems available from multiple vendors to support and automate each of these functional systems. And that could be part of the problem. Read on.


#### Decision Support Systems (DSS)
Next up are *Decision Support Systems*. DSS, as they are most often to referred to, are knowledge-based systems used by senior management to assist in the complex process of making decisions. They are, in fact, *context systems*, creating the rich soup of data, information and previous knowledge that allows organisations to *learn*. They are best suited to assisting in the complex process of making *semi-structured* and *unstructured* decisions. Tapping databases of TPS and MIS data for their *memory*, they do *what if* analysis (discussed below), perform forecasting to simulate the long-term effects of various decisions and are adept at distributing their results through reporting and integration into various *dashboards* displaying the health of the organisation.

Several different *flavours* of DSS are in use, including Group Decisions Making Systems (GDMS), logistics systems (logistics is concerned with getting the right thing to the right place at the right time in the supply chain) and financial planning systems (where forecasting comes in quite handy). Systems as ubiquitous (found everywhere) as spreadsheets such as Microsoft Excel and Apple Numbers can and are also considered to be DSS. Thus every enterprise large or small has access to a DSS. It’s just knowing how to use them.

##### What-if analysis
So let’s talk about a *what-if Analysis*.

What-if analysis answers the question “What is likely to happen to *x* if we do *y*?” So what is likely to happen to our sales if we raise prices by 5%? Or what will be the impact on our bottom line if we ramp up production to 125% next fiscal year? In a structured analysis, using historical data and algorithms (a step-by-step set of operations to be performed on data that yield a predictable and verifiable result - sort of like structured decision making eh?) designed to produce outcomes along a continuum from worst to best, what-if analysis can reduce the error around a decision by allowing the range of potential outcomes to be examined before the decision is made to embark on a tactic. For example, in the scenario where the impact of ramping up production is being examined, it might be concluded that, while the short-term implications are serious (spending on new machinery, new hires and new warehouse and fulfillment capacity will impact the bottom line in the near-term), the longer-term gain from increasing capacity will more than sooth the short-term pain and overall ROI will be quite favourable. Taking the short-term outlook would lead to erroneous conclusions. A simple spreadsheet model can illuminate the way forward.

#### Executive Information Systems (EIS)
We now move on to the penultimate (next to last) set of systems, those used by the very top executives in the organisation. Occupants of the *C-suites* need a specific set of tools with a specific set of characteristics. Such systems allow for analysis of the context (environment) in which the organisation finds itself (the wider set of circumstances illuminated by a PESTLED analysis, for example), illuminate long-term trends and possibilities, and suggest potential strategic initiatives to address the longer-term trends identified. The data in such systems is often poorly structured (which is an unfortunate word for it since poor structure does not automatically mean bad data -- rather the data might be quite rich as a *function of* it's lack of 'proper' structure) or completely unstructured and makes use not only of rolled-up TPS and MIS data, but also data from sources external to the organisation (as suggested by the PESTLED analysis). EISs are future-oriented, support unstructured decision-making, and are designed with simplicity and intuitiveness in mind so that executives can easily manipulate and customise the system for individual circumstances and preference. An EIS used by an oil exploration executive would look much different from one used by a senior federal bureaucrat, but both are the same *under the hood*.

When we say that a system characteristic is *simplicity* it is not to be confused with *simplistic* or *immature*. Quite the opposite. As a long-time systems designer and developer, I can attest to the fact that making something appear simple and, moreover, to be *intuitive*, is the product of very hard work. The simpler a system appears on the outside, the more work has gone into the back end of it. My mantra is "Simplicity is difficult." Words to live by.

#### Enterprise Systems
The final type of system we will discuss here is the most all-encompassing of all, the so-called *Enterprise System* or ES for short. Enterprise systems are just as their name suggests – they target or encompass a wider target of functions that the MIS, for example. Their scope is the enterprise. Recall that MIS includes systems such as payroll and sales support and personnel (HR) functions. What happens when an organisation is structured around the various * functional silos* in terms of function? Take a look at Figure PB below.

**Figure ESA. The siloed organisation**

![A siloed organisation](https://raw.githubusercontent.com/robertriordan/2400/master/Images/silo.png)

In a so-called *siloed* organisation, functional areas of the firm (such as Sales and Marketing) operate in silos much like farm silos, one of which might  contain only corn and another only oats, etc. and they never mix. They operate independently of each other, even though they are on the same farm and farmed by the same farmer.  Silos in organisation create problems such as:

- Delays in communication where protracted lead time results in problems getting raw materials from suppliers
- Expanded cycle time, or the elapsed time from the beginning to end of a process
- Excess inventory in order to compensate for lead time and cycle time delays, a firm must have finished product or raw materials on hand – this costs money
- Lack of visibility in terms of the overall workflow within the organisation – issues such as confusion over the status of process when it’s currently in other parts of organisation (lack of communication between functions means that only the current function knows the status of an order making its way through the firm, for example)
- This lack of visibility leads to Point of contact confusion -- who has the current order status? Sales? Accounting? Customer Service?
- Performance metrics are a challenge – it’s difficult to know how well a process is performing over time because of the lack of process visibility

Figure PB shows an organisation where each functional silo has its own data store (represented by the multicoloured cylinders at the bottom of the figure). Pity the poor Senior VP responsible for Sales, Marketing and Customer Service (represented by the horizontal green bar labelled *SVP* above those three functions) who needs data from each department in order to do some forecasting. The database of each department must be accessed (and each database might be from a different vendor with a different file structure and data characteristics and refresh cycle), and the data from each must be formatted in a compatible way with corresponding dates and reporting periods in order to make sense of the overall picture in the VP's division. Even though each department might be using a *state-of-the art MIS optimised for their function*, note the path of requests and returns, represented by the blue and yellow paths up and down the silo and out to and back from the data stores. Often systems just don’t play nice with each other.

In siloed organisations, even the sharing of information *between* functional areas can be a challenge, as requests must be made up the chain to senior management, passed down to the target silo, back up to the management level and then back down to the requesting silo. Neither efficient nor effective. Now move up one to the Cxx level and imagine, since now some lower boundaries are crossed (note the CFO is responsible for the Customer Service function rather than the Chief Marketing Officer -- stranger things have and do happen in organisations). Imagine the reporting nightmare of trying to integrate data across so many functional and management boundaries.

What to do? As a first step, some rationalisation of data stores is in order. Looking at the organisation from a *process viewpoint*, we realise that the Sales, Marketing and Customer Service functions all relate to the *customer interface* and share more in common with each other than they do with Manufacturing or Finance, for example. So we might thing to rationalise around an enterprise system that has a customer focus. And there's just such a beast: the *Customer Relationship Management* or CRM system. Take a look at Figure CSV. Note the only real change? Functions under the same VP now share databases, making reporting much easier at that level. The databases are bigger, more sophisticated in terms of reporting and relationships and allow for data to be stored and formatted in compatible ways for reporting purposes in this management structure. That’s a great first step. But really, we have only *reduced* the pain. It’s not a cure. Note the CFO would experience the same problem getting compatible and timely reports as before, as she or he must cross systems boundaries to get rolled-up data. Not a complete solution at all.

Examples of enterprise systems include:

- *CRM* (Customer Relationship Management) -- manages customer-related processes
- *PLM* (Product Lifecycle Management) -- handles creation and implementation of new products
- *SCM* (Supply Chain Management) -- deals with procurement, inventory, and other supply chain processes
- *SRM* (Supplier Relationship Management) -- helps working with suppliers, vendors and service providers

Each of these types of ES concentrate on a particular aspect of the value chain. Note they are *managing* some process or aspect, such as *Customers* or *Suppliers* or *Products*. Using such systems, while productive (efficient and effective) in and of themselves, does not get us to the truly integrated enterprise stage that we seek. Read on.

**Figure CSV. An enterprise systems organisation**

![An ES organisation](https://raw.githubusercontent.com/robertriordan/2400/master/Images/es.png)

You are probably already guessing what the ultimate fix might be, and that is the enterprise system to beat all enterprise systems -- the mother of all ESs -- the *Enterprise Resource Planning*, or ERP, system. The ERP organisation is a medium to large (to enormous) operation with enough functional complexity and cash to warrant such a comprehensive and expensive solution. ERP (Enterprise Resource Planning systems) automate and rationalize key business functions such as financials, human capital, operations, and corporate services, and also provide complete *snap-in* solutions for a wide variety of industries (such as pharma, auto, defence, agriculture, retail, etc…) which integrate and automate all functions of an organisation. Take a look at Figure GST below and spot the change.

<a name="erp_org"></a>
**Figure GST. An ERP organisation**

![An ERP organisation](https://raw.githubusercontent.com/robertriordan/2400/master/Images/erp.png)

While this is a *massive* oversimplification of all the benefits or ERP, it serves to illustrate its most basic principle: that a transaction should be *atomic*, that is, there should only ever be one instance of a thing such as a *sale*. The sale, as an *entity*, should make its way through the organisational value chain but should never exist anywhere other than in the value area in which it resides. So there should not be an instance of the sale in Accounting, and in Finance, and in Sales and in Shipping. There is only ever *one* sale. We can track its position but never copy it. Because a sale, like any other object in an organisation, has a lifetime. We can watch it and interact with it and query it to ask what it's up to through its lifetime but we must never clone it to fulfil the siloed needs of functional areas. And enterprise database *backends* help to fulfil this very basic requirement. We will discuss *backends* in Chapter [system development].

What are the benefits of Enterprise Systems (such as ERP)? According to Rick Mullin, *ERP Users Say Payback is Passé*, (Chemical Week, Feb. 24, 1999) as quoted in CGA stuff waiting for permission, they are plenty:

- inventory reduction
- personnel reduction
- productivity improvement
- order management improvement
- financial close cycle reduction
- procurement cost reductions
- cash management improvements
- revenue increases
- transportation/logistics cost reduction
- maintenance reduction
- on-time delivery improvements
- information visibility
- improved processes
- customer responsiveness
- cost reduction
- integration
- standardization
- flexibility
- globalization
- improved business performance
- supply chain management

What's not to love?

Note the major change – one massive database has replaced all functional and MIS systems. While this is the most *obvious* change, it is by no means the *only* change that organisations undergo when adopting an ERP.  Next in line in terms of significance following the integration of all company data stores into a single, transaction-oriented database, the largest impact that an ERP has on an organisation is the requirement that the firm examine and alter all its business processes to match the *best practice* standards enforced by the ERP system. Don’t want to do business our way? Then you won’t be running SAP or Oracle or Microsoft ERP systems. You play by the rules or you don’t play. This is the most common reason cited for failed ERP installations – the inability (or unwillingness) of the organisation to change the way it does business to match the ERP’s standards.

Let's take a quick look at role-based visibility and scope as it applies to organisations using ERP-type software. Figure KT shows the breadth of visibility of data and information corresponding to position in the organisational hierarchy.

**Figure KT. Role-based scope of visibility**

![An ERP organisation](https://raw.githubusercontent.com/robertriordan/2400/master/Images/scope.png)

The *visibility* of data/information refers to the reporting structure. Starting at the very top, note the great, grey pyramid radiating downward from the CEO position. The CEO *sees* all data and their Executive Information System software ensures that they have complete visibility of all data because their *role* as Chief, demands it. So their role-based visibility is 100% wide in scope. Others in the hierarchy have different visibility of, and responsibility for, more restricted domains. Not all the roles are scoped out on this Figure. You can see what the others would be by simply tracing the functional responsibilities up to each successive level of reporting. Such *role-based* visibility is easily effected in enterprise software.

##### ERP vendors

There are several large vendors of these enormously complex systems, and some of the names of the players in this market will be familiar to you. You may or may not know that the world’s largest provider of enterprise application software is not Microsoft or Apple of even IBM. It’s *SAP*, a large German software house, started by former employees of IBM.

[Interested in SAP?]( http://bit.ly/1MDeI6Y)

Other big players in this market are the database giant *Oracle*, who have over the past few years gobbled up other equally large players such as PeopleSoft and Siebel, whose offerings included Financial Management Solutions (FMS), Human Resource Management Systems (HRMS), Supply Chain Management (SCM), Customer Relationship Management (CRM - from their acquisition of Siebel), and Enterprise Performance Management (EPM) software, as well as systems for manufacturing and student administration. Microsoft is also a player in this general ERP marketplace (with special focus on small to medium-sized firms), but the biggest by far is SAP. Walk through any airport and you can’t help but notice the big ads for SAP.

#### When ERP fails

What happens when organisations can't make the necessary adjustments to their business processes to allow the ERP to run their business? There are several high profile cases. IN the Canadian context, the biggest splash was made in 2001 when grocery giants Sobey's has a very public spat with SAP over a database failure (Sobey's was using IBM's DB2 software as their enterprise database system). [Interested?](http://www.computerdealernews.com/news/sobeys-fires-sap-over-erp-debacle/22906) and [a slightly different perspective](http://www.itworldcanada.com/article/sobeys-says-goodbye-sap/29540). But they apparently kissed and made up, as Sobey's implemented an SAP system a few years later [Interested?](http://www.itbusiness.ca/news/sobeys-gives-sap-a-second-chance/10471).

In 2008, Mountain States Entertainment made the news for a big ERP flop [Interested?](http://www.erpsoftwareblog.com/2011/01/erp-implementation-failure-you-be-the-jury-part-1/), and in 2004 Marin County California's failed implementation led to a lawsuit against Deloitte [Interested?](http://www.computerworlduk.com/news/it-business/20575/deloitte-sued-over-failed-erp-project/).  A more academic treatment is found in a Harvard business case written by A. McAfee, entitled *Rich-Con Steel*, (Harvard Business School Case 9-699-133, HBS Press, January 27, 1999).

But the knife cuts both ways. ERP business process is based on best practices (extensive research, testing and proof from the field that the ERP-recommended way to do business is the most efficient and effective way. The opportunity for an organisation to actually stop and look at its processes – which may have grown up over years in a patchwork quilt of expediency and become inefficient and redundant – is an amazing opportunity.

Key features of ERP include dealing with key business functions such as:

- Financials, including:
    - Tools for core accounting and reporting capabilities
    - Financial links to supply chain processes (paying suppliers)
    - Functions for compliance with national and global financial regulations
    - Monitoring cash flow

- Human Capital Management
    - Empowering employees to manage personal information
    - Allowing department-level collaboration for corporate budget (sharing of information)

- ERP Operations
    - Automate and manage day-to-day organisational activities

- Enterprise Systems (ES):
    - Enable a company to link its business processes
    - Remove silo walls between business functions leading to an integrated business solution
    - Remove friction between functions, individuals and processes to promote optimal workflow
    - Operate in real time (not batch or offline so everything is instantly up to date)
    - Are scalable (can grow and shrink as needed) and flexible (somewhat…)

There are downsides to implementing such large-scale solutions, and one of them is that they are expensive – not at all for the faint of heart or light of wallet. A 2013 report form the City of Toronto, for example, cited the all-in cost of some $69M to implement an SAP system. They write, “The FPARS project is a transformative effort that aims to restructure the financial planning, budgeting, accounting, human resource and management information systems and processes by implementing SAP as an integrative solution. Improving the City's financial and organizational management functions has the potential to produce significant benefits both in terms of greater internal efficiencies and enhanced value to the public in improved transparency, accountability and the delivery of higher quality of services.”

[Interested in what Toronto did? Take a look at the first 5 pages](http://bit.ly/1MEPuFm)

As a final note on the virtues of an integrated solution, it must be noted that for any business transaction (such as a sale) there exists only *one instance of that object*. This means that there are not multiple *Sales Spreadsheets* floating around the organisation, some with and some without that sale included. Fresh data is obtained as needed (or even automatically populated to reports as they happen) from a single source. There isn't a record of that sale in the sales database, and another in the warehouse database and another in accounts receivable, etc. One sale object with various *properties* of that object exists in one place. This is an enormous efficiency booster for organisations. (More on objects and properties in Chapter 3). Bottom line message: single object for all transactions - no copies of stuff everywhere.

Let's now return to our discussion of Figure JL where we left off, which was as we finished off the final vertical pieces. We now move to considering the horizontal dimensions of the figure in the context of the organisation.

We have explicitly stated here that different levels of workers in an organisation require different data resources in order to perform their duties. People at different levels of the organisation (just like those in different functional areas of the firm) make different types of decisions and the impact of those decisions is also different. The flow of information up and down the organisation is also dictated by one's position in the hierarchy. All of this implies that different functions at different levels require different information and different systems in order to work effectively. Much of the complexity of matching systems with functions and levels is taken care of with the ERP solution. An integrated, role-based system (your view of the data in the system is based on your assigned role in the organisation -- data entry clerks have a limited view whereas Senior VPs have a much broader view).

### The sideways view
Let's take the horizontal view of the big picture that is Figure JL and focus on the three numbered ovals running horizontally across all the vertical dimensions. First, let's bring back Figure JL for a refresher.

**Figure JL. The big picture (redux)**

![The big picture of the organisation](https://raw.githubusercontent.com/robertriordan/2400/master/Images/big_picture.png)

Oval number 1 runs across the bottom and encompasses functions and roles and systems that deal predominantly with the measurement and collection/storage of highly granular data, using systems that are low cost and complexity. Decisions at this level of the organisation are highly structured (algorithmic) and are overwhelmingly concerned with matters operational in the firm. The dominant system at this level of the organisation is the TPS. Note finally that increasingly, these tasks are being performed by machines. This is the future of such work - increasingly automated. Stay in school.

Oval number 2 represents mostly the functions of middle management, where context becomes important and where data become information as they are rolled up through the hierarchy. This level makes decisions that vary from structured to some unstructured at the tactical level with information created predominantly by humans though increasingly by machines. Data and information here are becoming less granular as they roll up. Systems are predominantly at the MIS level of functional specificity within silos, but are becoming more costly and complex to match the level of decisions made. Some DSS are used here.

You will note that the three activities associated with middle management are all marked with a little ![The big picture of the organisation](https://raw.githubusercontent.com/robertriordan/2400/master/Images/target.png) target. Let's spend a minute here and unpack the reason for *targeting* these three activities and those humans who perform them. I have singled them out (unlike the rockets ![The big picture of the organisation](https://raw.githubusercontent.com/robertriordan/2400/master/Images/rocket.png) which indicate that there is high potential here for research and employment - note that for future reference) because the incumbents of these positions are in imminent danger of being replaced by machines. The whole *middle layer* of the organisation -- those who don't do knowledge work and don't do technical work (those in the bottom and the top of the hierarchy) and those who do predominantly rules-based work (accountants, lawyers, physicians to a certain degree, managers of all functions) will soon largely be replaced in the majority of their functions of creating context, creating information and making decisions. It's simply a reality of working in a profession where the context and information creation, and the decision making can and is being increasingly accomplished by machines are we become more able to digitise (liquefy) analogue data and simplify the making of previously difficult decisions. Once again, stay n school.

The middle management functions of mentoring and coaching and socialising new employees into the organisational culture and providing visibility into the upper ranks will cease to be performed unless machines can take on these tasks. And that might be a ways away. Meanwhile, rational and maximising algorithms will continue to supplant middle managers. Make sure you train yourself and seek employment either as a technician or as an idea person; someone who can leverage technology. Stay away from rules-based occupations. Their days are numbered.

As we reach the top level at oval number 3, we are interacting predominantly with decision, action and knowledge creation at the strategic levels of the organisation. Information is not at all granular and is rolled up to the highest levels for consumption among senior executives who might only be concerned with a single number representing all sales year-to-date as a metric for organisational health. Here, DSS and EIS predominate as unstructured, highly strategic and potentially costly decisions are made. While it's true at every level since much data at the top come from TPS at the root of the organisational processes, especially here, the numbers must be right.

While there are many different types and sizes of organisations, and each is uniquely structured and will have developed with its own particular culture and style, the general taxonomy implied here by the three ovals is a reasonable approximation of the differences across all these dimensions driven by level in the organisation. There will inevitably be overlap (the ovals in fact overlap by design) and differences in particular cases, but this pretty much sums it up. Eat it for dinner with a dash of salt.


[Interested in types of ICT?](http://tutor2u.net/business/ict/intro*information*system*types.htm)

### And finally, the rapidly declining cost of computing

We end this chapter with an astonishing table from our friends at Wikipedia on the cost of computing. A *gigaflop* is described as *the power to execute one billion floating point calculations per second*. A floating point operation (or a FLOP) is any mathematical manipulation (+ - * /) involving two numbers which have decimal places. So 2 (two) is an *integer* but 2.0 (two point zero) is a *floating point number*. *Ergo* a FLOP might be the mathematical operation to add 1.0 and 1.0. Floating point math takes longer than integer math. A computer processor's power is often measured in *gigaflops*, providing a universal standard for speed of execution, which is a proxy for computing power. The more flops a system can do in a certain period of time, the more powerful the system.

Below is a table equating gigaflops with dollars. How much did the computing power to effect one gigaflop cost, down through the annals of computer history? Here's what Wikipedia has to say (it will astonish you):

**Table GFP. Hardware cost to get a gig going**

| :- | :- | :- | :- | :- |
| **Date** | **Approximate cost per GFLOPS** | **Approximate cost per GFLOPS** [inflation adjusted to 2013 US dollars] | **Platform providing the lowest cost per GFLOPS** | **Comments** |
| 1961 | US $1,100,000,000,000 ($1.1 trillion) | US $8.3 trillion | About 17 million IBM 1620 units costing $64,000 each | The 1620's multiplication operation takes 17.7 ms. |
| 1984 |$18,750,000 | $42,780,000 |Cray X-MP/48 | $15,000,000 / 0.8 GFLOPS |
| 1997 | $30,000 | $42,000 | Two 16-processor Beowulf clusters with Pentium Pro microprocessors ||
| April 2000 | $1,000 | $1,300 | Bunyip Beowulf cluster | Bunyip was the first sub-US-$1/MFLOPS computing technology. It won the Gordon Bell Prize in 2000.|
| May 2000 | $640 | $836 | KLAT2 |KLAT2 was the first computing technology which scaled to large applications while staying under US-$1/MFLOPS. |
| August 2003 | $82 | $100 | KASY0 |KASY0 was the first sub-US-$100/GFLOPS computing technology. |
| August 2007 | $48 | $52 | Microwulf | As of August 2007, this 26.25 GFLOPS "personal" Beowulf cluster can be built for $1256. |
| March 2011 | $1.80 | $1.80 | HPU4Science | This $30,000 cluster was built using only commercially available "gamer" grade hardware. |
| June 2013 | $0.22 | $0.22 | Sony Playstation 4 | The Sony PlayStation 4 is listed as having a peak performance of 1.84 TFLOPS, at a price of $400 |
| November 2013 | $0.16 | $0.16 | AMD Sempron 145 GeForce GTX 760 System | Built using commercially available parts, a system using one AMD Sempron 145 and three GeForce GTX 760 reaches a total of 6.771 TFLOPS for a total cost of $1090.66. |
| December 2013 | $0.12 | $0.12 | Pentium G550 R9 290 System | Built using commercially available parts. Pentium G550 & AMD R9 290 tops out at 4.848 TFLOPS grand total of $681.84 USD. |
| January 2015 | $0.08 | $0.08 | Celeron G1830 R9 295x2 System | Built using commercially available parts. Intel Celeron G1830 & AMD Radeon R9 295x2 tops out at over 11.5 TFLOPS at a grand total of $902.57 USD. |

[See the source for important notes and additional information.]

*Source: http://en.wikipedia.org/wiki/FLOPS*

In 55 years (shorter than my already short life) the equivalent cost to execute a billion FLOPs has dropped from USD $8,300,000,000,000 to USD $0.08. If that's not stunning and breathtaking then neither is (insert your most stunning and breathtaking thing here). Computing wins.

While a bit dated, in a liquidinformation.org piece representing probably the absolute minimum achievable computing power, it is asserted that, for USD $1,000, we will be able to buy a computer with the computing power of an insect in 2018. That same $1,K will get us a mouse brain in 2030, a human brain is 2042 and *all human brains combined* by 2060. If you are a normal early 20s undergraduate student, 2060 is well within your lifetime. Think of it. Just *think.*

[Interested?](http://www.liquidinformation.org/information_history.html) {read just the *Computation* sub-section including the *When will it end?* piece]

**Go Figure #1. Random SC advert**


<iframe width="800" height="491" src="http://www.powtoon.com/embed/fdjbos4uIyd/" frameborder="0"></iframe>
