# Chapter 3 [Public]
---
Here's a quiz about Gitbook
|                  | Good | Bad |
| ---------------- | ---- | --- |
| What is Gitbook? | (x)  | ( ) |

> Gitbook is good

What does Gitbook support?
- [x] Table-based questions with radio buttons
- [x] Table-based questions with checkboxes
- [ ] Telepathy
- [x] List-based questions with checkboxes
- [x] List-based questions with radio buttons
- [ ] Moon-on-a-stick

> Gitbook supports table and list based quiz questions using either radio buttons or checkboxes.
>
> Gitbook is not telepathic and does not give you the moon on a stick.

---

# ICT as a product
In this chapter we will consider the broad topic of how systems come to be. What sparks the need for a system or a system change? How are system requirements decided?  How are systems built? How are they put into place in an organisation? How are they cared for during their life-span and how are they retired?

This chapter is about more than building new systems. It is also about NOT building systems when a new system is required, rather acquiring it through other channels. And it's about how organisations decide whether to buy, build, rent or commission the building of a brand-new system.
## What sparks the need for a new system in a typical organisation?

The on-line [Merriam-Webster Dictionary](http://www.merriam-webster.com/dictionary/process) defines _process_ simply as "a series of actions that produce something or that lead to a particular result." Clean. Simple. But we also know that something must spur the process into action. You get cold, you do something. The something produces change as output.

Recall our discussion of a simple process in Chapter 1. _Input_ **-->** _Process_ **-->** _Output_. Simple and clean. When you stop to think about it, everything that happens in any organisation (and in your life) is part of a process. Something spurs action (it's cold in the room - this is input) so you either turn up the thermostat, or put on a sweater or close an open window (this is the process part) and some output is produced (something is changed - more warmth or less cold but in the end, you feel more comfortable).

It's the same in an organisation. Something happens as input (profits are falling; employees are calling in sick in record numbers; a competitor releases a new product or it's simply time for a strategic review - the ticking of the clock has led to a milestone being hit, triggering a review). This input bubbles through the organisation until it's recognised by someone or some monitoring process, causing someone or some group to start mounting a response.

One of those possible _somethings that could be done_ is a change to an existing system or the recognition that an entirely new system is required. This decision would be made using one of the decision models discussed in Chapter 3, where we also discuss strategic alignment. For now, let's just assume that a decision was made to respond to the input stimulus through the tactic of introducing a new (meaning new _to the organisation_) system.

##Sourcing a new system
What are the choices when sourcing a new system? There are several different variations, leading to eleven distinct possible paths plus (just to make a long story even longer) several possibilities for combing one or more of the eleven. 

We will first make the distinction of whether the system will be: A) custom build using some combination of existing components and/or brand new code, or; B) if the system is sourced from the marketplace of existing software systems that any organisation could purchase or rent on the open market. Purchased commercial software is referred to as COTS (for _Commercial_Off-The-Shelf_) software (such as Microsoft Excel), while rented software is referred to as _Software as a Service or SaaS_. A further wrinkle is produced in that _Open Source Software_ (or OSS) can be had for literally no initial capital layout. Furthermore, systems can be pieced together using components sourced from any or all of the possibilities, creating a mashup that defies categorisation. 

So as not to muddy the already turbid waters, the four groups and the eleven total possibilities. A general description is provided here, followed by a table outlining pros, cons and including a high-level determination of cost, time to value and overall quality. Here then are the eleven routes:

**Figure ZZ. Software Form Factors: Eleven paths to a new system**

![Custom Designed Software](http://riordan.ca/images/software_form_factor.jpg)

###Eleven paths to a new system - the software form factor
**A: Custom Developed Software (CDS)**

A1. Custom-built system built using the in-house expertise of a dedicated systems development functional area (so called _in-sourcing_).

A2. New custom-built system using expertise from outside the organisation (so called _outsourcing_).

A3. New custom-built system using in-house expertise and built by the actual future users of the system whose job is not systems development but rather in the functional area in which the system will be used (so called _self-sourcing_).

**B: Open Source Software (OSS)**

B1. Custom-built system using code “borrowed” from the open-source community on the internet and built using the in-house expertise of a dedicated systems development functional area (a form of _in-sourcing_).

B2. New custom-built system using code “borrowed “from the open-source community and built using the expertise from outside the organisation (a form of _outsourcing_)

B3 New custom-built system using code “borrowed “from the open-source community and configured/built using in-house expertise of the actual future users of the system whose job is not systems development but rather in the functional area in which the system will be used (while this scenario would be relatively rare, it is a form of _self-sourcing_).

**C: Commercial Off-the-shelf Software (COTS)**

C1. Purchasing a COTS solution and customising it in some fashion to better match the requirements of the functional area in which the system will be used. Think Microsoft Excel with some specific functionality programmed in macros or custom VBA code. The customisation in this case is carried out by a dedicated in-house systems development function (a form of _in-sourcing_).

C2. Purchasing a COTS solution and the customisation is carried out using expertise from outside the organisation (a form of _out-sourcing_).

C3. Purchasing a COTS solution and the customisation is carried out by the end-users of the system (a form of _self-sourcing_).

C4. Purchasing a COTS solution and implementing it with no changes whatsoever (think Microsoft Excel here -- everybody gets a copy on their desktop with the management directive "Now go to it!")

**D: Software as a Service (SaaS)**

D1. SaaS involves essentially “renting” software from a software service provider. If the organisation wants a big enterprise system and doesn’t want the cost or responsibility of buying, installing and maintaining its own copy of the software, said software can be “rented” and provided over the internet. There is little or no customisation here. You take what is offered. If any customisation is available, it's done on a outsourced basis by the service provider.

As you might imagine, there are pros and cons to each approach, a summary of which appears below.

**Table X: Sourcing a system** [need space between title and first row]

| Source type | Advantages | Disadvantages | Assessment
| :- | :- | :- |:-:
| A. CDS | By far the most costly option, but you get what you pay for. CDS provides systems that are specifically optimised to deal with exactly the challenge or opportunity faced by the organisation, and are built upon (hopefully) rigorous analysis, testing and monitoring in ways that are specific to the situation. The organisation isn’t forced to shoehorn into a one-size-fits-all solution and compromise functionality, flexibility and efficiency for the sake of cost. Furthermore, the evolution of the software is under the organisation’s control. The asset value of the intellectual property (IP) embodied in the code is owned and internal and thus controlled. Finally, the organisation retains full control of any data that is implicated in the process. Plenty of upside here. | The old adage that “nothing is free” is nowhere more appropriate than here. While surgery-like solutions to critical issues are the ideal for every organisation, they come at a price. Here, the price is the double-headed monster of real dollar cost and a long time to value (a metric that indicates the elapsed time from spend to reward). There is a risk of obsolescence as well and the organisation owns the system and must maintain it – you own the stack and all the risk associated with the development right through to retirement. Finally, all tech and user support is on your organisation. This can be expensive. Big bucks and a lot of time are the main drawbacks here. If cheap and quick are important, look elsewhere.| ![Custom Designed Software](http://riordan.ca/images/cds.png)
| B. OSS | An increasingly worthy consideration in the systems development mix is the use, whether exclusively or as one of more components of a solution, is the use of open source software. OSS is software that is made available free from initial cost by developers in the community. The code is free to “fork” (copy then modify a local version), modify and implement. Knowing what we do about the time value of money and especially if the availability is low and/or the cost of capital is high, this is indeed an intriguing opportunity as there is little or no cash outlay at onset. Solutions can be built from existing code or modified as required. Code (at least initially) is supported by a community of developers, providing many eyes on the implementation (but this can be risky). Another potential advantage lies in not being tethered to a particular vendor such as SAP or Oracle or Microsoft. OSS is open, and open means freedom to choose. | Again, nothing is free, even free stuff. Gartner (http://gartner.com/webinar/1633714 accessed February 12, 2015) maintains that a sobering 92% of the total cost of systems ownership is accounted for by the maintenance phase (the period during which the system is in use) ergo the initial savings are not as enticing as expected, especially when trying to do maintenance on code that was not written from scratch to be maintainable and is not supported by a software vendor but rather by a vague “user community.”  Moreover, like COTS solutions, such generic code, if unmodified, confers no competitive advantage on the organisation. If it’s a strategic priority to use a system that is tailored to a particular value-generating process, then OSS is not the way to go. IN addition, the issue of solution integration must be addressed. A system can’t simply be dropped into place and begin to work seamlessly in the organisation. Larger vendors will provide such service as part of their development costs. With OSS, it’s on you. Penultimately, there just might not be any OSS available to address the challenge at your organisation. There’s no guarantee that anything will fit, and forcing a solution on a problem poses similar risks as buying COTS (see below). Finally, mixing and matching OSS with other solutions such as SCD and COTS might raise governance issues with open source licensing. Beware and read the agreements carefully. | ![Open-source Software](http://riordan.ca/images/oss.png)
| C. COTS | By far the least costly option, and that's always a valid consideration; but there's a price to be paid for being cheap (paradoxically -- see Disadvantages). Additionally, it’s likely that industry best practices are adhered to and enforced in commercial software. This should be encouraging to the operations people at your organisation. Finally, it’s likely that the technology is up-to-date. | Given the nature of such software (commercially available, generic systems to solve generic problems), it is unlikely that an organisation's challenges would be efficiently or effectively addressed by such an all-purpose tool. Think Excel. Great tool, tons of power, massive scope, not at all specific to an industry or a functional area. You can do some dentistry with a pair of pliers; question is, would it be efficient or effective? The organisation buying COTS also exposes itself to the risk of vendor viability. What if you buy a system and suddenly, XYZ Co. goes bust? Or is bought out? Additionally, much like OSS, a solution might not exist right off the shelf. So the problem might well become framed in terms of the available solution. This is obviously not optimal. Finally, retaining key staff, if their competency is development, will likely be compromised. Developers develop. Buyers buy. Different people. | ![Commercial Off-the-shelf Software](http://riordan.ca/images/cots.png)
| D. SaaS | A fairly expensive proposition is this, despite there being no development costs at all. The organisation will pay a price for essentially transferring all the application risk to an outside provider, which house and maintain the software at remote locations. There is no need for the organisation to have local hardware or software other than an internet connection and display devices for users. System maintenance (upgrades, bug fixes, etc.) are all the responsibility of the service provider. Service Level Agreements (SLAs) provide guarantees of uptime and availability and the hefty penalties attached to such agreements guarantee that the organisation consuming the SaaS are protected from loss of business arising from unforeseen circumstances (such as outages, system failures, etc.). SaaS offers a very short time to value, includes codified best practices and service providers provide state-of-the-art, up-to-date software, made available on all platforms and devices (from mainframe to smartphone). Finally, the software is available anywhere you have internet access, so distributed systems and scattered workforces (such as the cottage in summer, for example -- oh joy!) are all supported. | Of all the software form factors, SaaS has the highest vendor viability risk. Putting all your eggs in one basket with one vendor can be dangerous. Much like COTS, what if the vendor (service provider) were to suddenly close its doors or go offline? The risk of data lock in is also high. There is little opportunity to specify the optimal data model (information architecture) for the organisation. You take what you get. This also impinges on data confidentiality issues – how does the organisation protect its IP in terms of its own data when the data is processed and stored off-site? Finally, usage-based pricing could become costly over time. It is exppected that SaaS will grow rapidly in proportion to other forms of system acquisition.| ![Software as a Service](http://riordan.ca/images/saas.png)
| 1. In-source | More likely to meet user requirements as the organisation’s developers, who will build the system in the case of CDS or configure/modify it in the case of OSS and COTS, are familiar with the organisation's business model and processes. Organisation owns the code and the solution.| On the downside, it’s costly to support such a systems development function and unless the organisation is itself a software house, systems development will not be a core competence. | ![In sourcing](http://riordan.ca/images/in_source.png)
| 2. Outsource | Frees up the organisation to focus on its core competence. There is more certain cost control (through performance metrics and contractual obligations) and external technical specialists are likely to use state-of-the-art tools and procedures along with industry best practices. Finally, systems development houses have well-trained staff as technology solutions are _their_ core competence| Less likely than in- or self-sourcing to meet user requirements as the requirements must be provided to an outside team with no particular expertise or knowledge of the organisation's business model. This route can be very costly and time consuming. The organisation has no control over the external entity in terms of its survival, potential sale or even going out of business, thus exposing the organisation to significant vendor risk. Moreover, the advantage of leveraging technology in-house is lost to the organisation. Penultimately, this development route is less likely to produce a sustainable competitive advantage as the driver is external to the organisation. Finally, unless specifically specified, the firm that creates the solution also owns the code – so the IP is lost. | ![Outsourcing](http://riordan.ca/images/out_source.png)
| 3. Self-source | This route is very likely to meet user requirements as the end-users – who are actually creating a solution based on their own needs - are quite familiar with their own processes. Furthermore, the organisation owns the code and the solution, thus the IP remains in house. | Very costly in terms of diverting attention and resources away from the actual work of the end-users (they aren't doing their real job if they are developing a system). Often there is no attention to organisational standards in terms of software tools, protocols, connectivity to larger, enterprise-wide systems or, especially, security. Systems development is not a core competence of functional specialists in, for example, the Accounting department, thus systems built by those whose training is in Accounting or Finance or Marketing will not be optimised. Finally, to reiterate, system-wide connectivity, security and privacy are often the most serious issues. And heaven help the organisation if the employee who did the work were to leave for any of the various reasons that people move on. Documentation is almost never attempted, let alone completed, in self-created systems. Finally, as Abraham Maslow famously wrote “Give a small boy a hammer, and he will find that everything he encounters needs hammering.” [Interested?] Abraham H. Maslow (1966). The Psychology of Science. p. 15. Re-written in its more familiar aphorism form, we often see or hear “If the only tool you have is a hammer, everything looks like a nail.” If the functional analyst building the system is familiar with Excel, then Excel will be her hammer and will be the solution to everything, whether or not it’s the best solution. | ![Self-sourcing](http://riordan.ca/images/self_source.png)

### Buy or Build?
We will consider Rent to be a subset of Buy. That being said, let's start with the _Buy or Build_ decision. That's the distinction between commissioning a brand new system using either the in-, out- or self-sourcing option, compared to the decision to buy or rent a commercial product and either customise it or not. 

We begin by posing the question "Should we start from scratch here, rent something or should we buy off the shelf?" There are actually two distinct ways to look at the _B-or-B_ question in terms of what is described above in the pros and cons table. We can consider the broad _Buy_ category to be comprised of buying or renting anything from outside the organisation, whether it's a custom, ground-up application or an OTS solution that is either customised through outsourcing or not customised at all. So this one broad category involves not using internal resources in any way. 

The other broad category is, obviously, the opposite -- doing everything in-house, whether building from scratch or customising an OTS system using the organisation's resources and personnel.

A useful tool to understand the context of this choice is the Outsourcing Decision Matrix. This is a strategy tool, useful in a wide variety of situations but not necessarily in the B-or-B software systems arena. We'll use the tool to give us an appreciation for the decision process in B-or-B.

The Mindtools website (see the Interested link below) poses a series of questions much like these: "Which activities should we outsource, and which tasks should we do in-house? For instance, imagine that you work in the healthcare industry. Should you outsource your cleaning staff, or hire in-house cleaners? Would the decision be the same for a furniture manufacturer? If you worked for an airline, would you outsource your in-flight meal preparation, or would you hire cooks directly? What if you managed a luxury hotel?" As I write this chapter, I have just returned from my local Ikea store. My wife and I made a stop in the cafeteria (shopping at Ikea is hungry work) and I found myself wondering if the cooks and serving personnel providing the meals were Ikea employees or outsiders occupying Ikea-owned space and kitchen tools to provide service under contract to Ikea. You get the idea. 

So do you do it yourself or get others to do for you? This is a good question indeed. [[Interested?](http://www.mindtools.com/pages/article/newSTR_45.htm)]

Figure x. Outsourcing Decision Matrix (symmetrical)
![Outsourcing Decision Matrix (Symmetrical)](http://riordan.ca/images/outsourcing_decision_equal.jpg)


Figure X shows the matrix in a symmetrical configuration. The idea of this tool is to envision a process or activity undertaken or proposed by a particular organisation and decide what to do with it. We get a measurement on the two dimensions (Contribution to Performance and Strategic Importance) and then plot the process on the grid based on the values of the two dimensions. Simple. 

We will use as illustration here a strategic review process with which we should all be able to relate: that of a University considering the value of an existing academic programme. Universities are increasingly numbers driven (bums in seats) as government funding is increasingly tied to enrolment numbers so schools are required to be agile and to engage in continuous programme review. 

Let’s say that the programme under consideration is a degree in Airborne Fulfilment Logistics – better understood as ¬_delivering stuff using drones_. The school in question currently offers the programme as a joint initiative of the Aerospace Engineering department and the Supply Chain Management people in the Business faculty.  

Now we need to work towards deciding if and how to proceed with the decision of what to do with this drone degree. This is where the tool comes in handy. 

Figure Z. Outsourcing Decision Matrix with proposed process
![Outsourcing Decision Matrix with process located](http://riordan.ca/images/outsourcing_decision_system_box.jpg)
As a high-level illustration, let's assume we've got our two metrics (we will discuss in detail below but for now, just play along). Now we need to locate the degree programme in the decision matrix based on its measurements on the two axis variables to assist in making the decision on how to proceed. Figure Z shows the metrics on the degree (little blue box), locating it in the upper, right quadrant of the matrix based on it being assessed a score of ~75% on both variables. This locates the process squarely in the "Retain" quadrant, meaning that it's important to competitive advantage and to organisational efficiency. So the organisation will retain the process internally. Now, some detail. 

Upon measurement of the two dimensions, the programme under consideration here will most likely (especially if, in measuring the two dimension variables, a value of exactly 50% is avoided) land in one of the four quadrants. Note the outcome (strategy) that is represented by landing in a quadrant (clockwise from top left we have: Strategic Alliance, Retain, Outsouce and finally Eliminate). Let’s look in more detail.

First, examine the horizontal and vertical axes, which measure two important variables and range from Low (0%) to High (100%). The vertical axis represents Strategic Importance. A process is considered strategically important if it impacts competitive advantage. Recall from Chapter 1 that competitive advantage is a superiority gained through providing the same value (usefulness or problem-solving ability) as its competitors but at a lower price, or increased revenue through charging higher prices supported by providing greater value through differentiation. (http://www.businessdictionary.com/definition/competitive-advantage.html - accessed February 26, 2015). 
In our example, if administration determines that the strategic importance of offering a drone programme is high (administration thinks that it provides an edge in attracting not just students but specialist faculty and research dollars and that ever-important intangible _prestige_), then they would rank the drone initiative above the 50% level on importance. This signifies that administration feels that, on balance, the programme is a net contributor to fulfilling the school’s strategy. The discussion of exactly how this would be measured is beyond the scope of this text, but must be done in the real world in order to use this tool.

To move forward, let's assume we have some measure of the strategic importance of the programme on a scale from 0 to 100% where higher is more strategically important.

Let's move on to the horizontal dimension, where the impact of the process on operational performance must be evaluated, again on a scale from 0 to 100%. This variable measures the impact on the organisation of the efficiency of the programme: if a program is operationally important, if it runs poorly, it will impact the organisation in a negative and important way. So the systems involved in supporting and running the programme itself must be efficient and effective. 

(Delete?) Think of the process for fuelling a fleet of city busses. If unreliable, slow or otherwise inefficient, the integrity of the city economy can be jeopardised. Nothing would run on time. On the other hand, a system with little operational significance will not materially affect the organisation's performance one way or the other. Think of the process or washing the exterior of those same city busses. Clearly not critically time sensitive or nearly as impactful as keeping the fuel tanks full.

Back to our university example. Management must come up with a metric to measure the impact of the degree programme on the overall efficiency of the university. Considerations include whether facilities to house faculty administration, offices, classrooms, labs etc. are at a premium or do not exist. In addition, the average salary of professors in the field (professors in rare fields can attract better compensation than others) is high, then this might be factored in. If the programme is more expensive, pound for pound than other programmes, then it might be decided that overall operational impact might be negative. If, on the other hand, significant synergies (the whole being of greater value than the pieces) are being achieved and/or if space is being efficiently utilised and perhaps if other faculties are finding ways to leverage the drone group, then the scale could be tipped in favour of the degree programme. 

These are complex issues, but here again we assume that a metric exists to measure such impact.

Let’s look at what would happen (what strategy would be followed) from the strategic review according to various hypothetical score combinations. First, a high score on Strategic Importance, coupled with a high score on Contribution to Performance would locate the programme squarely in the Retain quadrant in the upper right. In this case, the university would decide to not only continue offering the programme, but to offer it on campus with full staffing and facilities, keeping it all in house. This programme is a star.

On the other hand, scores coming in low on both dimensions (less than 50% on both measures) would locate the programme in the Eliminate quadrant, making it a prime candidate for elimination altogether. 

These are the two extremes. So let’s say the Operational Performance metric comes in at 75, but the Strategic Performance comes in at 25. This would represent a situation where the programme is efficient and contributing to overall performance, but was not measuring up in terms of the strategic direction of the school. Say the school has a strategy to be the preeminent university in Arts and Philosophy. A highly technical programme in remote drone supply chain fulfillment might not be what the school wants to be known for. So maybe, just maybe, the programme gets cut. Or maybe, just maybe, the school can outsource the delivery of the programme to the private sector. There are any number of private educational training firms out there. The school might want to keep the programme on campus, retaining the operational synergies and the capacity utilisation, but outsource the delivery to the private sector. This would be a difficult sell for faculty. And not likely to fly at all… but the times they are a changing. 
The final possibility is the opposite of the above, where Strategic Performance is above 50%, but Operational Performance is below. So the school likes the programme because it fits with its overall strategy (maybe it wants to be a high-tech hub), but the programme is just not operationally feasible.  IN this case, a Strategic Alliance might work. The school could look to partner with another local university to deliver the content, offering to take the operations of an underperforming programme at the partner school in a trade. 

[THINK ABOUT THIS IN TERMS OF WHETHER IT MIGHT DICTATE THE SOURCING DECISION FOR A SYSTEM] When deciding on an Information System however, it's unlikely that a decision would be made to enter into a strategic alliance with a system solution provider or especially a competitor. Such alliances are formed between two or more organisations in order to solve a particular problem or to take advantage of a unique, perhaps non-recurring opportunity, where all parties to the alliance would benefit.

[[Interested?](http://www.theneweconomy.com/home/strategic-alliance-ibm-apple)]

While a strategic alliance is not likely to happen in the case of a B-or-B decision, this shouldn't dampen our enthusiasm for the tool. It's still quite valuable as it illustrates the important considerations that need to be taken into account and highlights trade-offs that need to be made when deciding on how to commission a new system.

That's how it works in the ideal world. The real world is a bit messier and more complex.

What are the issues? First of all, we have chosen arbitrary cut points between decision outcomes, located at 50% on each scale. This is esthetically quite pleasing (yielding four, nice, equally-sized quadrants), but it unlikely to represent reality in all but the most unusual cases. More likely is the organisation having different cultures, priorities, strategies and practices, thus requiring different cut-points.

Figure Y. Decision Matrix examples with different variable cut points
![Outsourcing Decision Matrix Mashup](http://riordan.ca/images/outsourcing_decision_mashup.jpg)

Examining Figure Y, we see organisations imbued with different realities. A particularly lean organisation would have a very small upper, right quadrant (the Retain area), preferring to outsource, partner or eliminate all but the most essential of processes. The cut points for both strategic importance and Contribution to Efficiency could be moved up to 75% or even 80 or 90%. Such organisations are sometimes referred to as _virtual organisations,_ existing as only a core set of processes with no real physical space, having outsourced, partnered-off or cut everything not considered absolutely essential.

The recent and astoundingly swift rise of Web 2.0 communications and collaborative technologies, along with e-commerce, secure credit card transactions and teleworking, coupled with the rapid rise of the service sector, have led to the rise of such virtual (not bricks and mortar) organisations. This is how Amazon started way back when.

Don't confuse this sort of virtual organisation with a _virtual corporation_, which is really a form of strategic alliance. [Some sources](http://www.allbusiness.com/glossaries/virtual-corporation/4960651-1.html) muddy the water a bit on this.

[[Interested?](http://www.economist.com/node/14301746)]

Let's then take our new-found expertise in decision making and translate it into a more difficult situation which, while sharing some similarities with the outsourcing decision challenge, has more and varied inputs to the process.

To make the decision about how to commission a new system in an organisation, a series of determinations need to be made.

Table XX. Buy-or-Build Considerations

| Consideration | Build if | Buy if |
| :- | :- | :- |
| 1. System size and complexity | Small, simple and _ad hoc_ | Big, complex, or an adequate OTS solution exists and is cost-effective |
| 2. Strategic necessity | Not strategic and/or limited operational impact | Strategically important and/or significant operational impact |
| 3. Timeline | Small with plenty of time to get it right | Medium to large with a tight delivery timeline |
| 4. Uniqueness | Unique or proprietary or might expose a trade secret or competitive advantage | Ordinary, garden-variety with no secret sauce |
| 5. In-house talent | Have a dedicated, well-funded and persistent systems development resources | No real competence in development |
| 6. System footprint | Small, restricted impact on a single function or process | Impacts a larger number of functions and/or needs integration with an enterprise system (such as SAP) and/or must be scalable and robust |
| 7. Lifespan | Short | Long |
| 8. Compliance | Not required to be compliant with external agencies | Requires external compliance such as SOX or Bill C198 among others |
| 9. Stability | Industry, market, competition and business practices are stable and glacial | Industry, market, competition and business practices are volatile |

There are plenty of compliance standards, and many agencies (especially governmental) have their own set of rules.  [[Interested?](http://www.cihi.ca/CIHI-ext-portal/internet/en/Document/standards+and+data+submission/standards/MIS_FAQ)]

There's plenty to consider when deciding to B-or-B. [[Interested?](http://www.techrepublic.com/article/buy-vs-build-six-steps-to-making-the-right-decision/)]

## What makes a quality system?
Regardless of the decision to either buy or build, there are certain imperatives in system building. Let's examine them now.

Quality is an aggregate function of how well a system meets each of the following characteristics, Each is important in isolation, but the relative weight of each factor in determining overall quality is context dependent (and isn't _everything_?). Not to put too fine a point on it, but in one context at a certain point in time for a certain organisation, _efficiency_ might take precedence over _security_, say. At another point in time, in another circumstance, the reverse might be true. So the relative weights of the system quality factors below can change over time, both within and between organisations and are sensitive to context.

Here are the factors:

- **Exhaustiveness** — A system is exhaustive if it _addresses all requirements_ specified by analysing existing systems (if extant) to discover shortcomings, by examining the organisation's needs including their strategies, and by polling potential system users in the _Requirement Analysis and Definition_ phase (see later discussion on SDLC and others) of a proposed systems development project.
- **Reliability** — A system is reliable when it operates in _predictable and consistent fashion_ no matter the demand load placed upon it. It is said to be _scalable_, both up and down, if it robustly responds to changes in demand such that there is minimal impact on other important metrics (such as accuracy and efficiency). "It takes a licking and keeps on ticking." to borrow a 1950-1960s and again in the 1990s _Timex_ watch ad in which wristwatches survived various staged torture tests. Systems must have the capacity to handle peek workloads while ideally being able to scale back when capacity isn’t required. 
- **Accuracy** — A system is considered to be accurate when it produces _predictable and verifiably-correct outputs_ when executing its required functions. So 2 + 2 is always 4. This requirement speaks to data and process integrity. 
- **Efficiency** — A system is efficient if it produces outputs that are _more valuable than is the cumulative cost of the required inputs_ to the system. The greater the spread between the value of outputs and the cost of inputs, the more efficient is the system. This is the basic and most important test of the value of ICT. A system must either shrink required inputs or grow the volume of outputs in order to be of value. The spread between the cost and the benefit should be positive, non-zero and subject to continual scrutiny and adjustment.
- **Security** — A system is considered secure if access to the system itself, to any required inputs, and in some cases the system outputs, are_ protected from unauthorised access and tampering_.
- **Usability** — A system is considered to be usable if it allows users to complete their work with _a minimum of error, wasted effort or frustration_. This obviously impinges on the characteristic of efficiency. Much thought and effort has gone into the area of user experience design (or UxD) in the system design community of late (more on this later in this chapter).
- **Maintainability** — A system is maintainable if its program code is both written according to accepted industry standards and is well documented such that_ errors can easily be detected and corrected_ (see transparency below), and new features can be added (or existing ones deleted) with minimal impact on the metrics of other important system characteristics (such as efficiency). 
- **Transparency** — A system is transparent if it is designed in such a way as to allow _metrics on its other characteristics to be tested and gauged_. Thus a system should afford testing of reliability, accuracy, etc.
- **Availability** — A system is considered available if it is online and readily accessible to do the job for which it was designed. 
- **Recoverability** — A system is recoverable if it can be brought back online quickly and with minimal data loss following a system outage caused by any type of problem. This requirement demands that a disaster recovery plan be in place and enforced.
- **Interoperability** — A system is considered to be interoperable if it “plays well with others.”  In other words, it fits well into the infrastructure and is a seamless player with whatever other processes or systems of which it is a part in the organisation. A good system should be virtually transparent – just quietly goes about doing what it is tasked with doing. 
##What's at stake?

Large organisations spend a lot (a LOT) of their resources on systems development, training and maintenance. How much? One study published by McKinsey claimed that organisations spend around 50% ([some report](http://www.mckinsey.com/insights/business_technology/enhancing_the_efficiency_and_effectiveness_of_application_development) up to 60% in the US) of their total IT budget on application development. But even given the big bucks spent, "... the quality of execution leaves much to be desired." Furthermore, they offered that "A joint study by McKinsey and Oxford University found that large software projects on average run 66 percent over budget and 33 percent over schedule; as many as 17 percent of projects go so badly that they can threaten the very existence of the company." Yikes!

[[Interested?](http://www.mckinsey.com/insights/business_technology/achieving_success_in_large_complex_software_projects?cid=other-eml-ttn-mip-mck-oth-1412)]

##Building a system?

To the quality metrics introduced above must be added and separate but related dimension -- that of timeliness of delivery. Often, organisations face problems that demand immediate solution or are presented with opportunities the window to which is fleeting and fast closing. So solutions need to be timely.

A McKinsey/Oxford University [study](http://www.mckinsey.com/insights/business_technology/developing_talent_for_large_it_projects?cid=other-eml-ttn-mip-mck-oth-1412) reported that "... 71 percent of large IT projects face cost overruns, and 33 percent of projects are around 50 percent over budget. On average, large IT projects deliver 56 percent less value than predicted."

So it's clear that there are real challenges in system development and in the related field of Project Management as it impacts large software development (more on this later). Clearly the software development community is aware of their quality and timeliness issues. More needs to be done, however, to improve on these critical metrics.

How then is development actually accomplished? Whether the decision is to in-source or outsource, there are several paths that systems development can take.

## Systems development methods
As systems development evolved from an art to a science and increasingly came under the scrutiny of project management (seeking predictable structure) and cost accounting (fixated on ROI), methods were needed to ensure that systems were delivered on time, to specification, were efficient, accurate and maintainable, thus providing the longest possible period of trouble-free operation and thus a decent return on the significant investment put into them.

Indeed, methods were created and rigour was added and metrics were devised. The basic steps in systems development do not vary much from method to method. Their arrangement, sequencing and whether they can be revisited once complete (or indeed if they are ever completed at all) is what creates the various flavours of systems development. It is on a tour of many such methods that we now embark. But first, the progenitor.

###The Systems Development Life Cycle (SDLC)
The first such formalised method was the Systems Development Life Cycle, a so-called _waterfall method_.

The SDLC is referred to as a _waterfall method_ since it's steps resemble a waterfall; in order for water to reach the bottom of a waterfall, it must pass along the entire difference between the top of the falls (system conception) to the bottom of the falls (system retirement). You can't skip any of the distance along the way. Equally, once the water has reached any fixed point, there's no going back. It's all one way, and the only way is to finish the plunge to the bottom.

Figure ZZ shows the Systems DLC (as opposed to the Software DLC discussed later) illustrating the seven phases and accompanied by a whimsical estimate, through images, of the cost of finding and fixing errors at the various stages of the cycle. Image, if you will, the associated animal appearing suddenly, unannounced, in your home. What would it take to remedy the situation? The fly is a simple nuisance. Image the structural havoc to your home of having to deal with a 6,500+ kg. bull elephant in your kitchen.

That’s the order of magnitude issue faced by software developers who use the SDLC. The US space agency NASA estimates that, on average, it can take upwards of 100 times the resources to fix an error discovered after delivery (implementation) than if the error were discovered in the requirements or early design phase of development. Some estimates are up to 1,000 times.   
[Interested?] http://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20100036670.pdf
SDLC Phases ![SDLC Phases](http://riordan.ca/images/systemsDLC.png)

Let’s take a quick look at what happens during each of these eight phases of the SDLC. 

| Phase # | Phase | Activities | Cost of errors |
| :-: | :-: | :- | :-: |
| 1 | Inception & feasibility | This is where the idea for a new system bubbles up from the organisation through innovation, error detection or challenges arising from competitors or regulatory or market changes. The possibility of a new system arises here where it gets a preliminary scan (see Chapter # where we discuss governance and decision making) and the general parameters of the organisational response are set. This is a gateway stage. The questions at this stage are “Here’s the situation. Can a system help us here?” Approval is critical. A no-go means end of discussion. | ![Fly](http://riordan.ca/images/fly.png) |
| 2 | Requirements analysis | Given a preliminary go at the inception stage, analysts of both types (business and systems) begin to gather the requirements for the system. What problem is the system supposed to solve? Who will the users be? What inputs are required and what are the expected outputs? Fairly broad, general requirements lead to quite specific details as analysis and fact finding progress.  Two types of requirements are gathered in this stage: Functional (what the system must do), including:  business rules, transaction corrections and adjustments, administrative functions, authentication, audit tracking, external interfaces, certification requirements, and reporting requirements, among others. The second set of requirements revolve around non-functional requirements (what qualities the system must have and to what standards is it subject - see discussion in this chapter entitled _What makes a quality system?_) Requirements here include: scalability, capacity, availability, reliability, recoverability, maintainability, serviceability, security, regulatory, manageability, environmental, data integrity, usability, interoperability and performance. [Interested?] (http://usabilitygeek.com/requirements-gathering-user-experience-pt1/) |![Mouse](http://riordan.ca/images/mouse.png) |
| 3 | Design | There are two distinct types of design occurring in the design phase: Logical and Physical.  In the logical design sub-phase, analysts are concerned with high-level models and abstract representations of data flows and the inputs and outputs of the system. Data might just be referred to as “data” with no attempt to describe the characteristics at all. This phase if conceptual, as in going no deeper than the “concept” of a system and what it might broadly be tasked with in terms of the requirements gathered in phase 2. This is the “what” of system design – just broadly _what_ a system will do, but not _how_ it will be accomplished. The physical design activity, on the other hand, gets into the nitty-gritty of exactly _how_ things will get done. Data and storage and process and input/output details are considered down to the most minute detail. Tools that analysts use in this process include Data Flow Diagrams (DFDs) and Entity-Relationship Diagrams (ERs or ERDs) and Unified Modelling Language (UML – see discussion this chapter) diagrams.. This is where the system is “scoped out” in preparation for building it, a phase that requires exact detail. Details such as exact inputs, process and output displayed and/or stored are carefully specified here. It is at this stage that user interfaces are designed. This is one of the most critical and creative pieces of software design. See the discussion in this chapter regarding Ux design. |![Bunny](http://riordan.ca/images/bunny.png) |
| 4 | Development & coding | In this phase, the design emanating from the previous phase is programmed into actual software. Hardware such as computers, servers and even satellites, if required, is purchased. Service contracts for things such as cloud storage are negotiated and initiated. Software systems such as commercial databases are purchased, installed and configured while code is being written to access them. Requirements are put into action. Coding is accomplished using a language appropriate to the target environment (mainframe, desktop, Windows, Mac, mobile, Android, iOS, etc.) using any one or more of the many, many coding languages available. |![Cat](http://riordan.ca/images/cat.png) |
| 5 | Testing & verification | The testing phase measures the actual versus expected outcome of the system. The outcome expectations are based on the system requirements elicited in the requirements stage. The goal of testing is to find and fix unexpected outcomes when actually executing the system as built in the design phase.  There are numerous types of testing, culminating in _beta testing_ (where sometimes the public is invited to use a system for free and to report bugs to the developers) and _acceptance testing_ (where the actual users of the system, which is in production-ready mode, are tasked with giving their final approval, or acceptance). While the SDLC (as a waterfall method) is no given to iterative development (test, find, fix, test…), testing is often conducted in this fashion. So quite unlike other phases of the SDLC, where discovering serious errors necessitates moving all the way back to the feasibility stage and a restart, testing often uncovers minor issues in coding, for example, that can be fixed quickly and without resetting the whole project. A specific type of testing, in fact, is dedicated to this iterative process. This type is _regression testing_ wherein the system is re-tested to make sure that fixes to previous bugs have not introduced errors in previously error-free code. The beat goes on.  The importance of testing cannot be overstated. [Interested?]( http://www.waterfall-model.com/sdlc-test-phases/)| ![Dog](http://riordan.ca/images/dog.png) |
| 6 | Implementation & integration| In this phase, the fully-tested system is put into production in the target environment. The choice of how to _transition_ to the (often) new system is an important one. See Table ZZZ for a comparison. Additionally, the new system must often be integrated with existing systems and workflows in the organisation. This is especially, though not exclusively, important when implementing a COTS system. All the pieces need to work together in order to create value. |![Horse](http://riordan.ca/images/horse.png) |
| 7 | Maintenance & Evaluation| In this stage, the system is subject to monitoring to ensure that it continues to create value and meet the expectations of the organisation and the users of the system. Small, incremental additions, deletions, fixes and improvements are made on an ongoing basis. Recall that Gartner has reported that 92% or the total cost of system ownership is accounted for by activities in the Maintenance phase. |![Elephant](http://riordan.ca/images/elephant.png) |
| 8 | Retirement | Finally, as with everything, the end eventually arrives. When a system cannot be further patched or tweaked and has stopped creating value (for whatever reason), it’s time to retire it and move on. Note the line in Chart XX points directly back to Inception and Feasibility. Time to start again. At this point, several critical tasks must be undertaken, including securing the input and output data, both current and historical, involved with the system. Retiring a system shouldn’t retire the data associated with it. |![Headstone](http://riordan.ca/images/headstone.png)|

++ DOCUMENTATION
++DFDs + ERDs and UML and USE CASES

The various flavours of AGILE include SCRUM, LEAN and EXTREME PROGRAMMING. 

Regardless of what you might think of the SDLC in terms of its viability for creating systems, the stark truth is that all methods (more of which we are about to discuss) must touch each and every phase of the SDLC if they hope to produce a software system. It is in the emphasis, sequence, timing and duration of time spent on each phase that is the major differentiator between the various methods of systems development. 

## Prototyping

###Overview
The purpose of prototyping is to allow users of the software to get early and frequent insights into the design of the system by allowing users to actually use the system before its complete, rather than having to either simply read about features and processes or, in the worst case, to wait until they are tasked with acceptance testing of the finished product. Prototyping can thus better protect against the potential catastrophe attendant upon “finding the elephant” at the end of the development process. 
Prototyping is also often used to “try out” improvements to the system that were not part of the original specification but which “occurred to” the developers in the process of building the system. 

Figure LJ. The prototyping process![SDLC Phases](http://riordan.ca/images/proto.png)

Figure LJ provides a pictorial overview of the prototyping process as it relates to software development. First, note that there are no more bunnies, cats or dogs as a cost of finding errors. Replaced with a bunch of mice becasue there's not as much at stake. The exposed system is smaller, the changes more easily made and the investment in development much smaller. This is great. 

Next, note that the red lines connecting steps 3, 4 and 5, unlike in the SDLC, can be repeated (or iterated) as often as necessary until the evaluation at step 6 branches to step 7, effectively exiting the prototype loop when the system is ready for delivery. The obviously pivotal step is #6, where the outcome of the prototype evaluation can branch to either a refinement of the current design (step 3), a revisit of the system requirements (if the prototype is introducing a refinement) or to the delivery of a finished product (step 7). 
### The prototyping process for software development
1.	Project inception and feasibility stage is a given. We don’t just start producing a system out of nowhere. There must be demonstrated need and management approval if working in a large organisation.
2.	Perform a basic requirements analysis, but not as in-depth as in the SDLC. Often, the riskiest bits of the system are modelled early. If you can do the hard stuff, the easy stuff will fall into place. So we get the nitty-gritty details; the make-or-break stuff.  Often, difficult but manageable details such as security are ignored in the early stages. 
3.	A prototype is developed, often including only user interfaces in the earliest stages. This is referred to as Horizontal Prototyping (discussed below). In later stages, Vertical Prototyping is used to drill down deep into the system to model the full functionality of a feature or required process. 
4.	The prototype at whatever stage it’s currently at is shown to the clients (end users) to elicit feedback. 
5.	The feedback provided in step 4 is used to revise and enhance the prototype. New features or screens are added in an incremental fashion and we return to step 3, continuing in this fashion until a deliverable system is produced. 
Usability Engineer Jakob Neilson described the various types of prototyping in his 1993 book entitled Usability Engineering (Academic Press Inc.). Two are relevant to us in this context: 
### Horizontal 
A user interface prototype is referred to as a horizontal prototype. Such a prototype provides an overview of a complete system or a significant subsystem, with an emphasis on how the user uses the system rather than how the system processes user input. Such prototypes are useful to confirm the logic and flow of user interfaces and setting the broad parameters of what the system (or sub-system) is expected to do. Furthermore, they can help in developing some metrics around anticipated time and resources required to deliver the full system. Finally, such prototypes often have the benefit of securing _buy-in_ from decision makers at the organisation as they can see and more tangibly grasp the overall scope, and thus value, of the proposed system. 
### Vertical 
A vertical prototype is an in-depth elaboration of a single process, subsystem or function. Such prototypes are useful in discovering detailed requirements, such as the “risky bits” of a system and to demonstrate that they can be accomplished.  The benefits of vertical prototyping include determining details of data modelling (database design)and in getting a handle on processing volume requirements (how many transactions, or basic units of work) a system is required to be capable of doing, 
Further distinctions are made between Throwaway and Evolutionary prototypes. The former is just as its name imp[lies, and is not as often used in software prototyping as the latter, which retains its basic structure and functionality throughout the process to become the final system.

### Benefits
Prototyping has several benefits: 
1.	Valuable user feedback is elicited early and often
2.	Requirements can be more easily verified
3.	Metrics around cost and time are iteratively brought into focus
4.	Users are much more likely to buy into the system and support its use when in production as they had a stake and a voice in its development
5.	Training requirements for users are significantly reduced as users have been exposed to the system often and have trained themselves on its use

Table RM provides a comparison between SDLC and prototyping on some important dimensions. 

Table RM. A comparison of SDLC and prototyping

| Development Method | SDLC | Prototyping |
| :- | :-: | :-: |
| When user requirements are poorly specified | Poor |  Excellent |
| When developers are using unfamiliar technology | Poor | Better |
| When developers are using proven technology | Good | Better |
| With complex projects | Good | Good |
| When delivery deadlines are tight | Poor | Good  |
| When technology is changing rapidly | Poor | Good |
| When continuous management buy-in is crucial | Poor | Better |
| When user buy-in and support is critical | Poor | Excellent |
| When audit trails and multi-level signoff are critical | Excellent | Poor  |


### Agile and Scrum
So-called lightweight agile software development methods evolved in the mid-1990s in reaction to the heavyweight waterfall-oriented methods, which critics called heavily regulated, regimented, micromanaged and over-incremental.
Proponents of lightweight agile methods contend that they are returning to development practices that were present early in the history of software.[2]
Early implementations of agile methods include unified process (1994), scrum (1995), Crystal Clear, extreme programming (1996), adaptive software development, feature-driven development (1997), and dynamic systems development method (DSDM) (1995). These are now collectively referred to as agile development, after the Agile Manifesto was published in 2001.[6]
http://en.wikipedia.org/wiki/Agile_software_development#The_Agile_Manifesto
Agile Principles:
1.	Our highest priority is to satisfy the customer through early and continuous delivery of valuable software. Welcome changing requirements, even late in development. Agile processes harness change for the customer’s competitive advantage. 
2.	Deliver working software frequently, from a couple of weeks to a couple of months, with a preference to the shorter timescale. 
3.	Business people and developers must work together daily throughout the project. 
4.	Build projects around motivated individuals. Give them the environment and support they need, and trust them to get the job done. 
5.	The most efficient and effective method of conveying information to and within a development team is face-to-face conversation. 
6.	Working software is the primary measure of progress. 
7.	Agile processes promote sustainable development. The sponsors, developers, and users should be able to maintain a constant pace indefinitely. 
8.	Continuous attention to technical excellence and good design enhances agility. 
9.	Simplicity -- the art of maximizing the amount of work not done- is essential. 
10.	The best architectures, requirements, and designs emerge from self- organizing teams. 
11.	At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behavior accordingly. 
Agile Values: 
1.	Individuals and interactions over processes and tools 
2.	Working software over comprehensive documentation 
3.	Customer collaboration over contract negotiation 
4.	Responding to change over following a plan 
That is, while there is value in the items on the right, we value the items on the left more.
Source: agilemanifesto.org/principles.html

![chuckle_bros_efficiency.gif](http://riordan.ca/images/chuckle_bros_efficiency.gif)
[Source: <http://www.gocomics.com/chucklebros>]
