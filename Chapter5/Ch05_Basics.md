#Chapter 5 - Basics ![Basics](https://raw.githubusercontent.com/robertriordan/2400/master/Images/icons/32/mag_10.png)

## The personal side of ICT - What's in ICT for me?

####Productivity

Has technology made us more productive? To begin the conversation about the impact of tech on us as individuals, please read this Gartner article on productivity. Bear in mind it's written by an old guy who was actually there when email was introduced. Like me, he thought is was simply amazing. It was the beginning of all the social media we see today. Read it <a class="underlined-link" href="http://blogs.gartner.com/andrew_white/2016/08/10/are-we-more-productive/" target="_blank">here</a>. Consider this to be part of the textbook (as in required reading).

This leads us to another important discussion in terms of whether ICT has paid serious ROI: The Productivity Paradox. Here's a synopsis from our friends at Wikipedia:

>"The productivity paradox refers to the slowdown in productivity growth in the United States in the 1970s and 80s despite rapid development in the field of information technology (IT) over the same period. During that time, despite dramatic advances in computer power and increasing investment in IT, productivity growth slowed down at the level of the whole U.S. economy, and often within individual sectors of the U.S. economy that had invested heavily in IT. While the computing capacity of the U.S. increased a hundredfold in the 1970s and 1980s, labor [sic] productivity growth slowed from over 3% in the 1960s to roughly 1% in the 1990s. This perceived paradox was popularized in the media by analysts such as Steven Roach and Paul Strassman. The concept is sometimes referred to as the Solow computer paradox in reference to Robert Solow's 1987 quip, 'You can see the computer age everywhere but in the productivity statistics.' The paradox has been defined as a perceived 'discrepancy between measures of investment in information technology and measures of output at the national level.'" [Sources in original]


This touches the very essence of out book-long discussion of ROI, and especially of ROI on ICT investment. Wikipedia continues:

>Many observers disagree that any meaningful 'productivity paradox' exists and others, while acknowledging the disconnect between IT capacity and spending, view it less as a paradox than a series of ... unwarranted assumptions about the impact of technology on productivity. In the latter view, this disconnect is emblematic of our need to understand and do a better job of deploying the technology that becomes available to us rather than an arcane paradox that by its nature is difficult to unravel. Some point to historical parallels with the steam engine and with electricity, where the dividends of a productivity-enhancing disruptive technology were reaped only slowly, with an initial lag, over the course of decades, due to the time required for the technologies to diffuse into common use, and due to the time required to reorganize around and master efficient use of the new technology. As with previous technologies, an extremely large number of initial cutting-edge investments in IT were counterproductive and over-optimistic. Some modest IT-based gains may have been difficult to detect amid the apparent overall slowing of productivity growth, which is generally attributed to one or more of a variety of non-IT factors, such as oil shocks, increased regulation or other cultural changes, a hypothetical decrease in labor [sic] quality, a hypothetical exhaustion or slowdown in non-IT innovation, and/or a coincidence of sector-specific problems.

Academic studies of aggregate U.S. data from the 1970s and 1980s failed to find evidence that IT significantly increased overall productivity. However, the 1990s saw evidence of a delayed IT-related productivity jump, arguably resolving the original paradox; the broader issue of what measurable factors best explain the dramatic productivity ups-and-downs of the past two hundred years, as well as whether the rate of productivity growth is more likely to increase or to decrease in the decades ahead, remains a subject of contentious study." [Sources in original]

<a class="underlined-link" href="https://en.wikipedia.org/wiki/Productivity_paradox" target="_blank">Source</a>

With this notion of productivity at the national level under our belt, let's switch focus to the individual level, which is what this chapter is all about. I frame the discussion in term that we all understand. We all use social media. It's probably the biggest external tool we use in any day. It takes the most time to manage and thus should potentially provide a great return to us on our investment of time (and in keeping our tech tools up to date and connected). Let's see. 

#### Social Media (SM)

Here's a great quote form a book on machine learning (which we discuss below in the context of algorithms). It introduces nicely the topic of Social Media.

>"A few thousands of years ago, you needed to be a god or goddess if you wanted to be painted, be sculpted, or have your story remembered and told. A thousand years ago you needed to be a king or queen, and a few centuries ago you needed to be a rich merchant, or in the household of one. Now anybody, even a soup can, can be painted. A similar democratization has also taken place in computing and data. Once only large organizations and businesses had tasks worthy of a computer and hence only they had data; starting with the personal computer, people and even objects became generators of data. 
>
>"A recent source of data is social media, where our social interactions have become digital; these now constitute another type of data that can be collected, stored, and analyzed. Social media replaces discussions in the agora, piazza, market, coffeehouse, and pub, or at the gathering by the spring, the well, and the water cooler. 
>
>"With social media, each of us is now a celebrity whose life is worth following, and we are our own paparazzi. We are no longer allotted only fifteen minutes of fame, but every time we are online we are famous. The social media allows us to write our digital autobiography as we are living it. In the old times, books and newspapers were expensive and hence scarce; we could keep track of and tell the story of only important lives. Now data is cheap and we are all kings and queens of our little online fiefdoms. A baby born to gadget-loving parents today can generate more data in her first month than it took for Homer to narrate the complete adventures of Odysseus."

Source: Alpaydin, Ethem. Machine Learning: The New AI (The MIT Press Essential Knowledge series). The MIT Press. 

Given that we (you and I but likely much more you than I) spend a lot (see below) of time on social media, maybe it's high time we took a look at how much return we're getting on it. 

Let's start by quantifying, by example, what I mean by the term *social media*. According to <a class="underlined-link" href="http://www.ebizmba.com/articles/social-networking-websites" target="_blank">ebizmedia.com</a>, the top 15 most popular social media sites in October 2016 were:

1. Facebook (by far!)
2. YouTube
3. Twitter
4. LinkedIn
5. Pinterest
6. Google+
7. Tumblr
8. Instagram
9. reddit
10. VK
11. Flickr
12. Vine
13. meetup
14. ask.fm
15. ClassMates 

And not a Snapchat among them. Interesting eh? <a class="underlined-link" href="http://startouch.thestar.com/screens/348f6e41-9790-4816-9eac-2b2f5a0cd690%7C_0.html" target="_blank">Interested in a different view on Snapchat?</a>

But here is a slightly different list, from Wikipedia but equally current, with some important differences:

>"This is a list of the leading social networks based on number of active user accounts as of September 2016: 

1. Facebook 1,712,000,000 users.
1. WhatsApp 1,000,000,000 users.
1. Facebook Messenger: 1,000,000,000 users.
1. QQ: 899,000,000 users.
1. WeChat: 806,000,000 users.
1. QZone: 652,000,000 users.
1. Tumblr: 555,000,000 users.
1. Instagram: 500,000,000 users.
1. Twitter: 313,000,000 users.
1. Baidu Tieba: 300,000,000 users.
1. Skype: 300,000,000 users.
1. Sina Weibo: 282,000,000 users.
1. Viber: 249,000,000 users.
1. Line: 218,000,000 users.
1. Snapchat: 200,000,000 users."

<a class="underlined-link" href="https://en.wikipedia.org/wiki/Social_media" target="_blank">Source</a>

The differences between the lists underlines the difficulty in nailing down exactly what SM is and where SM is measured. With the folding of the SM site Vine in October 2016 week, the field is changing.

While it may be changing, it is also enormous. Take a look at the range of SM sites and services available:

**Figure DDSF. Social Media landscape**

![Social Media Landscape](https://raw.githubusercontent.com/robertriordan/2400/master/Images/social_media_types.jpg)

<a class="underlined-link" href="https://en.wikipedia.org/wiki/Social_media" target="_blank">Source</a>

Now let's look at some statistics on SM usage. Despite some really glaring thinko/typo errors in this infographic, it has an interesting story to tell.

**Figure JDRB. Social Media Usage**

![Social Media Usage](https://raw.githubusercontent.com/robertriordan/2400/master/Images/social_media.png)

<a class="underlined-link" href="http://www.adweek.com/socialtimes/social-media-addiction-stats/504131"target="_blank">*Source*</a>

Now some more recent (2016) statistics from :

![2016 stats](https://raw.githubusercontent.com/robertriordan/2400/master/Images/social-media-usage-stats-in-2016.jpg)

And this from <a class="underlined-link" href="http://growingsocialmedia.com/social-media-facts-and-statistics-for-2016/" target="_blank">growingsocialmedia.com</a>:

<div style="width:100%;margin:10px 0;"><iframe src="https://w.graphiq.com/w/3rqjtCzPh9r" width="600" height="554" frameborder="0" scrolling="no" style="position:static;vertical-align:top;margin:0 auto;display:block;width:600px !important;max-width:100%;min-height:554px !important;max-height:none !important;border:none;overflow:hidden;"></iframe><div style="text-align:center;font:14px/16px Helvetica,arial;color:#3d3d3d;"><a target="_blank" href="http://web-browsers.softwareinsider.com" style="color:#3d3d3d;">SoftwareInsider | Graphiq</a></div></div>

<div style="width:100%;margin:10px 0;"><iframe src="https://w.graphiq.com/w/5fcPr0oWTT7" width="600" height="495" frameborder="0" scrolling="no" style="position:static;vertical-align:top;margin:0 auto;display:block;width:600px !important;max-width:100%;min-height:495px !important;max-height:none !important;border:none;overflow:hidden;"></iframe><div style="text-align:center;font:14px/16px Helvetica,arial;color:#3d3d3d;"><a target="_blank" href="https://www.graphiq.com/vlp/5fcPr0oWTT7" style="color:#3d3d3d;">FindTheCompany | Graphiq</a></div></div>

Why do people use SM? Here is an interesting article: http://www.onepoll.com/10-reasons-people-use-social-media/

Despite the fact that the survey link is broken, this is an interesting place to start:

>"A recent study [link broken] by Whiting and Williams interviewed a range of social media users and explored what keeps them coming back to social networks. They found that people use SM for the following reasons (I assume not in any particular order.) I have added some editorial comment following each reason in [square brackets].

>Social interaction – social media, not surprisingly, allows people to be social. They meet new people and keep in touch with friends, acquaintances and family. [People are social animals - we need social interaction or at least *most* of us do - in order to validate our existence. SM provides such contact, albeit not very *rich* contact. Physical touch is essential.]
>
Information seeking – this refers to the process of finding information about products/services, keeping up to date with real-world social events, and learning new things. [Humans are innately curious about our surroundings. We have survived through the millennia by being constantly aware of what is in our surroundings and what is friend and what is foe. This is context.]
>
Passing time – social media is a great time killer and can cure boredom whether at home, at school, or in the work place. [See later stats about just how much of our online time at work is actually work!]
>
Entertainment – games, music and videos are all accessed through social media. Watching the stream of updates from people is also a form of entertainment – whether intentionally humorous or not. [We all need a break from time to time. essentially the same as Passing time (above) and Relaxation (below).]
>
Relaxation – whilst people find others' updates humorous, they also find them relaxing. Social media is a way to alleviate stress and escape from reality. [I'm not so sure this is any different from Entertainment...]
>
Expression of opinions – expressing thoughts and opinions, criticizing others and blowing off steam (either anonymously or named) is regularly undertaken through social media. [But trolling is a nasty business.]
>
Things to talk about – like the daily newspaper, social media provide subject matter for people to talk and gossip about with others. [This is information seeking so doesn't merit a separate category.]
>
Convenience – social media is readily accessible, even more so as mobile devices become ubiquitous. Furthermore, people can talk to several people at the same time. [Convenience is not a human need as far as I understand. We like to be efficient, sometimes... The second part about multi-channel is valid but this is simply Sharing information (below) and Social interaction (above).]
>
Sharing information – people can use social media to broadcast things about themselves. By publishing updates, videos and pictures, people market their own personal brand or business. [The marketing part I agree with, but the broadcasting is too similar to expressing of opinions to warrant specific mention here.] 

>Knowing about others – social media allows a window into the lives of others. By checking out other profiles, they can be nosey or ‘keep up with the Jones’’. [Way too similar to Information seeking and Social interaction.]"

All in all I would take much of this research with a grain of salt. There is a lot of category overlap and bleed. It does inject some interesting context into the discussion.

Here is a technical definition of social media from our friends at Wikipedia (accessed October 29, 2016) from the usage statistics entry cited above:

>"Social media are computer-mediated technologies that allow individuals, companies, NGOs, governments, and other organizations to view, create and share information, ideas, career interests, and other forms of expression via virtual communities and networks. The variety of stand-alone and built-in social media services currently available introduces challenges of definition; however, there are some common features:
>
- social media are interactive Web 2.0 Internet-based applications
- user-generated content such as text posts or comments, digital photos or videos, as well as data generated through all online interactions, are the lifeblood of the social media organism
- users create service-specific profiles for the website or app, that are designed and maintained by the social media organization and
- social media facilitate the development of online social networks by connecting a user's profile with those of other individuals and/or groups."

They add further that:

>"Social media use web-based and mobile technologies on smartphones and tablet computers to create highly interactive platforms through which individuals, communities and organizations can share, co-create, discuss, and modify user-generated content or pre-made content posted online. They introduce substantial and pervasive changes to communication between businesses, organizations, communities, and individuals. Social media changes the way individuals and large organizations communicate. These changes are the focus of the emerging field of technoself studies.
>
>"Social media differ from paper-based or traditional electronic media such as TV broadcasting in many ways, including quality, reach, frequency, usability, immediacy, and permanence. Social media operate in a dialogic transmission system (many sources to many receivers). This is in contrast to traditional media that operates under a monologic transmission model (one source to many receivers), such as a paper newspaper which is delivered to many subscribers. Some of the most popular social media websites are Facebook (and its associated Facebook Messenger), WhatsApp, Tumblr, Instagram, Twitter, Baidu Tieba, Pinterest, LinkedIn, Gab, Google+, YouTube, Viber and Snapchat."

So let's boil that down to what I think are the main reasons people use SM. Here's my list:

1. Social interaction
1. Data seeking and sharing
1. Diversion (entertainment, passing time and relaxation)
1. Marketing one's personal brand
1. And one that's *not* included above: creating *meaning* from our experiences

Looking first at #5 above, we have an interesting challenge. People will create meaning from their experiences whether they use social media or not, SM simply being one way to do that. But what do I mean when I write "create meaning"? Meaning is interpretation. Meaning involves perception and context. Humans are unlike all other creatures (we humans believe) because we alone are searching for answers to the big question of life: "Why?" We have created all kinds of explanations for things down through the ages. Science is but another tool for creating order and meaning in and among natural phenomena. And social media can assist. In order to create meaning, all we need is agreement on interpretation. Something happens (lightening strikes the earth) and someone creates an interpretation of it (the gods are unhappy with us for driving Volkswagens!). Interpretation is important to humans because we seek to understand cause and effect. We get a *Dopamine rush* when we search for meaning and an *opioid hit* when we find it. This *community of understanding* is vital to us. And SM allows us to create such communities and to come to shared understandings of the contextual soup in which we live. 

Considering the first four above, there's nothing *particularly special* about social media as opposed to other forms of human interaction. We use SM in much the same way we have used newspapers, libraries, movie theatres, radio and TV in the past. But what *is* different is the ability SM gives us to reach out to a wide audience, and to receive from a wide variety of sources, both in real time. This *marketing of personal brand* is unprecedented in history. We do need to ask though, with everyone doing personal marketing on such a grand scale, is there enough time to listen?

In this regard, I'm reminded of research by British Anthropologist Robin Dunbar, discussed by Malcolm Gladwell in his iconic year 2000 book *The Tipping Point: How Little Things Can Make a Big Difference* (Back Bay Books, pp: 177-181, 185-86). Gladwell reports on Dunbar's findings that, all through history, humans have kept their optimal social group size surprisingly constant at around 150. Dunbar's research demonstrates that it is the size of the human neocortex (a region of the brain) that dictates the maximum number of *relationships* both direct and between the others in the group. This 150 figure is remarkably consistent across all manner of social groups (including military) over recorded history. Our little brain just can't handle any more complexity than that. The social fabric begins to unravel when numbers in a group get too far beyond this optimal level.  

Interested in neocortex? https://en.wikipedia.org/wiki/Neocortex

Interested in Dunbar's Number? https://en.wikipedia.org/wiki/Dunbar%27s_number

So we need to ask. Are we expanding our network by using SM or are we simply spreading ourselves thinner? Or maybe we are expanding our network but at the expense of the quality of our closest relationships? The *social platform* we use (Facebook, Twitter, Instagram, etc.) keeps track of much of what we would otherwise need to process in our little brains. It allows us to scroll back through our timeline to see what was happening and what we and others were thinking and talking about last week or last month or last year. We are freed from having to keep all that detail in our own memory - the cloud does it for us. Perhaps this allows us to artificially extend our network beyond the 150 mark?

There is also some greater potential collective good that can come of social media use. Have a read:

>"... consider the Arab Spring of 2011, and the anniversary of the revolution in Egypt this year. The question has repeatedly been posed as to whether the Internet, specifically social media platforms like Facebook and Twitter, had caused the revolution. Two kinds of answers typically follow. First, the qualified yes: these technological media were necessary but not sufficient, they provided new capacities for organization that previous revolutions did not possess. Second, the concerted no: the technologies are important, but the necessary and sufficient cause of the revolution was 'the people.'  No one (except Biz Stone and Mark Zuckerberg) believes that these tools actually cause revolutions.

>"Both answers miss the mark, but they nonetheless point to one of those well-worn paths of argument. On the one hand there are technologies that create new relationships, new capacities, or re-arrange existing relationships of knowledge and power.  On the other hand, there are the reassuringly familiar collectivities—like 'the people' or 'the public' or 'the community.' Sometimes information technologies are invoked as a threat to older forms of collective life; other times, especially in response to inflated claims about the power of those technologies, they are seen as irrelevant to the power of known collectives. Do information technologies connect existing collectivities or do they generate the conditions of possibility for new collectivities—maybe even new kinds of collectivity?"

<a class="underlined-link" href="http://limn.it/preface-crowds-and-clouds/](http://limn.it/preface-crowds-and-clouds/" target="_blank">Interested?</a>

![LinkedIn](https://raw.githubusercontent.com/robertriordan/2400/master/Images/linkedin.PNG)

But let me share something with you. As of November 13, 2016, I have 1,599 connections in my LinkedIn network. And I ask myself *Why?* I spend some part of nearly every day simply maintaining that network, saying "Congrats on the new job!" or approving (or more likely rejecting) new requests for inclusion in my *exclusive network* of 1,600 close associates (#sarcasm). I recently approved a request from an HR Project Coordinator at the Royal College of Physicians and Surgeons of Canada. And I don't know why. I took the time to examine her profile and to check our common connections and then said yes to her request. But I'm not sure what it gives me at this point in my career. I'm not going to change jobs and we have little or nothing in common (except my background in Epidemiology I suppose) that would lead to a synergistic relationship. So what kind of collective or community is this LinkedIn thing of mine? And what kid of community created the Arab Spring? And what kind of community comes together around a public tragedy such as a shooting or a hurricane or an earthquake? Are such communities artificial in comparison to those crowds that assemble physically and have a palpable presence and can cause the ground to shake. Is the community formed by those watching a Blue Jays game on TV different from the crowd that assembles on the lake shore in Toronto when the Jays play the Rogers Centre? Certainly they are different, but in what ways? One is virtual and one is physical and that distinction frames the distinction between them.  

This distinction defines the hit we take on the quality of our *physical* interactions. We maintain these artificially-outsized networks in an increasingly insular way. How many times have you seen a scene such as below? People not interacting on a personal level, even given the opportunity, because they are occupied with their device, either answering some sort of correspondence, updating their status or snapping a selfie for *posterity*. I'm willing to wager that upwards of 95% of all photos taken today are *never looked at again*. Ever. And we missed the moment by trying to preserve it. Next time you watch an Olympic opening ceremony on TV (unless you are lucky enough to actually *be there*), note how many are watching it through their smartphone or other tech device. We need to return to *being there*. Just saying. 

**Image SECC. People in the moment?**

![People and their Phones](https://raw.githubusercontent.com/robertriordan/2400/master/Images/people_smartphones.jpg)

#### Social Media ROI

Are we getting value from our use of Social Media? There's no reason not to use the same metrics that firms use to measure their ROI on their efforts to get their message out there. Let's use some standard tools and see what your personal ROI on social media is. 

Step 1: I will define social media as *any technology tool that allows the sending and/or receipt of messages to and/or from one or more members of your relevant social network of family and either existing or potential friends, contacts, employers, lovers or haters.* (A long list of SM appears above in this Chapter).

Step 2: A simple definition of *ROI* as:

	ROI = (return – investment) / investment 

Step 3: Define *investment*. For personal users of social media, those who aren't *selling something* in the commercial sense, the investment we make in social media can only be measured in *time*. How many minutes we spend in a defined time period engaging in social media activities. Those minutes are your investment. Your resource spend. Let's quantify this arbitrarily. Some [fairly specific data](http://www.marketingcharts.com/online/social-networking-eats-up-3-hours-per-day-for-the-average-american-user-26049/) suggest that young people (18-34) spend 3.8 hours a day on social media, and some quick calculations yield that females spend 32% more time on SM than do males. This is in part due to their higher propensity to actually *use* SM, but also due to their increased time spend when on. So not only do females participate more often than males, but they also spend more time per person than males. But the traditional gender gap is closing. <a class="underlined-link" href=" http://www.pewresearch.org/fact-tank/2015/08/28/men-catch-up-with-women-on-overall-social-media-use/" target="_blank">Interested in up-to-date stats on social media use by gender?</a>

<a class="underlined-link" href="http://www.pewresearch.org/fact-tank/2013/09/12/its-a-womans-social-media-world/" target="_blank">Interested in more on gender?</a> 


**Figure NAFL: Social media use by platform and gender, 2015**

![Social Media Usage](https://raw.githubusercontent.com/robertriordan/2400/master/Images/sm_usage.png)

Step 4 - Define *return*. What does it mean in terms of your personal efforts? What do you want/expect to achieve by spending time on social media? What's a return on using Facebook, for example? What's the return on a tweet? For marketing or sales firms, those answers are a little easier (though not much) to nail down. A new *follower*? A re-tweet? A product brochure download? A sale? Some of these are more concrete than others, but there's a progression, culminating in the ultimate for a business: revenue. But for you or I, personally, what kind of meaningful return can we measure? 

I don't have an answer. I get nothing back from LinkedIn that is of any value to me personally or professionally. I don't participate in Facebook anymore (I did at the very beginning but it became just overwhelming, maintaining my network and keeping up - there was no value). I stopped years ago, long before my own mother got an account. At 93, she's on Facebook. That's a great reason for me *not* to be. When your mother wants to friend you, it's time to bail. I use Twitter sparingly. I got in early on Snapchat, but, as you might imagine, I don't get much use from it. I don't have an Instagram account, though one of my dear friends spends part of the little time we can manage to spend together at a quarterly lunch in maintaining his pictorial account of the exotic vacations upon which he and his wife go. I sometime say "Hey! I'm talking to you!" It doesn't phase him.

Thus we need also to determine what our goals are for using SM. What do you expect to achieve?

<a class="underlined-link" href="https://blog.hootsuite.com/measure-social-media-roi-business/" target="_blank">Hootsuite </a> has this to say about measuring the value of a social media programme for business:

>"Measuring your social media ROI is important for countless reasons, including, but not limited to: 
>
> 1. Proving the value of social media to your organization’s overall goals and business objectives
1. Allowing you to clearly see where efforts and resources are being used efficiently
1. Enabling you to evaluate where resources are being wasted, or not used as efficiently as possible
1. Allowing you to recognize gaps in strategy, key messages, and content
1. Showing where your social media budget is being used most effectively, and showing areas where it can be pulled back"

Let's look at these from a personal perspective. 

1. How would you, personally, go about the task of proving the value of social media to your overall objectives? And what are your overall objectives for using SM? FOMO (Fear of Missing Out)? Meeting people? Having quality relationships? Getting a job or a promotion? Staying in touch? Relaxation? Make a list. Which goals can you quantify? Can you measure relaxation? Does playing a fast-paced action game count as relaxation, entertainment or diversion? So make your list and then attach some kind of value to each one. But what value? I'll leave that to you. 
2. Can you easily see which resources (time) are being spent effectively? Which SM interaction using which platform is contributing to your efficient and effective achievement of a goal?
3. The mirror image of #2. Where are you wasting time (your only input resource)? How do you know when it's time to cut and run? 
4. Can you identify where you are missing your targets and how will you get back on track?
5. Can you metricise your inputs and outputs and calculate an ROI?

In unsolicited response to #5 above, I'm going to say no. You can't. There's no clean and defensible way to calculate the ROI from social media use. Yet we use it. We spend countless hours at it. I did a quick estimate using Life Tables (sometimes called mortality tables) for Ontario males and females, and came to some startling conclusions. Using the most conservative estimates (about 3 hours/day for those aged between 0 and 18) and 2 hours/day thereafter, I calculate that you will have spent 228 *full 24-hour days* on social media by your 18th birthday. Furthermore, you will have *social mediad* your way through 743 days (more than *two full years at current rates*) by the time you complete your 35th year on this rock of ours. That same amount of time would give you a decent Master's degree. If you live to the ripe old age of 65, you will have spent nearly 2,200 full, 24-hour days on social media (if anything remotely similar still exists in that faraway future). 

Just think about it. Exactly what kind of return on that time would be worth it? How will you get back the value of more than two full years of your life by age 36? It's mind-boggling. All the more since it is the platforms that are being enriched in tangible assets (real dollars) from your participation. We are left to imagine and *artificially create* (call it rationalise) the value we derive from our participation. 

Returning to the Wikipedia article quoted above, here are some final thoughts on social media.

>"Observers have noted a range of positive and negative impacts from social media use. Social media can help to improve individuals' sense of connectedness with real and/or online communities and social media can be an effective communications (or marketing) tool for corporations, entrepreneurs, nonprofit organizations, including advocacy groups and political parties and governments. At the same time, concerns have been raised about possible links between heavy social media use and depression and even the issues of cyberbullying, online harassment and "trolling". According to Nielsen, Internet users continue to spend more time with social media sites than any other type of site. At the same time, the total time spent on social media in the U.S. across PC and mobile devices increased by 99 percent to 121 billion minutes in July 2012 compared to 66 billion minutes in July 2011."

Imagine what the numbers are today.

<a class="underlined-link" href="https://en.wikipedia.org/wiki/Social_media#Positive_effects" target="_blank">Interested in the positive effects of SM?</a>

<a class="underlined-link" href="https://en.wikipedia.org/wiki/Social_media#Negative_effects" target="_blank">Interested in the negative effects of SM?</a>

You can see the complete life table that I used to derive these figures for males, Ontario, 2009-2011 [here](http://www.statcan.gc.ca/pub/84-537-x/2013005/tbl/tbl7a-eng.htm). Same for females [here](http://www.statcan.gc.ca/pub/84-537-x/2013005/tbl/tbl7b-eng.htm). 

Finally, <a class="underlined-link" href="http://ottawacitizen.com/news/local-news/areyouhappy-twitter-study-suggests-ottawa-has-canadas-happiest-tweeters-sorry-edmonton" target="_blank">perhaps you might be interested in which Canadian city has the happiest Tweets? (spoiler alert - it's Ottawa!)</a>

Time for some XKCD.

![XKCD Phishing](https://raw.githubusercontent.com/robertriordan/2400/master/Images/xkcd_phishing.png)

<a class="underlined-link" href="http://imgs.xkcd.com/comics/phishing_license.png" target="_blank">XKCD Source</a>

BUSI 2400 Fall 2016 please ignore the chunk from here ------------------

Life Logging and the Quantified Self (TK)  https://en.wikipedia.org/wiki/Lifelog also: http://mashable.com/2014/03/20/lifelogging-experiment/ also: http://www.computerworld.com/article/2499169/enterprise-applications/is-the--quantified-self--movement-just-a-fad-.html and for the negative, see: http://www.computerworld.com/article/3048497/personal-technology/lifelogging-is-dead-for-now.html

To here: -------------------------------------

Listen to the first 2:00 minutes of <a class="underlined-link" href="http://www.cbc.ca/radio/ideas/big-data-part-2-1.3658439" target="_blank">this podcast.</a> on big data, security and privacy. 

### Algorithms

If you are in BUSI 2400, you will have already (or will soon) be learning the fundamentals of programming. You may already be an accomplished coder and, if so, you know a good algorithm when you see one. For those new to the field, let's define what we mean. A simple Google search of the term yields the following: An algorithm is "A process or set of rules to be followed in calculations or other problem-solving operations, especially by a computer." So algorithms are technology, broadly defined. They are a set of rules or procedures, collected together and tested and which produce a quantifiable and expected result. 

Thus when Twitter reports what's *Trending*, they are reporting the results obtained by applying an algorithm to their tweet data. When I think of what's trending on Twitter, I think of what's most popular at the moment. What hash tag is most prevalent (most frequently occurring) over the past minute or 5 minutes or hour. But it's more complex than that, according to Twitter. 

A simple *incidence algorithm* would look something like:

	for x = 1 to all hashtags
		trending(x) = hashtag(x) / total_hashtags
	next
	sort trending(x) descending
	for x = 1 to n
		show hashtag(x)
	next
	
Twitter might set 'n' to be 10 or 15, let's say, and then the top 10 or 15 hashtags would be displayed. The algorithm could be run every time someone hits the page, or on a fixed schedule per second, minute or five minutes or at whatever interval Twitter deemed appropriate. Here's what the result of that might look like:

**Figure TTAP. Trending on Twitter, October 28, 2016 ~ 4PM**

![Twitter Trending](https://raw.githubusercontent.com/robertriordan/2400/master/Images/twitter_trending.png)

But when the Twitter hash tag *#occupywallstreet* did not trend despite the Occupy movement being the top news story at the time, there were cries of *censoring* from the blogosphere. But hold on. 

>"Twitter explains that *Trends* is designed to identify topics that are enjoying a surge, not just rising above the normal chatter, but doing so in a particular way. Part of the evaluation includes: Is the use of the term spiking, i.e. accelerating rapidly, or is its growth more gradual? Are the users densely interconnected into a single cluster, or does the term span multiple clusters? Are the tweets unique content, or mostly retweets of the same post? Is this the first time the term has Trended? (If not, the threshold to Trend again is higher.) So this list, though automatically calculated in real time, is also the result of the careful implementation of Twitter’s judgments as to what should count as a “trend.”"

<a class="underlined-link" href="http://limn.it/can-an-algorithm-be-wrong/" target="_blank">Source</a>

Apparently, Twitter's algorithm is quite a bit more sophisticated than our simple *incidence algorithm*. Not only does it matter that a hashtag is popular, it must also be *increasingly* and not just *persistently* popular. This is *spiking*. Not just *up* but persistently *on the way* up. And it can't be popular in isolation. It needs to be popular across what Twitter calls *clusters* of users. And it just can't be any old recurring and spiking and popular story... it's got to have something more. Like not being censored. Sounds like gobbledygook to me. Twitter was trying to hide something IMHO. But who am I to say?

Now take a listen to the first 10 minutes of this <a class="underlined-link" href="http://www.cbc.ca/radio/spark/pastepisodes/259-algorithm-awareness-mindful-multitasking-going-on-a-data-safari-a-crowd-sourced-hunt-for-marginalia-1.2772167?autoplay=true" target="_blank">CBC Spark podcast</a> (this is examinable content so please do plug in and listen). 

####A deeper look at algorithms

ZDNET (a tech publishing service) has this to offer on algorithms. Reporting on a talk given by Peter Sondergaard, a research chief at well-respected tech consultancy Gartner, they wrote:

>"'Big data is not where the value is,' said Sondergaard. 'Algorithm is where the real value lies. Algorithms are where the action lies. Data is dumb. Algorithms define the way the world works.'"

They further shared that:

>"'A market for algorithms will emerge,' said Sondergaard.

>The platforms that enterprises rely on will be powered by algorithms. Cortana, Siri and the like are just precursors to what's coming. [...] Technology giants such as Microsoft may not provide apps, but algorithms and analytics. Is there any wonder why IBM, Microsoft, Google and Amazon Web Services have all spun their clouds with an analytic bent?

>Here are my [the ZDNET author's] thoughts about the promise of perils of this algorithmic nirvana.
>
>Algorithms are only going to be as good as the humans producing them. Some companies are going to go digital, algorithm happy and merely scale bad processes and models.
>
>Vendors are going to spin magic bullets with algorithms and analytics. It's one thing to evaluate user interfaces, software, processes and integration. It's quite another to dig into the data science to validate vendor claims.
>
>Big data is looking increasingly like a backend plumbing topic. If data science can't find the signals and real business use, all you're going to have is a big lake of information. [I, Rob, would say *data* but hey, who am I?]
>
>Transforming to this algorithmic business isn't going to be easy. Companies are going to need new suppliers, ways to invest and approach to innovation. *Every company is going to need to be about technology as well as a venture investor*. Sondergaard urged enterprises to use "techquisitions," acquisitions of IT companies that can boost traditional businesses.
>
>Algorithms as a scene setter this year was a different tack from the previous two themes from Gartner. In 2014 and 2013, digital business was the key theme with smart machines and algorithms viewed as something developing in the future."

<a class="underlined-link" href="http://www.zdnet.com/article/dear-enterprise-you-are-your-algorithms-says-gartner/?imm_mid=0da452&cmp=em-data-na-na-newsltr_20151014" target="_blank">Interested?</a>

Thus algorithms are the future, according to Gartner. I agree. Big data is big data. It's just a relentless, jet-speed stream of un-contextual facts. Without some way to make sense of the data, without a way to create the necessary *context*, big data cannot be leveraged to value. 

Algorithms are, however, not static. They evolve, morph and *learn*. The technical term for algorithms that evolve in this way is *machine learning*. Here's a rather long passage from the Forward of a book I'm currently reading called *The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World* by Domingos, Pedro. (Basic Books). 

>"You may not know it, but machine learning is all around you. When you type a query into a search engine, it’s how the engine figures out which results to show you (and which ads, as well). When you read your e-mail, you don’t see most of the spam, because machine learning filtered it out. Go to Amazon.com to buy a book or Netflix to watch a video, and a machine-learning system helpfully recommends some you might like. Facebook uses machine learning to decide which updates to show you, and Twitter does the same for tweets. Whenever you use a computer, chances are machine learning is involved somewhere. Traditionally, the only way to get a computer to do something— from adding two numbers to flying an airplane— was to write down an algorithm explaining how, in painstaking detail. But machine-learning algorithms, also known as learners, are different: they figure it out on their own, by making inferences from data. And the more data they have, the better they get. Now we don’t have to program computers; they program themselves. It’s not just in cyberspace, either: your whole day, from the moment you wake up to the moment you fall asleep, is suffused with machine learning.

>"Your clock radio goes off at 7: 00 a.m. It’s playing a song you haven’t heard before, but you really like it. Courtesy of Pandora, it’s been learning your tastes in music, like your own personal radio jock. Perhaps the song itself was produced with the help of machine learning. You eat breakfast and read the morning paper. It came off the printing press a few hours earlier, the printing process carefully adjusted to avoid streaking using a learning algorithm. The temperature in your house is just right, and your electricity bill noticeably down, since you installed a Nest learning thermostat. 
>
>"As you drive to work, your car continually adjusts fuel injection and exhaust recirculation to get the best gas mileage. You use Inrix, a traffic prediction system, to shorten your rush-hour commute, not to mention lowering your stress level. At work, machine learning helps you combat information overload. You use a data cube to summarize masses of data, look at it from every angle, and drill down on the most important bits. You have a decision to make: Will layout A or B bring more business to your website? A web-learning system tries both out and reports back. You need to check out a potential supplier’s website, but it’s in a foreign language. No problem: Google automatically translates it for you. Your e-mail conveniently sorts itself into folders, leaving only the most important messages in the inbox. Your word processor checks your grammar and spelling. You find a flight for an upcoming trip, but hold off on buying the ticket because Bing Travel predicts its price will go down soon. Without realizing it, you accomplish a lot more, hour by hour, than you would without the help of machine learning. 
>
>"During a break you check on your mutual funds. Most of them use learning algorithms to help pick stocks, and one of them is completely run by a learning system. At lunchtime you walk down the street, smart phone in hand, looking for a place to eat. Yelp’s learning system helps you find it. Your cell phone is chock-full of learning algorithms. They’re hard at work correcting your typos, understanding your spoken commands, reducing transmission errors, recognizing bar codes, and much else. Your phone can even anticipate what you’re going to do next and advise you accordingly. For example, as you’re finishing lunch, it discreetly alerts you that your afternoon meeting with an out-of-town visitor will have to start late because her flight has been delayed. 
>
>"Night has fallen by the time you get off work. Machine learning helps keep you safe as you walk to your car, monitoring the video feed from the surveillance camera in the parking lot and alerting off-site security staff if it detects suspicious activity. On your way home, you stop at the supermarket, where you walk down aisles that were laid out with the help of learning algorithms: which goods to stock, which end-of-aisle displays to set up, whether to put the salsa in the sauce section or next to the tortilla chips. You pay with a credit card. A learning algorithm decided to send you the offer for that card and approved your application. Another one continually looks for suspicious transactions and alerts you if it thinks your card number was stolen. A third one tries to estimate how happy you are with this card. If you’re a good customer but seem dissatisfied, you get a sweetened offer before you switch to another one. 
>
>"You get home and walk to the mailbox. You have a letter from a friend, routed to you by a learning algorithm that can read handwritten addresses. There’s also the usual junk, selected for you by other learning algorithms (oh, well). You stop for a moment to take in the cool night air. Crime in your city is noticeably down since the police started using statistical learning to predict where crimes are most likely to occur and concentrating beat officers there *[Rob: Take note as we will discuss this later]*. You eat dinner with your family. The mayor is in the news. You voted for him because he personally called you on election day, after a learning algorithm pinpointed you as a key undecided voter. After dinner, you watch the ball game. Both teams selected their players with the help of statistical learning. Or perhaps you play games on your Xbox with your kids, and Kinect’s learning algorithm figures out where you are and what you’re doing. Before going to sleep, you take your medicine, which was designed and tested with the help of yet more learning algorithms. Your doctor, too, may have used machine learning to help diagnose you, from interpreting X-rays to figuring out an unusual set of symptoms. 
>
>"Machine learning plays a part in every stage of your life. If you studied online for the SAT college admission exam, a learning algorithm graded your practice essays. And if you applied to business school and took the GMAT exam recently, one of your essay graders was a learning system. Perhaps when you applied for your job, a learning algorithm picked your résumé from the virtual pile and told your prospective employer: here’s a strong candidate; take a look. Your latest raise may have come courtesy of another learning algorithm. If you’re looking to buy a house, Zillow.com will estimate what each one you’re considering is worth. When you’ve settled on one, you apply for a home loan, and a learning algorithm studies your application and recommends accepting it (or not). Perhaps most important, if you’ve used an online dating service, machine learning may even have helped you find the love of your life. Society is changing, one learning algorithm at a time. Machine learning is remaking science, technology, business, politics, and war. Satellites, DNA sequencers, and particle accelerators probe nature in ever-finer detail, and learning algorithms turn the torrents of data into new scientific knowledge. Companies know their customers like never before. The candidate with the best voter models wins, like Obama against Romney. Unmanned vehicles pilot themselves across land, sea, and air. No one programmed your tastes into the Amazon recommendation system; a learning algorithm figured them out on its own, by generalizing from your past purchases. Google’s self-driving car taught itself how to stay on the road; no engineer wrote an algorithm instructing it, step-by-step, how to get from A to B. No one knows how to program a car to drive, and no one needs to, because a car equipped with a learning algorithm picks it up by observing what the driver does.
>
>"Machine learning is something new under the sun: a technology that builds itself. Ever since our remote ancestors started sharpening stones into tools, humans have been designing artifacts, whether they’re hand built or mass produced. But learning algorithms are artifacts that design other artifacts. “Computers are useless,” said Picasso. “They can only give you answers.” Computers aren’t supposed to be creative; they’re supposed to do what you tell them to. If what you tell them to do is be creative, you get machine learning. A learning algorithm is like a master craftsman: every one of its productions is different and exquisitely tailored to the customer’s needs. But instead of turning stone into masonry or gold into jewelry, learners turn data into algorithms. And the more data they have, the more intricate the algorithms can be. 
>
>"*Homo sapiens* is the species that adapts the world to itself instead of adapting itself to the world. Machine learning is the newest chapter in this million-year saga: with it, the world senses what you want and changes accordingly, without you having to lift a finger. Like a magic forest, your surroundings— virtual today, physical tomorrow— rearrange themselves as you move through them. The path you picked out between the trees and bushes grows into a road. Signs pointing the way spring up in the places where you got lost. 
>
>"These seemingly magical technologies work because, at its core, machine learning is about prediction: predicting what we want, the results of our actions, how to achieve our goals, how the world will change. Once upon a time we relied on shamans and soothsayers for this, but they were much too fallible. Science’s predictions are more trustworthy, but they are limited to what we can systematically observe and tractably model. Big data and machine learning greatly expand that scope. Some everyday things can be predicted by the unaided mind, from catching a ball to carrying on a conversation. Some things, try as we might, are just unpredictable. For the vast middle ground between the two, there’s machine learning. 
>
>"Paradoxically, even as they open new windows on nature and human behavior, learning algorithms themselves have remained shrouded in mystery. Hardly a day goes by without a story in the media involving machine learning, whether it’s Apple’s launch of the Siri personal assistant, IBM’s Watson beating the human Jeopardy! champion, Target finding out a teenager is pregnant before her parents do, or the NSA looking for dots to connect. But in each case the learning algorithm driving the story is a black box. Even books on big data skirt around what really happens when the computer swallows all those terabytes and magically comes up with new insights. At best, we’re left with the impression that learning algorithms just find correlations between pairs of events, such as googling “flu medicine” and having the flu. But finding correlations is to machine learning no more than bricks are to houses, and people don’t live in bricks. 
>
>"When a new technology is as pervasive and game changing as machine learning, it’s not wise to let it remain a black box. Opacity opens the door to error and misuse. Amazon’s algorithm, more than any one person, determines what books are read in the world today. The NSA’s algorithms decide whether you’re a potential terrorist. Climate models decide what’s a safe level of carbon dioxide in the atmosphere. Stock-picking models drive the economy more than most of us do. You can’t control what you don’t understand, and that’s why you need to understand machine learning— as a citizen, a professional, and a human being engaged in the pursuit of happiness. 
>
>"This book’s first goal is to let you in on the secrets of machine learning. Only engineers and mechanics need to know how a car’s engine works, but every driver needs to know that turning the steering wheel changes the car’s direction and stepping on the brake brings it to a stop. Few people today know what the corresponding elements of a learner even are, let alone how to use them. The psychologist Don Norman coined the term conceptual model to refer to the rough knowledge of a technology we need to have in order to use it effectively. This book provides you with a conceptual model of machine learning. 
>
>"Not all learning algorithms work the same, and the differences have consequences. Take Amazon’s and Netflix’s recommenders, for example. If each were guiding you through a physical bookstore, trying to determine what’s “right for you,” Amazon would be more likely to walk you over to shelves you’ve frequented previously; Netflix would take you to unfamiliar and seemingly odd sections of the store but lead you to stuff you’d end up loving. In this book we’ll see the different kinds of algorithms that companies like Amazon and Netflix use. Netflix’s algorithm has a deeper (even if still quite limited) understanding of your tastes than Amazon’s, but ironically that doesn’t mean Amazon would be better off using it. Netflix’s business model depends on driving demand into the long tail of obscure movies and TV shows, which cost it little, and away from the blockbusters, which your subscription isn’t enough to pay for. Amazon has no such problem; although it’s well placed to take advantage of the long tail, it’s equally happy to sell you more expensive popular items, which also simplify its logistics. And we, as customers, are more willing to take a chance on an odd item if we have a subscription than if we have to pay for it separately.

>"Hundreds of new learning algorithms are invented every year, but they’re all based on the same few basic ideas. These are what this book is about, and they’re all you really need to know to understand how machine learning is changing the world. Far from esoteric, and quite aside even from their use in computers, they are answers to questions that matter to all of us: How do we learn? Is there a better way? What can we predict? Can we trust what we’ve learned? Rival schools of thought within machine learning have very different answers to these questions. The main ones are five in number, and we’ll devote a chapter to each. Symbolists view learning as the inverse of deduction and take ideas from philosophy, psychology, and logic. Connectionists reverse engineer the brain and are inspired by neuroscience and physics. Evolutionaries simulate evolution on the computer and draw on genetics and evolutionary biology. Bayesians believe learning is a form of probabilistic inference and have their roots in statistics. Analogizers learn by extrapolating from similarity judgments and are influenced by psychology and mathematical optimization. Driven by the goal of building learning machines, we’ll tour a good chunk of the intellectual history of the last hundred years and see it in a new light. 
>
>"Each of the five tribes of machine learning has its own master algorithm, a general-purpose learner that you can in principle use to discover knowledge from data in any domain. The symbolists’ master algorithm is inverse deduction, the connectionists’ is backpropagation, the evolutionaries’ is genetic programming, the Bayesians’ is Bayesian inference, and the analogizers’ is the support vector machine. In practice, however, each of these algorithms is good for some things but not others. What we really want is a single algorithm combining the key features of all of them: the ultimate master algorithm. For some this is an unattainable dream, but for many of us in machine learning, it’s what puts a twinkle in our eye and keeps us working late into the night.
>
>"If it exists, the Master Algorithm can derive all knowledge in the world— past, present, and future— from data. Inventing it would be one of the greatest advances in the history of science. It would speed up the progress of knowledge across the board, and change the world in ways that we can barely begin to imagine. The Master Algorithm is to machine learning what the Standard Model is to particle physics or the Central Dogma to molecular biology: a unified theory that makes sense of everything we know to date, and lays the foundation for decades or centuries of future progress. The Master Algorithm is our gateway to solving some of the hardest problems we face, from building domestic robots to curing cancer. 
>
>"Take cancer. Curing it is hard because cancer is not one disease, but many. Tumors can be triggered by a dizzying array of causes, and they mutate as they metastasize. The surest way to kill a tumor is to sequence its genome, figure out which drugs will work against it— without harming you, given your genome and medical history— and perhaps even design a new drug specifically for your case. No doctor can master all the knowledge required for this. Sounds like a perfect job for machine learning: in effect, it’s a more complicated and challenging version of the searches that Amazon and Netflix do every day, except it’s looking for the right treatment for you instead of the right book or movie. Unfortunately, while today’s learning algorithms can diagnose many diseases with superhuman accuracy, curing cancer is well beyond their ken. If we succeed in our quest for the Master Algorithm, it will no longer be. 
>
>"The second goal of this book is thus to enable you to invent the Master Algorithm. You’d think this would require heavy-duty mathematics and severe theoretical work. On the contrary, what it requires is stepping back from the mathematical *arcana* to see the overarching pattern of learning phenomena; and for this the layman, approaching the forest from a distance, is in some ways better placed than the specialist, already deeply immersed in the study of particular trees. Once we have the conceptual solution, we can fill in the mathematical details; but that is not for this book, and not the most important part. Thus, as we visit each tribe, our goal is to gather its piece of the puzzle and understand where it fits, mindful that none of the blind men can see the whole elephant. In particular, we’ll see what each tribe can contribute to curing cancer, and also what it’s missing. Then, step-by-step, we’ll assemble all the pieces into the solution— or rather, a solution that is not yet the Master Algorithm, but is the closest anyone has come, and hopefully makes a good launch pad for your imagination. And we’ll preview the use of this algorithm as a weapon in the fight against cancer. As you read the book, feel free to skim or skip any parts you find troublesome; it’s the big picture that matters, and you’ll probably get more out of those parts if you revisit them after the puzzle is assembled."

Heady stuff. A master algorithm. I'll let you ponder that for the moment. We will revisit big issues like this in Chapter 6.

####Algorithmic Trading

How about algorithms on a personal level? In the world of Finance, algorithms have replaced the day-trader dudes on the floor of the stock exchange in the business of buying and selling large blocks of stocks. In the old days (a few years ago), an institutional buyer (such as a mutual fund) would, if they wanted to buy or sell stocks in their portfolio, call up a broker and say "Hey. We need to sell a million shares of XYZ Corp. over the next few weeks but we don't want to create any kind of a shock in the market. Tell your traders to unload a few hundred here, a few hundred there and get it done by December 31." For their efforts, the brokers would take a commission on each sale. Everyone was happy (sort of). Brokers and traders were a chatty, close-knit lot, and news soon got around regarding what would be coming on the market and in what amounts and from whom. 

Then came algorithms which, at the time, were simple mechanisms to distribute buy or sell orders across some time frame and achieve what people on the floor of the stock exchange used to do. So the brokers disintermediated (jumped over) their traders and let machines do the trading. Chapter one of the story. The underlying players and their motivations could be more closely held, but still there was the messy and expensive hand-off to the broker and the fee to be paid.

Chapter two begins with DMA (direct market access), which allowed the ultimate investor (the pension fund or mutual fund or you and I) to access the trading mechanism without using a broker. Thus the broker was disintermediated as well. Investors large and small used either their own algorithms, bought or rented (see Knight Capital for a look at the havoc a broken algorithm can cause <a class="underlined-link" href="http://www.bloomberg.com/news/articles/2012-08-02/knight-shows-how-to-lose-440-million-in-30-minutes" target="_blank">Interested?</a>) to execute transactions. First the brokers automated themselves, but now the investors are automated. A typical adoption curve for this new technology sweeps the industry, picking up speed as it takes an exponential path towards dominating the market. While intermediaries (so called middlemen, specialists, market makers) once stood ready to buy and sell, algorithms now did their work. Instead of brokers offering to buy and sell, they coded up algorithms to monitor the market and then offer to buy and sell. Instead of a human making the decision about the quantities and prices at which they were willing to buy and sell, an algorithm made that decision. 

This was automation of the classic market makers. These market makers essentially took their business model and replicated it in an Excel spreadsheet. These traditional market makers were ripe to be disrupted by [editorial warning - massive and unkind generalisation coming] neck-beard, Cheetos-eating, basement dwellers. Upstart technology market makers, called *high frequency traders* (HFTs), started competing with traditional market makers for their business. They were faster and cheaper than the traditional market makers and were willing to trade at better prices than was the old guard. An article in Wired magazine puts the HFTs into perspective:

>"On the first day of the New York conference [of HFT algorithm experts], Aaron Brown, a legendary quant and former professional poker player, took the stage in rumpled chinos and a leather jacket to lecture the assembly on game theory. He began his talk by saying, '3.14159,' and then pausing expectantly. From the back of the room came the response: '265358.' Together they made up the first 12 digits of pi — a geek shibboleth. 'You won’t see a lot of masters of the universe here,' said Charles Jones, a professor of finance and economics at Columbia Business School. 'A lot of these guys, if they’re wearing a tie, it might be the only one they own." Chapter three begins.

<a class="underlined-link" href="https://www.wired.com/2012/08/ff_wallstreet_trading/" target="_blank">Source - and a great article to read!</a>

To set up this final piece on HFT, please read <a class="underlined-link" href="http://www.wsj.com/articles/SB10001424052702303947904579340711424615716" target="_blank">this article</a> from the Wall Street Journal. 

These HFTs were located as close to the electronic market infrastructure as possible. Sometimes they would rent offices directly across from the exchange to shorten the distance between themselves and the markets, other times they would co-locate (cite) within the exchange infrastructure. Entire skyscrapers in NYC close to the exchanges have been hollowed out and filled with servers and network infrastructure, just to beat *latency* (the time it takes for an electronic signal to move from point A to point B) in an effort to *reach zero latency* (the *speed of light*) in transactions. These new market makers quickly drove the slower market makers out of business, leaving only HFT willing to stand ready to buy and sell securities in most markets. 

For the most part, this has been beneficial to the market. The price of liquidity (the difference between the buy and sell price) has fallen and markets have become relatively resilient (see the <a class="underlined-link" href="https://en.wikipedia.org/wiki/2010_Flash_Crash" target="_blank">Flash Crash</a>). Nevertheless, the public and regulators are concerned about the overall impact of these ultra-fast liquidity suppliers. In particular whether or not the HFT speed advantage leads to an unfair unfair advantage over slower and less sophisticated investors. Most evidence suggests that this is not the case as research shows that most individual investors are better off with HFT intermediaries than with the classic, old-school intermediaries. HFTs are cheaper and quicker to react to market changes. There is no clear evidence that anyone was better served in the previous market structure. 

Here are some interesting research papers if you are so inclined (Finance people will be). They are not required reading. 

<a class="underlined-link" href="http://www.sciencedirect.com/science/article/pii/S1386418113000281" target="_blank">New market makers</a>
<a class="underlined-link" href="http://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.2010.01624.x/full" target="_blank">Algorithmic trading (AT)</a>
<a class="underlined-link" href="http://journals.cambridge.org/abstract_S0022109013000471" target="_blank">Another AT link</a>
<a class="underlined-link" href="http://rfs.oxfordjournals.org/content/27/8/2267.short" target="_blank">HFT Link</a>
<a class="underlined-link" href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2236201" target="_blank">another HFT Link</a>

Overall the jury is still out on whether or not HFTs are beneficial to markets overall. Nevertheless, most evidence suggests that HFTs have been relatively good for all players. 

##Blockchains

We end this chapter with a discussion of probably the single biggest impact technology over the next decade: *Blockchains*. This technology (a set of rules on how to use technology), which is behind such popular initiatives as *Bitcoin*, is poised to revolutionise the way we interact with each other, with public institutions (including banks and governments) and with platform enterprises such as *Uber*, *Facebook* and *Twitter*.

What is a Blockchain? A blockchains is, simply speaking, a distributed ledger. Ledgers exactly as you have studied in your introductory accounting classes. Everyone who participates in the blockchain has their own copy of the ledger - thus there can be millions of copies of the ledger spread across what can be a vast network of participants. And the ledger grows with each transaction. Using *Bitcoin* as an example, two participants in the network can exchange services for funds simply by the purchaser broadcasting a message to the network that their account should be decremented by *x* amount, and the receiver's account should be incremented by the same amount. This *proposed transaction* (we'll get back to why it's only *proposed* below) is then recorded in each copy of the ledger across the network of participants. So every participant has a copy of every transaction that has ever or will ever occur in the network for as long as they remain participants.

If you agreed to participate in Bitcoin, for example, the entire collection of every transaction that ever occurred in the Bitcoin network is downloaded onto your computer and is processed back through the chain from that moment to the very first creation of the very first Bitcoin. This can take over 24 hours. Note the two figures below. This reconciliation occurred on my own desktop computer. 

**Figure KJTA. Bitcoin reconciliation (start)**

![Bitcoin process begin](https://raw.githubusercontent.com/robertriordan/2400/master/Images/bitcoin_synchro_install.png)

Note the highlighted sections at the bottom, indicating where we are at in the process. Seems I joined the Bitcoin game about 7 years and some weeks late. As my old machine clunked away at reconciliation, we see the status some 28 hours later, below.

**Figure KJPT. Bitcoin reconciliation (nearing completion)**

![Bitcoin process nearing completion](https://raw.githubusercontent.com/robertriordan/2400/master/Images/bitcoin_synchro_install_2.png)

What's unique and groundbreaking about such a system is that, unlike the way we are accustomed to doing business - through large financial organisations such as banks where unless a transaction were the subject of an investigation, details are hidden from all but the bank itself and the participants - with blockchain networks such as Bitcoin, everyone sees every transaction. It's the ultimate hippy commune. What we don't know, however, is the *identity* of the participants. We see that a transaction has occurred between party A and part B and we see *the amount that was transferred*, we do not and should not know who A and B are. 

###Public Key Infrastructure (PKI)###

In transacting on the network, the sender and recipient of a transaction don't use their real identities. Rather they use *digital signatures* (see below) which allow both parties to verify their authenticity without revealing their true identities. Such signatures are made possible through a tried-and-true technology known as *PKI* or *Public Key Infrastructure*. Participants in blockchain networks use PKI to generate a unique signature each time they initiate a transaction. PKI works by generating two keys (digital hashes - see below): a *private key* that only the owner knows and a *public key* that anyone can use and which proves that the public key belongs to the owner of the private key. 

[Interested in PKI?](https://en.wikipedia.org/wiki/Public_key_infrastructure)

The first step is to install a digital wallet (or equivalent - email clients can do the same thing for you). You then ask the wallet to generate a private key for you. This private key never changes and must be safeguarded. If you lose your private key, you also lose all claim to anything based on your public key as they depend on each other. Once you have a private key, the wallet will allow you to generate any number of public keys. Only the holder of the private key can unlock the contents of a message encrypted with a particular public key. The sender of the transaction must initiate and send the message to move something from their possession to the possession of another. A payee can also request a payment by sending their address to the payer's address and specifying the amount. This private/public key technology is an important component of a *digital signature*, as we will see below. 

####Digital signatures

As we learned above, digital signatures are based on PKI (which is also also known as *asymmetric cryptography*). PKI algorithms such as RSA can be used to generate two keys that are mathematically linked: one private and one public. To create a digital signature, signing software (such as an email program) creates a one-way *hash* (see below) of the electronic data to be signed. In a blockchain transaction such as Bitcoin, this electronic data consists of your signature (I know this sounds circular - just hang on), the signature of the party to whom you are sending Bitcoins, the hash of the previous block in the chain, and finally a random digit at the end. We will come back to this in some detail later. We take all this electronic data and then use the private key to encrypt the hash. All this together is the digital signature. 

The reason for encrypting the hash instead of the entire message or document is that a hash function can convert an arbitrary input into a fixed length value, which is usually much shorter. This saves time since hashing is much faster than signing.

###Using blockchains for transactions

Here's how it works. To transfer ownership of something you own to someone else (in Bitcoin this is bitcoin funds but it could be anything as we will later explain), both parties must have an account on the system used for the exchange. For person A to transfer ownership to person B, all that is required is that A send a message to the network that they want to transfer some amount of whatever is being traded from A to B. Each recipient of the message updates their local copy of the blockchain to reflect the change, and passes the message on to the next node. This message contains the *digital signature* of both the sender and the recipient. Thus the message is to send *x* from the account of the owner of digital signature *A* to the account of the owner of digital signature *B*. Since the identities of both parties to the transaction are *protected by PKI*, the exchange is completely private, even though all participants in the network can see the transaction. 

###Hash (no not *that* kind)

A hash is a well-used and time-honoured function from Computer Science that is used to map (create a path) from digital input data of arbitrary (random) size to digital output data of a fixed (known and predictable) size. To demonstrate this principle, see the Excel macro-enabled worksheet downloadable from the following link: [Excel hash algorithm](https://raw.githubusercontent.com/robertriordan/2400/master/resources/risk_profiler.xlsx). We use a variation of this hash to do Peer Evals anonymously. Download the Excel sheet and enter any series of characters (even a blank or null string) and note that you will always get a 10-digit hash back from the algorithm. 

But more importantly, Blockchain hashes are *cryptographic*. A cryptographic hash has certain characteristics, the most important of which is that it can't be reverse-engineered to recreate the input data without having to endeavour to use all possible combinations to see which one produced the same output. Such hashes are called *one-way*. You can't figure out the input by looking at the output. And this is critical. But there are other critical things as well. Here are the three big ones according to Wikipedia:

1. Pre-image resistance - Given a hash value h it should be difficult to find any message m such that h = hash(m). This concept is related to that of one-way function. Functions that lack this property are vulnerable to preimage attacks.
2. Second pre-image resistance - Given an input m1 it should be difficult to find different input m2 such that hash(m1) = hash(m2). Functions that lack this property are vulnerable to second-preimage attacks.
3. Collision resistance - It should be difficult to find two different messages m1 and m2 such that hash(m1) = hash(m2). Such a pair is called a cryptographic hash collision. This property is sometimes referred to as strong collision resistance. It requires a hash value at least twice as long as that required for preimage-resistance; otherwise collisions may be found by a birthday attack.

The article continues that "These properties imply that a malicious adversary cannot replace or modify the input data without changing its digest. Thus, if two strings have the same digest, one can be very confident that they are identical."

[Interested?](https://en.wikipedia.org/wiki/Cryptographic_hash_function)

We know what transactions are from our discussions of Transaction Processing Systems (TPS); a transaction is simply a record of the exchange of something for something else: money for a product or service, for example. So transactions are simple. And transactions are the very basis of our financial and banking systems. It's simple accounting. 

Every transaction in a blockchain is stored and shared with every participant, making it quite democratic. There is no hiding of transactions, but only the identity of the transactors. Blockchains have been put to criminal use (if your laptop or tablet has ever been infected with ransomware, invariably the request from the ransomers is that you pay them in Bitcoin before they will unlock your computer). But there is much potential for good from blockchains. 

Blockchains are being used in many applications, including whole countries which are adopting them to replace their national currencies. See this fresh bit of news: <a class="underlined-link" href="http://qz.com/838589/chinas-central-bank-is-hiring-blockchain-experts-to-help-it-kill-off-cash/" target="_blank">China going cashless?</a> Other applications include real estate (much of the land in the world does not have clear ownership title, opening many in developing countries to the threat of eviction from land they have occupied for millennia. Blockchain can establish ownership.), drivers and other permits, social insurance cards, banking of course, and many others. 

BUSI 2400 Fall 2016 - Chapter ends rather abruptly here ------------------------

####Browser / OS usage

![Browser Usage - desktop Usage](https://raw.githubusercontent.com/robertriordan/2400/master/Images/browser-CA-monthly-201510-201610-bar.png)

![Browser Usage - mobile+tablet Usage](https://raw.githubusercontent.com/robertriordan/2400/master/Images/mobile_tablet_browser-CA-monthly-201510-201610-bar.png)

Source: http://gs.statcounter.com/#mobile+tablet-browser-CA-monthly-201510-201610-bar

App Annie

Backup - Nuclear reactor 

E-commerce & frictionless economy (see Chrome tab on this)

co-creation

Privacy - security issues  see OneNote

History of retail innovation wk04ch07

The frictionless economy

Types of e-commerce

Addictive apps

Malleable brain and conditioning

Wearables

Green IT

Buying IT



